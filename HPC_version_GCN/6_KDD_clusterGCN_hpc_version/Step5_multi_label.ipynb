{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## isolated clustering including recombination of mini-cluster for hpc run \n",
    "\n",
    "Comments:\n",
    "\n",
    "ClusterGCN baseline, KDD 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pickle\n",
    "import shutil\n",
    "\n",
    "from utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import torch\n",
    "from torch_geometric.utils import scatter_\n",
    "\n",
    "import math\n",
    "import random\n",
    "\n",
    "from torch.nn import Parameter\n",
    "from torch_scatter import scatter_add\n",
    "# from torch_geometric.nn import MessagePassing\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import add_remaining_self_loops\n",
    "\n",
    "### ====================== Establish a GCN based model ========================\n",
    "class ListModule(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Abstract list layer class.\n",
    "    \"\"\"\n",
    "    def __init__(self, *args):\n",
    "        \"\"\"\n",
    "        Module initializing.\n",
    "        \"\"\"\n",
    "        super(ListModule, self).__init__()\n",
    "        idx = 0\n",
    "        for module in args:\n",
    "            self.add_module(str(idx), module)\n",
    "            idx += 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Getting the indexed layer.\n",
    "        \"\"\"\n",
    "        if idx < 0 or idx >= len(self._modules):\n",
    "            raise IndexError('index {} is out of range'.format(idx))\n",
    "        it = iter(self._modules.values())\n",
    "        for i in range(idx):\n",
    "            next(it)\n",
    "        return next(it)\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "        Iterating on the layers.\n",
    "        \"\"\"\n",
    "        return iter(self._modules.values())\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Number of layers.\n",
    "        \"\"\"\n",
    "        return len(self._modules)\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, input_layers = [16, 16], dropout=0.3):\n",
    "        \"\"\"\n",
    "        input layers: list of integers\n",
    "        dropout: probability of droping out \n",
    "        \"\"\"\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.input_layers = input_layers\n",
    "        self.dropout = dropout\n",
    "        self.setup_layers()\n",
    "\n",
    "    def setup_layers(self):\n",
    "        \"\"\"\n",
    "        Creating the layes based on the args.\n",
    "        \"\"\"\n",
    "        self.layers = []\n",
    "        self.input_layers = [self.in_channels] + self.input_layers + [self.out_channels]\n",
    "        for i, _ in enumerate(self.input_layers[:-1]):\n",
    "            self.layers.append(GCNConv(self.input_layers[i],self.input_layers[i+1]))\n",
    "        self.layers = ListModule(*self.layers)\n",
    "\n",
    "    # change the dropout positions: \n",
    "    def forward(self, edge_index, features):\n",
    "        if len(self.layers) > 1:\n",
    "            for i in range(len(self.layers)-1):\n",
    "                features = F.relu(self.layers[i](features, edge_index))\n",
    "#                 if i>0:\n",
    "                features = F.dropout(features, p = self.dropout, training = self.training)\n",
    "                    \n",
    "            features = self.layers[len(self.layers)-1](features, edge_index)\n",
    "        else:\n",
    "            features = self.layers[0](features, edge_index)    # for a single layer case\n",
    "        \n",
    "        predictions = features\n",
    "        # just use the linear layer output, since we are using the cross-entropy loss\n",
    "        # just pay attention to the test part, change the predictions\n",
    "        \n",
    "#         predictions = F.log_softmax(features, dim=1)\n",
    "        # if using the nll loss, then we need this log_softmax layer\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partition GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import metis\n",
    "import random\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import chain\n",
    "\n",
    "class ClusteringMachine(object):\n",
    "    \"\"\"\n",
    "    Clustering the graph, feature set and label. Performed on the CPU side\n",
    "    \"\"\"\n",
    "    def __init__(self, edge_index, features, label, tmp_folder = './tmp/', info_folder = './info/'):\n",
    "        \"\"\"\n",
    "        :param edge_index: COO format of the edge indices.\n",
    "        :param features: Feature matrix (ndarray).\n",
    "        :param label: label vector (ndarray).\n",
    "        :tmp_folder(string): the path of the folder to contain all the clustering information files\n",
    "        \"\"\"\n",
    "        self.features = features\n",
    "        self.label = torch.tensor(label, dtype=torch.float)\n",
    "        self._set_sizes()\n",
    "        self.edge_index = edge_index\n",
    "        # store the information folder for memory tracing\n",
    "        self.tmp_folder = tmp_folder\n",
    "        self.info_folder = info_folder\n",
    "        \n",
    "        tmp = edge_index.t().numpy().tolist()\n",
    "        self.graph = nx.from_edgelist(tmp)\n",
    "        \n",
    "    def _set_sizes(self):\n",
    "        \"\"\"\n",
    "        Setting the feature and class count.\n",
    "        \"\"\"\n",
    "        self.node_count = self.features.shape[0]\n",
    "        self.feature_count = self.features.shape[1]    # features all always in the columns\n",
    "        self.label_count = len(np.unique(self.label.numpy()) )\n",
    "        \n",
    "    # 1) first use different clustering method, then split each cluster into train, test and validation nodes, split edges\n",
    "    def split_cluster_nodes_edges(self, validation_ratio, test_ratio, mini_cluster_num = 4, train_batch_num = 2, round_num = 2):\n",
    "        \"\"\"\n",
    "            1) decompose the whole graph into parition_num small mini-clusters, all the mini-cluster relevant use local variables\n",
    "            2) recombine the mini-clusters into train_batch_num batches (self.sg_nodes_global)\n",
    "            3) test is for the unseen data\n",
    "            4) validation is for the cross-validation purpose\n",
    "        \"\"\"\n",
    "        mini_cluster_nodes_global = self.metis_clustering(self.graph, mini_cluster_num)\n",
    "        mini_cluster_id = list(mini_cluster_nodes_global.keys())\n",
    "        \n",
    "        relative_validation_ratio = (validation_ratio) / (1 - test_ratio)\n",
    "        \n",
    "        mini_cluster_test_nodes_global = {}\n",
    "        mini_cluster_train_nodes_global = {}\n",
    "        mini_cluster_validation_nodes_global = {}\n",
    "        \n",
    "        for cluster in mini_cluster_id:\n",
    "            mini_cluster_model_nodes_global, mini_cluster_test_nodes_global[cluster] = \\\n",
    "                    train_test_split(mini_cluster_nodes_global[cluster], test_size = test_ratio)\n",
    "            mini_cluster_train_nodes_global[cluster], mini_cluster_validation_nodes_global[cluster] = \\\n",
    "                    train_test_split(mini_cluster_model_nodes_global, test_size = relative_validation_ratio)\n",
    "            \n",
    "        #recombine_mini_cluster_for_batch:\n",
    "        sg_test_nodes_global = {}\n",
    "        self.sg_nodes_global = {}\n",
    "        self.sg_train_nodes_global = {}\n",
    "        self.sg_validation_nodes_global = {}\n",
    "        # keep the info of each cluster:\n",
    "        self.info_isolate_cluster_size = {}\n",
    "        self.info_test_cluster_size = {}\n",
    "        self.info_train_cluster_size = {}\n",
    "        self.info_validation_cluster_size = {}\n",
    "        # compute how many elements is inside each batch\n",
    "        chunck_size = mini_cluster_num // train_batch_num\n",
    "        for round_id in range(round_num):\n",
    "            # first shuffle all the mini-cluster ids:\n",
    "            mini_cluster_order = mini_cluster_id\n",
    "            random.shuffle(mini_cluster_order)\n",
    "            combine_group = [mini_cluster_order[i * chunck_size : (i + 1) * chunck_size] for i in range((len(mini_cluster_order) + chunck_size - 1) // chunck_size )]  \n",
    "            for local_batch_id, group in enumerate(combine_group):\n",
    "                global_batch_id = round_id * train_batch_num + local_batch_id\n",
    "                self.sg_nodes_global[global_batch_id] = list(chain.from_iterable(mini_cluster_nodes_global[cluster_id] for cluster_id in group))\n",
    "                sg_test_nodes_global[global_batch_id] = list(chain.from_iterable(mini_cluster_test_nodes_global[cluster_id] for cluster_id in group))\n",
    "                self.sg_train_nodes_global[global_batch_id] = list(chain.from_iterable(mini_cluster_train_nodes_global[cluster_id] for cluster_id in group))\n",
    "                self.sg_validation_nodes_global[global_batch_id] = list(chain.from_iterable(mini_cluster_validation_nodes_global[cluster_id] for cluster_id in group))\n",
    "        \n",
    "        # accumulate all the validation nodes for validation process:\n",
    "        self.test_nodes_global = list(chain.from_iterable(sg_test_nodes_global.values()))\n",
    "        \n",
    "        for batch in self.sg_nodes_global.keys():\n",
    "            # record the information of each recombined batch:\n",
    "            self.info_isolate_cluster_size[batch] = len(self.sg_nodes_global[batch])\n",
    "            self.info_train_cluster_size[batch] = len(self.sg_train_nodes_global[batch])\n",
    "            self.info_validation_cluster_size[batch] = len(self.sg_validation_nodes_global[batch])\n",
    "    \n",
    "    \n",
    "    # just allocate each node to arandom cluster, store the membership inside each dict\n",
    "    def random_clustering(self, target_nodes, partition_num):\n",
    "        \"\"\"\n",
    "            Random clustering the nodes.\n",
    "            Input: \n",
    "                1) target_nodes: list of node \n",
    "                2) partition_num: number of partition to be generated\n",
    "            Output: \n",
    "                1) membership of each node\n",
    "        \"\"\"\n",
    "        # randomly divide into two clusters\n",
    "        nodes_order = [node for node in target_nodes]\n",
    "        random.shuffle(nodes_order)\n",
    "        n = (len(nodes_order) + partition_num - 1) // partition_num\n",
    "        partition_list = [nodes_order[i * n:(i + 1) * n] for i in range(partition_num)]\n",
    "#         cluster_membership = {node : i for i, node_list in enumerate(partition_list) for node in node_list}\n",
    "        cluster_nodes_global = {i : node_list for i, node_list in enumerate(partition_list)}\n",
    "        \n",
    "        return cluster_nodes_global\n",
    "\n",
    "    def metis_clustering(self, target_graph, partition_num):\n",
    "        \"\"\"\n",
    "            Random clustering the nodes.\n",
    "            Input: \n",
    "                1) target_nodes: list of node \n",
    "                2) partition_num: number of partition to be generated\n",
    "            Output: \n",
    "                1) membership of each node\n",
    "        \"\"\"\n",
    "        (st, parts) = metis.part_graph(target_graph, partition_num)\n",
    "        clusters = list(set(parts))\n",
    "        cluster_nodes_global = defaultdict(list)\n",
    "        for node, cluster_id in enumerate(parts):\n",
    "            cluster_nodes_global[cluster_id].append(node)\n",
    "        return cluster_nodes_global\n",
    "\n",
    "    # for use of validation on the whole graph as a whole in CPU-side memory\n",
    "    def whole_batch_generate(self, batch_file_folder, test_nodes):\n",
    "        \"\"\"\n",
    "            For use of testing the model: generate the needed tensors for testing in CPU-memory side\n",
    "        \"\"\"\n",
    "        # store the global edges\n",
    "        whole_nodes_global = sorted(self.graph.nodes())\n",
    "        whole_edges_global = {edge for edge in self.graph.edges()}\n",
    "        \n",
    "        whole_edges_local = \\\n",
    "                       [ [ left, right ] for left, right in whole_edges_global ] + \\\n",
    "                       [ [ right, left ] for left, right in whole_edges_global ] + \\\n",
    "                       [ [i, i] for i in whole_nodes_global ]  \n",
    "        \n",
    "        # store local features and lables\n",
    "        whole_features_local = self.features\n",
    "        whole_labels_local = self.label\n",
    "\n",
    "        # transform all the data to the tensor form\n",
    "        whole_edges_local = torch.LongTensor(whole_edges_local).t()\n",
    "        whole_features_local = torch.FloatTensor(whole_features_local)\n",
    "        whole_labels_local = torch.FloatTensor(whole_labels_local)\n",
    "        whole_test_nodes_local = torch.LongTensor( sorted(test_nodes) )\n",
    "\n",
    "        whole_batch_data = [whole_test_nodes_local, whole_edges_local, whole_features_local, whole_labels_local]\n",
    "\n",
    "        batch_file_name = batch_file_folder + 'batch_whole'\n",
    "\n",
    "        # store the batch files\n",
    "        t0 = time.time()\n",
    "        with open(batch_file_name, \"wb\") as fp:\n",
    "            pickle.dump(whole_batch_data, fp)\n",
    "        store_time = ((time.time() - t0) * 1000)\n",
    "        print('*** Generate batch file for # {0} batch, writing the batch file costed {1:.2f} ms ***'.format(\"whole graph\", store_time) )\n",
    "    \n",
    "    \n",
    "    \n",
    "    def mini_batch_generate(self, batch_file_folder, target_seed, batch_range = (0, 1)):\n",
    "        \"\"\"\n",
    "            create the mini-batch focused on the train nodes only, include a total of k layers of neighbors of the original training nodes\n",
    "            k: number of layers of neighbors for each training node\n",
    "            fraction: fraction of neighbor nodes in each layer to be considered\n",
    "            Input:\n",
    "                1) target_seed: global ids of the nodes for seed to generate the batch\n",
    "                    usually one of (train_global, test_global_, validation_global)\n",
    "            Output: all tensors which are gonna be used in the train, forward procedure\n",
    "                local:\n",
    "                    1) sg_mini_edges_local\n",
    "                    2) self.sg_mini_train_edge_weight_local\n",
    "                    3) self.sg_mini_train_nodes_local\n",
    "                    4) self.sg_mini_train_features\n",
    "                    5) self.sg_mini_train_labels\n",
    "            \n",
    "        \"\"\"\n",
    "        info_batch_node_size = {}\n",
    "        info_batch_edge_size = {}\n",
    "        batch_start, batch_end = batch_range\n",
    "        for cluster in range(batch_start, batch_end):\n",
    "            batch_subgraph = self.graph.subgraph(self.sg_nodes_global[cluster])\n",
    "            \n",
    "             # first select all the overlapping nodes of the train nodes\n",
    "            mini_nodes_global = sorted(node for node in batch_subgraph.nodes())\n",
    "            \n",
    "            # store the global edges\n",
    "            mini_edges_global = {edge for edge in batch_subgraph.edges()}\n",
    "            \n",
    "            # map nodes from global index to local index\n",
    "            mini_mapper = {node: i for i, node in enumerate(mini_nodes_global)}\n",
    "            \n",
    "            # store local index of batch nodes\n",
    "            mini_nodes_local = [ mini_mapper[global_idx] for global_idx in target_seed[cluster] ]\n",
    "            \n",
    "            # store local index of batch edges\n",
    "            mini_edges_local = \\\n",
    "                           [ [ mini_mapper[edge[0]], mini_mapper[edge[1]] ] for edge in mini_edges_global ] + \\\n",
    "                           [ [ mini_mapper[edge[1]], mini_mapper[edge[0]] ] for edge in mini_edges_global ]\n",
    "            \n",
    "            # store local features and lables\n",
    "            mini_features = self.features[mini_nodes_global,:]\n",
    "            mini_labels = self.label[mini_nodes_global]\n",
    "            \n",
    "            # record information \n",
    "            info_batch_node_size[cluster] = len(mini_nodes_global)\n",
    "            info_batch_edge_size[cluster] = len(mini_edges_local)\n",
    "            \n",
    "            mini_nodes_local = torch.LongTensor(mini_nodes_local)\n",
    "            mini_edges_local = torch.LongTensor(mini_edges_local).t()\n",
    "            mini_features = torch.FloatTensor(mini_features)\n",
    "            mini_labels = torch.FloatTensor(mini_labels)\n",
    "            \n",
    "            minibatch_data = [mini_nodes_local, mini_edges_local, mini_features, mini_labels]\n",
    "            \n",
    "            batch_file_name = batch_file_folder + 'batch_' + str(cluster)\n",
    "            \n",
    "            # store the batch files\n",
    "            t0 = time.time()\n",
    "            with open(batch_file_name, \"wb\") as fp:\n",
    "                pickle.dump(minibatch_data, fp)\n",
    "            store_time = ((time.time() - t0) * 1000)\n",
    "            print('*** Generate batch file for # {0:3d} batch, writing the batch file costed {1:.2f} ms ***'.format(cluster, store_time) )\n",
    "#             print('writing to the path: ', batch_file_name)\n",
    "            \n",
    "        return info_batch_node_size, info_batch_edge_size\n",
    "    \n",
    "    def save_info_dict(self, data, file_name, target_folder, header = 'key, value'):\n",
    "        # output the batch size information as the csv file\n",
    "#         os.makedirs(os.path.dirname(target_folder), exist_ok=True)\n",
    "        target_file = target_folder + file_name\n",
    "        \n",
    "        with open(target_file, 'a', newline='\\n') as fp:\n",
    "            wr = csv.writer(fp, delimiter = ',')\n",
    "            fp.write('\\n')\n",
    "            wr.writerow(header.split(','))\n",
    "            for key, val in data.items():\n",
    "                wr.writerow([key+1, val])\n",
    "    \n",
    "    def mini_batch_train_clustering(self, batch_folder, batch_range = (0, 1), info_folder = './info/', info_file = 'train_batch_size_info.csv'):\n",
    "        data_type = 'train'\n",
    "        batch_file_folder = batch_folder + data_type + '/'\n",
    "        check_folder_exist(batch_file_folder)\n",
    "        os.makedirs(os.path.dirname(batch_file_folder), exist_ok=True)\n",
    "        \n",
    "        self.info_train_batch_node_size, self.info_train_batch_edge_size  = self.mini_batch_generate(batch_file_folder, self.sg_train_nodes_global, batch_range = batch_range)\n",
    "        self.info_train_seed_size = {key : len(val) for key, val in self.sg_train_nodes_global.items()}\n",
    "        \n",
    "        self.save_info_dict(self.info_train_batch_node_size, info_file, info_folder, header = 'train_batch_node_id, train_batch_node_size')\n",
    "        self.save_info_dict(self.info_train_batch_edge_size, info_file, info_folder, header = 'train_batch_edge_id, train_batch_edge_size')\n",
    "        self.save_info_dict(self.info_train_seed_size, info_file, info_folder, header = 'train_seed_node_id, train_seed_node_size')\n",
    "        \n",
    "    def whole_validation_clustering(self, batch_folder, info_folder = './info/', info_file = 'validation_whole_size_info.csv'):\n",
    "        data_type = 'validation'\n",
    "        batch_file_folder = batch_folder + data_type + '/'\n",
    "#         check_folder_exist(batch_file_folder)\n",
    "        os.makedirs(os.path.dirname(batch_file_folder), exist_ok=True)\n",
    "        \n",
    "        self.whole_batch_generate(batch_file_folder, self.test_nodes_global)        \n",
    "        \n",
    "    def mini_batch_test_clustering(self, batch_folder, test_batch_num = 2):\n",
    "        data_type = 'test'\n",
    "        batch_file_folder = batch_folder + data_type + '/'\n",
    "        check_folder_exist(batch_file_folder)\n",
    "        os.makedirs(os.path.dirname(batch_file_folder), exist_ok=True)\n",
    "        \n",
    "        self.info_test_batch_node_size, self.info_test_batch_edge_size = self.mini_batch_generate(batch_file_folder, self.sg_validation_nodes_global)\n",
    "        self.info_test_seed_size = {key : len(val) for key, val in self.sg_validation_nodes_global.items()}\n",
    "        self.save_info_dict(self.info_test_batch_node_size, 'batch_size_info.csv', self.info_folder, header = 'test_batch_node_id, test_batch_node_size')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partition Graph with trainiing and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Custom_GCN_layer import Net\n",
    "import time\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class ClusterGCNTrainer_mini_Train(object):\n",
    "    \"\"\"\n",
    "    Training a ClusterGCN.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_folder, in_channels, out_channels, input_layers = [32, 16], dropout=0.3):\n",
    "        \"\"\"\n",
    "        :param in_channels, out_channels: input and output feature dimension\n",
    "        :param clustering_machine:\n",
    "        \"\"\"  \n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.test_device = torch.device(\"cpu\")\n",
    "        \n",
    "        self.data_folder = data_folder\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.input_layers = input_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.create_model()\n",
    "\n",
    "    def create_model(self):\n",
    "        \"\"\"\n",
    "        Creating a StackedGCN and transferring to CPU/GPU.\n",
    "        \"\"\"\n",
    "#         print('used layers are: ', str(self.input_layers))\n",
    "        self.model = Net(self.in_channels, self.out_channels, input_layers = self.input_layers, dropout = self.dropout)\n",
    "        self.model = self.model.to(self.device)\n",
    "    \n",
    "    # call the forward function batch by batch\n",
    "    def do_forward_pass(self, tr_train_nodes, tr_edges, tr_features, tr_target):\n",
    "        \"\"\"\n",
    "        Making a forward pass with data from a given partition.\n",
    "        :param cluster: Cluster index.\n",
    "        :return average_loss: Average loss on the cluster.\n",
    "        :return node_count: Number of nodes.\n",
    "        \"\"\"\n",
    "        \n",
    "        '''Target and features are one-one mapping'''\n",
    "        # calculate the probabilites from log_sofmax\n",
    "        predictions = self.model(tr_edges, tr_features)\n",
    "        _loss = torch.nn.BCEWithLogitsLoss()\n",
    "        ave_loss = _loss(predictions[tr_train_nodes], tr_target[tr_train_nodes])\n",
    "#         ave_loss = torch.nn.functional.nll_loss(predictions[tr_train_nodes], tr_target[tr_train_nodes])\n",
    "        node_count = tr_train_nodes.shape[0]\n",
    "\n",
    "        # for each cluster keep track of the counts of the nodes\n",
    "        return ave_loss, node_count\n",
    "\n",
    "    def update_average_loss(self, batch_average_loss, node_count, isolate = True):\n",
    "        \"\"\"\n",
    "        Updating the average loss in the epoch.\n",
    "        :param batch_average_loss: Loss of the cluster. \n",
    "        :param node_count: Number of nodes in currently processed cluster.\n",
    "        :return average_loss: Average loss in the epoch.\n",
    "        \"\"\"\n",
    "        self.accumulated_training_loss = self.accumulated_training_loss + batch_average_loss.item() * node_count\n",
    "        if isolate:\n",
    "            self.node_count_seen = self.node_count_seen + node_count\n",
    "        average_loss = self.accumulated_training_loss / self.node_count_seen\n",
    "        return average_loss\n",
    "    \n",
    "    def train_investigate_F1(self, epoch_num=10, learning_rate=0.01, weight_decay = 0.01, mini_epoch_num = 1, output_period = 10, train_batch_num = 2):\n",
    "        \"\"\"\n",
    "            *** Periodically output the F1 score during training. After certain number of epochs ***\n",
    "            epoch_num:  number of total training epoch number\n",
    "            learning rate: learning rate during training\n",
    "            weight_decay:  decay coefficients for the regularization\n",
    "            mini_epoch_num:  number of epochs of repeating training after loading data on the GPU\n",
    "            output_period:  number of epochs after which output the F1 and accuray to investigate the model refining process\n",
    "        \"\"\"\n",
    "        # load the validation data for investigation\n",
    "        batch_file_name = self.data_folder + 'validation/batch_whole'\n",
    "        t00 = time.time()\n",
    "        with open(batch_file_name, \"rb\") as fp:\n",
    "            minibatch_data_validation = pickle.load(fp)\n",
    "        read_time = (time.time() - t00) * 1000\n",
    "        print('*** During validation for # {0} batch, reading batch file costed {1:.2f} ms ***'.format(\"whole graph for investigation\", read_time) )\n",
    "        investigate_f1 = {}\n",
    "        investigate_accuracy = {}\n",
    "        \n",
    "        # start the training investigation\n",
    "        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        self.model.train()   #   set into train mode, only effective for certain modules such as dropout and batchNorm\n",
    "        self.record_ave_training_loss = []\n",
    "        \n",
    "        self.time_train_load_data = 0\n",
    "        total_data_IO_time = 0\n",
    "        \n",
    "        epoch_partition = epoch_num // mini_epoch_num\n",
    "        t0 = time.time()\n",
    "        train_clusters = list(range(train_batch_num))\n",
    "        for epoch_part in range(epoch_partition):\n",
    "#             For test purpose, we let the clusters to follow specific order\n",
    "            random.shuffle(train_clusters)\n",
    "            \n",
    "            for cluster in train_clusters:\n",
    "                # read in the train data from the pickle files\n",
    "                batch_file_name = self.data_folder + 'train/batch_' + str(cluster)\n",
    "                \n",
    "                t2 = time.time()\n",
    "                with open(batch_file_name, \"rb\") as fp:\n",
    "                    minibatch_data_train = pickle.load(fp)\n",
    "                total_data_IO_time += (time.time() - t2) * 1000\n",
    "                \n",
    "                tr_train_nodes, tr_edges, tr_features, tr_target = minibatch_data_train\n",
    "                \n",
    "                # for each cluster, we load once and train it for multiple epochs:\n",
    "                t1 = time.time()\n",
    "                tr_train_nodes = tr_train_nodes.to(self.device)\n",
    "                tr_edges = tr_edges.to(self.device)\n",
    "                tr_features = tr_features.to(self.device)\n",
    "                tr_target = tr_target.to(self.device)\n",
    "                \n",
    "                self.time_train_load_data += (time.time() - t1) * 1000\n",
    "                \n",
    "                # train each batch for multiple epochs\n",
    "                for mini_epoch in range(mini_epoch_num):\n",
    "                    self.node_count_seen = 0\n",
    "                    self.accumulated_training_loss = 0\n",
    "\n",
    "                    # record the current overall epoch index:\n",
    "                    real_epoch_num = 1 + mini_epoch + mini_epoch_num * epoch_part # real_epoch_num starts from 0, therefore we add 1\n",
    "\n",
    "                    self.optimizer.zero_grad()\n",
    "                    batch_ave_loss, node_count = self.do_forward_pass(tr_train_nodes, tr_edges, tr_features, tr_target)\n",
    "                    batch_ave_loss.backward()\n",
    "                    self.optimizer.step()\n",
    "                    ave_loss = self.update_average_loss(batch_ave_loss, node_count)\n",
    "                    self.record_ave_training_loss.append(ave_loss)\n",
    "\n",
    "                    # at this point finish a single train duration: update the parameter and calcualte the loss function\n",
    "                    # periodically output the F1-score in the middle of the training process\n",
    "                    if real_epoch_num % output_period == 0:\n",
    "                        investigate_f1[real_epoch_num], investigate_accuracy[real_epoch_num] = self.middle_check_whole_cpu_validate(minibatch_data_validation)\n",
    "#                             self.model.train()    # reset to the train mode\n",
    "            \n",
    "        # convert to ms\n",
    "        print('*** During training, reading all batch file I/O costed {0:.2f} ms ***'.format(total_data_IO_time) )\n",
    "        self.time_train_total = ((time.time() - t0) * 1000) - total_data_IO_time\n",
    "        return investigate_f1, investigate_accuracy\n",
    "    \n",
    "    # iterate through epoch and also the clusters\n",
    "    def train(self, epoch_num=10, learning_rate=0.01, weight_decay = 0.01, mini_epoch_num = 1, train_batch_num = 2):\n",
    "        \"\"\"\n",
    "            *** Training a model. ***\n",
    "            epoch_num:  number of total training epoch number\n",
    "            learning rate: learning rate during training\n",
    "            weight_decay:  decay coefficients for the regularization\n",
    "            mini_epoch_num:  number of epochs of repeating training after loading data on the GPU\n",
    "        \"\"\"\n",
    "        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        self.model.train()\n",
    "        self.record_ave_training_loss = []\n",
    "        # record the data uploading to GPU time, and the data IO time for each train batch\n",
    "        self.time_train_load_data = 0\n",
    "        total_data_IO_time = 0\n",
    "        \n",
    "        epoch_partition = epoch_num // mini_epoch_num\n",
    "        t0 = time.time()\n",
    "        train_clusters = list(range(train_batch_num))\n",
    "        for epoch in range(epoch_partition):\n",
    "#             For test purpose, we let the clusters to follow specific order\n",
    "            random.shuffle(train_clusters)\n",
    "            \n",
    "            for cluster in train_clusters:\n",
    "                # read in the train data from the pickle files\n",
    "                batch_file_name = self.data_folder + 'train/batch_' + str(cluster)\n",
    "                \n",
    "                t2 = time.time()\n",
    "                with open(batch_file_name, \"rb\") as fp:\n",
    "                    minibatch_data_train = pickle.load(fp)\n",
    "                total_data_IO_time += (time.time() - t2) * 1000\n",
    "                \n",
    "                tr_train_nodes, tr_edges, tr_features, tr_target = minibatch_data_train\n",
    "                \n",
    "                # for each cluster, we load once and train it for multiple epochs:\n",
    "                t1 = time.time()\n",
    "                tr_train_nodes = tr_train_nodes.to(self.device)\n",
    "                tr_edges = tr_edges.to(self.device)\n",
    "                tr_features = tr_features.to(self.device)\n",
    "                tr_target = tr_target.to(self.device)\n",
    "                \n",
    "                self.time_train_load_data += (time.time() - t1) * 1000\n",
    "                # train each batch for multiple epochs\n",
    "                for mini_epoch in range(mini_epoch_num):\n",
    "                    self.node_count_seen = 0\n",
    "                    self.accumulated_training_loss = 0\n",
    "                    \n",
    "                    self.optimizer.zero_grad()\n",
    "                    batch_ave_loss, node_count = self.do_forward_pass(tr_train_nodes, tr_edges, tr_features, tr_target)\n",
    "                    batch_ave_loss.backward()\n",
    "                    self.optimizer.step()\n",
    "                    ave_loss = self.update_average_loss(batch_ave_loss, node_count)\n",
    "                    # record training loss per epoch\n",
    "                    self.record_ave_training_loss.append(ave_loss)\n",
    "            \n",
    "        # convert to ms\n",
    "        print('*** During training, total IO data reading time for all batches costed {0:.2f} ms ***'.format(total_data_IO_time) )\n",
    "        self.time_train_total = ((time.time() - t0) * 1000) - total_data_IO_time\n",
    "    \n",
    "    \n",
    "    def whole_cpu_validate(self):\n",
    "        \"\"\"\n",
    "        Scoring the test and printing the F-1 score.\n",
    "        \"\"\"\n",
    "        self.test_device = torch.device(\"cpu\")\n",
    "        test_model = self.model.to(self.test_device)\n",
    "        test_model.eval()   # set into test mode, only effective for certain modules such as dropout and batchNorm\n",
    "        \n",
    "        batch_file_name = self.data_folder + 'validation/batch_whole'\n",
    "\n",
    "        t2 = time.time()\n",
    "        with open(batch_file_name, \"rb\") as fp:\n",
    "            minibatch_data_validation = pickle.load(fp)\n",
    "        read_time = (time.time() - t2) * 1000\n",
    "        print('*** During validation for # {0} batch, reading batch file costed {1:.2f} ms ***'.format(\"whole graph\", read_time) )\n",
    "\n",
    "        valid_validation_nodes, valid_edges, valid_features, valid_target = minibatch_data_validation\n",
    "        \n",
    "        # select the testing nodes predictions and real labels\n",
    "        y_pred = test_model(valid_edges, valid_features)[valid_validation_nodes]\n",
    "        # for multi-label task, first use the sigmoid function and rounding to 0, 1.0 labels\n",
    "        y_pred_tag = (torch.sigmoid(y_pred)).round()\n",
    "        predictions = y_pred_tag.cpu().detach().numpy()\n",
    "        \n",
    "        targets = valid_target[valid_validation_nodes].cpu().detach().numpy()\n",
    "        \n",
    "        f1 = f1_score(targets, predictions, average=\"micro\")\n",
    "#       accuracy = accuracy_score(targets.flatten(), predictions.flatten())   # for multi-class task, here have to be flatten first\n",
    "        accuracy = binary_acc(targets, predictions)    # for multi-label task\n",
    "#         print(\"\\nTest F-1 score: {:.4f}\".format(score))\n",
    "        return (f1, accuracy)\n",
    "    \n",
    "    \n",
    "    def middle_check_whole_cpu_validate(self, minibatch_data_validation):\n",
    "        \"\"\"\n",
    "        Scoring the test and printing the F-1 score.\n",
    "        \"\"\"\n",
    "        test_model = copy.deepcopy(self.model)\n",
    "        test_model = test_model.to(self.test_device)\n",
    "        test_model.eval()   # set into test mode, only effective for certain modules such as dropout and batchNorm\n",
    "        \n",
    "\n",
    "        valid_validation_nodes, valid_edges, valid_features, valid_target = minibatch_data_validation\n",
    "\n",
    "        # select the testing nodes predictions and real labels\n",
    "        y_pred = test_model(valid_edges, valid_features)[valid_validation_nodes]\n",
    "        # for multi-label task, first use the sigmoid function and rounding to 0, 1.0 labels\n",
    "        y_pred_tag = (torch.sigmoid(y_pred)).round()\n",
    "        predictions = y_pred_tag.cpu().detach().numpy()\n",
    "        \n",
    "        targets = valid_target[valid_validation_nodes].cpu().detach().numpy()\n",
    "        \n",
    "        f1 = f1_score(targets, predictions, average=\"micro\")\n",
    "#         accuracy = accuracy_score(targets.flatten(), predictions.flatten())\n",
    "        accuracy = binary_acc(targets, predictions)\n",
    "#         print(\"\\nTest F-1 score: {:.4f}\".format(score))\n",
    "        return (f1, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Trivial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 2.],\n",
      "        [0., 3.],\n",
      "        [0., 4.],\n",
      "        [0., 5.],\n",
      "        [0., 6.],\n",
      "        [0., 7.],\n",
      "        [0., 8.],\n",
      "        [0., 9.]]) torch.Size([10, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/ipykernel_launcher.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "'''Trivial data'''\n",
    "edge_index = torch.tensor([[0, 1, 1, 3, 1, 2, 4, 2, 4, 6, 6, 7, 7, 9, 2, 5, 9, 8], \n",
    "                           [1, 0, 3, 1, 2, 1, 2, 4, 6, 4, 7, 6, 9, 7, 5, 2, 8, 9]])\n",
    "# features = torch.rand(10, 3)\n",
    "features = torch.tensor([[0, 0], [0, 1], [0, 2], [0, 3], [0, 4],  \n",
    "                           [0, 5], [0, 6], [0, 7], [0, 8], [0, 9]], dtype = torch.float)\n",
    "# label = torch.tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "label = torch.tensor([[0, 1], [1, 0], [1, 1], [1, 0], [0, 0], [0, 1], [1, 0], [1, 1], [1, 0], [0, 0]], dtype = torch.float)\n",
    "print(features, features.shape)\n",
    "\n",
    "# set the tmp folder\n",
    "# tmp_folder = './tmp/'\n",
    "# check_folder_exist(tmp_folder)\n",
    "# os.makedirs(os.path.dirname(tmp_folder), exist_ok=True)\n",
    "# set the store clustering path\n",
    "tmp_folder = './res_save_batch/tmp/'\n",
    "check_folder_exist(tmp_folder)\n",
    "clustering_file_name = tmp_folder + 'check_clustering_machine.txt'\n",
    "os.makedirs(os.path.dirname(tmp_folder), exist_ok=True)\n",
    "info_folder = './res_save_batch/info/'\n",
    "check_folder_exist(info_folder)\n",
    "os.makedirs(os.path.dirname(info_folder), exist_ok=True)\n",
    "\n",
    "\n",
    "node_count = features.shape[0]\n",
    "clustering_machine = ClusteringMachine(edge_index, features, label)\n",
    "clustering_machine.split_cluster_nodes_edges(0.4, 0.4, mini_cluster_num = 2)\n",
    "output_GPU_memory_usage('Memory_use.txt', info_folder, comment ='after split: ')\n",
    "\n",
    "with open(clustering_file_name, \"wb\") as fp:\n",
    "    pickle.dump(clustering_machine, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### minibatch train nodes and batch validatioin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Generate batch file for #   0 batch, writing the batch file costed 0.58 ms ***\n",
      "*** Generate batch file for #   1 batch, writing the batch file costed 0.58 ms ***\n",
      "*** Generate batch file for # whole graph batch, writing the batch file costed 0.44 ms ***\n",
      "*** During training, total IO data reading time for all batches costed 1.02 ms ***\n",
      "*** During validation for # whole graph batch, reading batch file costed 0.29 ms ***\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mini_batch_folder = './res_save_batch/mini_batch_files/'\n",
    "check_folder_exist(mini_batch_folder)\n",
    "\n",
    "with open(clustering_file_name, \"rb\") as fp:\n",
    "    clustering_machine = pickle.load(fp)\n",
    "\n",
    "# generate the batches for train and validation\n",
    "clustering_machine.mini_batch_train_clustering(mini_batch_folder, batch_range = (0, 2), info_folder = info_folder) # include number of layers\n",
    "output_GPU_memory_usage('Memory_use.txt', info_folder, comment ='after train clustering: ')\n",
    "\n",
    "clustering_machine.whole_validation_clustering(mini_batch_folder, info_folder = info_folder)\n",
    "output_GPU_memory_usage('Memory_use.txt', info_folder, comment ='after validation clustering:  ')\n",
    "\n",
    "# construct the batch trainer\n",
    "gcn_trainer_batch = ClusterGCNTrainer_mini_Train(mini_batch_folder, 2, 2, input_layers = [16], dropout=0.3)\n",
    "\n",
    "output_GPU_memory_usage('Memory_use.txt', info_folder, comment = 'after generating trainer:  ')\n",
    "\n",
    "gcn_trainer_batch.train(1, 0.0001, 0.1, train_batch_num = 2)\n",
    "\n",
    "output_GPU_memory_usage('Memory_use.txt', info_folder, comment = 'after training the batch:  ')\n",
    "\n",
    "# gcn_trainer_batch.batch_validate(valid_batch_num = 2)\n",
    "\n",
    "gcn_trainer_batch.whole_cpu_validate()\n",
    "\n",
    "output_GPU_memory_usage('Memory_use.txt', info_folder, comment = 'after validating the batch:  ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### basic execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Execute the testing program '''\n",
    "def set_clustering_machine(data, dataset, intermediate_data_folder, validation_ratio = 0.05, test_ratio = 0.85, train_batch_num = 2, mini_cluster_num = 16, round_num = 2):\n",
    "    \"\"\"\n",
    "        Set the batch machine plus generate the training batches\n",
    "            1) data: the target dataset data\n",
    "            2) intermediate_data_folder: path to store the intermediate generated data\n",
    "            3) test_ratio, validation_ratio: data split ratio\n",
    "            4) neigh_layer: number of hops (layers) for the neighbor nodes \n",
    "            5) train_frac: each time including fraction of the neigbor nodes in each layer\n",
    "            6) valid_part_num, train_batch_num, test_part_num :  batch number for validation, train and test data correspondingly\n",
    "    \"\"\"\n",
    "    # set the tmp file for garbage tmp files, just collect the info:\n",
    "    tmp_folder = intermediate_data_folder + 'tmp/'\n",
    "    check_folder_exist(tmp_folder)\n",
    "    os.makedirs(os.path.dirname(tmp_folder), exist_ok=True)\n",
    "    \n",
    "    # Set the clustering information storing path\n",
    "    clustering_file_folder = intermediate_data_folder + 'clustering/'\n",
    "    data_info_file_folder = intermediate_data_folder + 'data_info/'\n",
    "    check_folder_exist(clustering_file_folder)  # if exist then delete\n",
    "    check_folder_exist(data_info_file_folder)  # if exist then delete\n",
    "    \n",
    "    clustering_file_name = clustering_file_folder + 'clustering_machine.txt'\n",
    "    data_info_file_name = data_info_file_folder + 'data_info_file.txt'\n",
    "    os.makedirs(os.path.dirname(clustering_file_folder), exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(data_info_file_folder), exist_ok=True)\n",
    "    \n",
    "\n",
    "    print('\\n' + '=' * 100)\n",
    "    print('Start to generate the clustering machine:')\n",
    "    t0 = time.time()\n",
    "    # if we use the random assignment of the code, then filtering out the isolated data may not be necessary\n",
    "    connect_edge_index, connect_features, connect_label = filter_out_isolate(data.edge_index, data.x, data.y)\n",
    "    clustering_machine = ClusteringMachine(connect_edge_index, connect_features, connect_label, tmp_folder)\n",
    "    \n",
    "#     clustering_machine = ClusteringMachine(data.edge_index, data.x, data.y, tmp_folder)\n",
    "    batch_machine_create = time.time() - t0\n",
    "    print('Batch machine creation costs a total of {0:.4f} seconds!'.format(batch_machine_create))\n",
    "    \n",
    "    node_count = connect_features.shape[0]\n",
    "    feature_count = connect_features.shape[1]    # features all always in the columns\n",
    "    edge_count = connect_edge_index.shape[1]\n",
    "    print('\\nEdge number: ', edge_count, '\\nNode number: ', node_count, '\\nFeature number: ', feature_count) \n",
    "    \n",
    "    # at last output the information inside the folder:\n",
    "    print_dir_content_info(tmp_folder)\n",
    "    \n",
    "#     clustering_machine.split_cluster_nodes_edges(test_ratio, validation_ratio, partition_num = train_batch_num)\n",
    "    # mini-batch only: split to train test valid before clustering\n",
    "    print('Start to split data into train, test, validation:')\n",
    "    t1 = time.time()\n",
    "    clustering_machine.split_cluster_nodes_edges(validation_ratio, test_ratio, mini_cluster_num = mini_cluster_num, train_batch_num = train_batch_num, round_num = round_num)\n",
    "    data_split_time = time.time() - t1\n",
    "    print('Data splitting costs a total of {0:.4f} seconds!'.format(data_split_time))\n",
    "    \n",
    "    print('Start to store the batch machine file:')\n",
    "    t3 = time.time()\n",
    "    with open(clustering_file_name, \"wb\") as fp:\n",
    "        pickle.dump(clustering_machine, fp)\n",
    "    \n",
    "    # data number we requred are the feature number and the classes, note after the filtering, the node number may be smaller by removing isolated nodes\n",
    "    data_info = (dataset.num_node_features, dataset.num_classes )\n",
    "    with open(data_info_file_name, \"wb\") as fp:\n",
    "        pickle.dump(data_info, fp)\n",
    "\n",
    "    batch_machine_store_time = time.time() - t3\n",
    "    print('Storing batch machine after training batches generation costs a total of {0:.4f} seconds!'.format(batch_machine_store_time))\n",
    "    print('\\n' + '=' * 100)\n",
    "    # output the memory usage information\n",
    "    info_GPU_memory_folder = intermediate_data_folder + 'info_GPU_memory/'\n",
    "    output_GPU_memory_usage('Memory_use_setting_cluster.txt', info_GPU_memory_folder, comment ='after setting clustering machine: ')\n",
    "    \n",
    "def set_clustering_machine_train_batch(intermediate_data_folder, \\\n",
    "                                      batch_range = (0, 1), info_folder = 'info_train_batch/', info_file = 'train_batch_size_info.csv'):\n",
    "    \"\"\"\n",
    "        Generate the train batches\n",
    "    \"\"\"\n",
    "    clustering_file_folder = intermediate_data_folder + 'clustering/'\n",
    "    clustering_file_name = clustering_file_folder + 'clustering_machine.txt'\n",
    "    print('\\n' + '=' * 100)\n",
    "    \n",
    "    t0 = time.time()\n",
    "    with open(clustering_file_name, \"rb\") as fp:\n",
    "        clustering_machine = pickle.load(fp)\n",
    "    batch_machine_read = time.time() - t0\n",
    "    print('Batch machine reading costs a total of {0:.4f} seconds!'.format(batch_machine_read))\n",
    "    \n",
    "#     check_folder_exist(intermediate_data_folder)  # if exist then delete\n",
    "    print('Start to generate the training batches:')\n",
    "    info_folder = intermediate_data_folder + info_folder\n",
    "    os.makedirs(os.path.dirname(info_folder), exist_ok=True)\n",
    "    t2 = time.time()\n",
    "    clustering_machine.mini_batch_train_clustering(intermediate_data_folder, \\\n",
    "                                                   batch_range = batch_range, info_folder = info_folder, info_file = info_file)\n",
    "    train_batch_production_time = time.time() - t2\n",
    "    print('Train batches production costs a total of {0:.4f} seconds!'.format(train_batch_production_time))\n",
    "    print_dir_content_info(intermediate_data_folder + 'train/')\n",
    "    print('=' * 100)\n",
    "    # output the memory usage information\n",
    "    info_GPU_memory_folder = intermediate_data_folder + 'info_GPU_memory/'\n",
    "    output_GPU_memory_usage('GPU_cost_setting_train_batch.txt', info_GPU_memory_folder, comment ='after generating train batches: ')\n",
    "\n",
    "def set_clustering_machine_validation_whole_graph(intermediate_data_folder, \\\n",
    "                                                  info_folder = 'info_validation_whole_graph/', info_file = 'validation_whole_graph_size_info.csv'):\n",
    "    \"\"\"\n",
    "        Generate the validation batches\n",
    "    \"\"\"\n",
    "    clustering_file_folder = intermediate_data_folder + 'clustering/'\n",
    "    clustering_file_name = clustering_file_folder + 'clustering_machine.txt'\n",
    "    print('\\n' + '=' * 100)\n",
    "    \n",
    "    t0 = time.time()\n",
    "    with open(clustering_file_name, \"rb\") as fp:\n",
    "        clustering_machine = pickle.load(fp)\n",
    "    batch_machine_read = time.time() - t0\n",
    "    print('Batch machine reading costs a total of {0:.4f} seconds!'.format(batch_machine_read))\n",
    "    \n",
    "    print('Start to generate the validation whole graph:')\n",
    "    info_folder = intermediate_data_folder + info_folder\n",
    "    os.makedirs(os.path.dirname(info_folder), exist_ok=True)\n",
    "    t1 = time.time()\n",
    "    # create the validation batch for the whole graph\n",
    "    clustering_machine.whole_validation_clustering(intermediate_data_folder, info_folder = info_folder)\n",
    "    \n",
    "    validation_batch_production_time = time.time() - t1\n",
    "    print('Validation batches production costs a total of {0:.4f} seconds!'.format(validation_batch_production_time))\n",
    "    print_dir_content_info(intermediate_data_folder + 'validation/')\n",
    "    print('=' * 100)\n",
    "    # output the memory usage information\n",
    "    info_GPU_memory_folder = intermediate_data_folder + 'info_GPU_memory/'\n",
    "    output_GPU_memory_usage('GPU_memory_cost_generate_validatoin_data.txt', info_GPU_memory_folder, comment ='after generating validation for whole graph: ')\n",
    "\n",
    "def Cluster_train_batch_run(trainer_id, intermediate_data_folder, input_layer = [16, 16], epochs=300, \\\n",
    "                           dropout = 0.3, lr = 0.01, weight_decay = 0.01, mini_epoch_num = 5, \\\n",
    "                                 train_batch_num = 2, test_part_num = 1):\n",
    "    \"\"\"\n",
    "    # Run the mini-batch model (train and validate both in batches)\n",
    "    Tuning parameters:  dropout, lr (learning rate), weight_decay: l2 regularization\n",
    "    return: validation accuracy value, validation F-1 value, time_training (ms), time_data_load (ms)\n",
    "    \"\"\"\n",
    "    data_info_file_folder = intermediate_data_folder + 'data_info/'\n",
    "    data_info_file = data_info_file_folder + 'data_info_file.txt'\n",
    "    with open(data_info_file, \"rb\") as fp:\n",
    "        num_node_features, num_classes = pickle.load(fp)\n",
    "        \n",
    "    print('\\n' + '=' * 100)\n",
    "    print('Start generate the trainer:')\n",
    "    t0 = time.time()\n",
    "    gcn_trainer = ClusterGCNTrainer_mini_Train(intermediate_data_folder, num_node_features, num_classes, input_layers = input_layer, dropout = dropout)\n",
    "    train_create = time.time() - t0\n",
    "    print('Trainer creation costs a total of {0:.4f} seconds!'.format(train_create))\n",
    "    \n",
    "    print('Start train the model:')\n",
    "    t1 = time.time()\n",
    "    gcn_trainer.train(epoch_num=epochs, learning_rate=lr, weight_decay=weight_decay, mini_epoch_num = mini_epoch_num, train_batch_num = train_batch_num)\n",
    "    train_period = time.time() - t1\n",
    "    print('Training costs a total of {0:.4f} seconds!'.format(train_period))\n",
    "    \n",
    "    print('Start to save the GCN trainer model (parameters: weights, bias):')\n",
    "    trainer_file_name = intermediate_data_folder + 'GCNtrainer/GCN_trainer_' + str(trainer_id)\n",
    "    t2 = time.time()\n",
    "    with open(trainer_file_name, \"wb\") as fp:\n",
    "        pickle.dump(gcn_trainer, fp)\n",
    "    store_trainer = time.time() - t2\n",
    "    print('Storing the trainer costs a total of {0:.4f} seconds!'.format(store_trainer))\n",
    "    print('-' * 80)\n",
    "    info_GPU_memory_folder = intermediate_data_folder + 'info_GPU_memory/'\n",
    "    output_GPU_memory_usage('Memory_use_batch_train.txt', info_GPU_memory_folder, comment ='after generating trainer and train minibatches: ')\n",
    "\n",
    "\n",
    "def Cluster_valid_batch_run(trainer_id, intermediate_data_folder):\n",
    "    print('Start to read the GCN trainer model (parameters: weights, bias):')\n",
    "    trainer_file_name = intermediate_data_folder + 'GCNtrainer/GCN_trainer_' + str(trainer_id)\n",
    "    t1 = time.time()\n",
    "    with open(trainer_file_name, \"rb\") as fp:\n",
    "        gcn_trainer = pickle.load(fp)\n",
    "    read_trainer = (time.time() - t1) * 1000\n",
    "    print('Reading the trainer costs a total of {0:.4f} seconds!'.format(read_trainer))\n",
    "    \n",
    "    print('Start validate the model:')\n",
    "    t2 = time.time()\n",
    "#     validation_F1, validation_accuracy = gcn_trainer.batch_validate(valid_batch_num = valid_part_num)\n",
    "    validation_F1, validation_accuracy = gcn_trainer.whole_cpu_validate()\n",
    "    validation_period = time.time() - t2\n",
    "    print('Validatoin costs a total of {0:.4f} seconds!'.format(validation_period))\n",
    "    print('=' * 100)\n",
    "    time_train_total = gcn_trainer.time_train_total\n",
    "    time_data_load = gcn_trainer.time_train_load_data\n",
    "    \n",
    "    info_GPU_memory_folder = intermediate_data_folder + 'info_GPU_memory/'\n",
    "    output_GPU_memory_usage('Memory_use_run_cpu_validation.txt', info_GPU_memory_folder, comment ='after validating minibatches: ')\n",
    "    \n",
    "    return validation_accuracy, validation_F1, time_train_total, time_data_load\n",
    "\n",
    "\n",
    "def Cluster_tune_train_run(intermediate_data_folder, input_layer = [16, 16], epochs=300, \\\n",
    "                           dropout = 0.3, lr = 0.01, weight_decay = 0.01, mini_epoch_num = 5, \\\n",
    "                                 train_batch_num = 2):\n",
    "    \"\"\"\n",
    "    # Run the mini-batch model (train and validate both in batches)\n",
    "    Tuning parameters:  dropout, lr (learning rate), weight_decay: l2 regularization\n",
    "    return: validation accuracy value, validation F-1 value, time_training (ms), time_data_load (ms)\n",
    "    \"\"\"\n",
    "    data_info_file_folder = intermediate_data_folder + 'data_info/'\n",
    "    data_info_file = data_info_file_folder + 'data_info_file.txt'\n",
    "    with open(data_info_file, \"rb\") as fp:\n",
    "        num_node_features, num_classes = pickle.load(fp)\n",
    "    \n",
    "    print('\\n' + '=' * 100)\n",
    "    print('Start generate the trainer:')\n",
    "    t0 = time.time()\n",
    "    gcn_trainer = ClusterGCNTrainer_mini_Train(intermediate_data_folder, num_node_features, num_classes, input_layers = input_layer, dropout = dropout)\n",
    "    train_create = time.time() - t0\n",
    "    print('Trainer creation costs a total of {0:.4f} seconds!'.format(train_create))\n",
    "    \n",
    "    print('Start train the model:')\n",
    "    t1 = time.time()\n",
    "    gcn_trainer.train(epoch_num=epochs, learning_rate=lr, weight_decay=weight_decay, mini_epoch_num = mini_epoch_num, train_batch_num = train_batch_num)\n",
    "    train_period = time.time() - t1\n",
    "    print('Training costs a total of {0:.4f} seconds!'.format(train_period))\n",
    "    print('-' * 80)\n",
    "    \n",
    "    info_GPU_memory_folder = intermediate_data_folder + 'info_GPU_memory/'\n",
    "    output_GPU_memory_usage('Memory_use_tune_batch_train.txt', info_GPU_memory_folder, comment ='after tune training: ')\n",
    "    \n",
    "    return gcn_trainer\n",
    "    \n",
    "    \n",
    "def Cluster_tune_validation_run(gcn_trainer, intermediate_data_folder):\n",
    "    \n",
    "    print('Start validate the model:')\n",
    "    t2 = time.time()\n",
    "    validation_F1, validation_accuracy = gcn_trainer.whole_cpu_validate()\n",
    "    \n",
    "    validation_period = time.time() - t2\n",
    "    print('Validatoin costs a total of {0:.4f} seconds!'.format(validation_period))\n",
    "    print('=' * 100)\n",
    "    time_train_total = gcn_trainer.time_train_total\n",
    "    time_data_load = gcn_trainer.time_train_load_data\n",
    "    \n",
    "    info_GPU_memory_folder = intermediate_data_folder + 'info_GPU_memory/'\n",
    "    output_GPU_memory_usage('Memory_use_tune_whole_validation.txt', info_GPU_memory_folder, comment ='after validation whole graph: ')\n",
    "    return validation_accuracy, validation_F1, time_train_total, time_data_load\n",
    "\n",
    "\n",
    "def Cluster_train_valid_batch_investigate(intermediate_data_folder, input_layer = [16, 16], epochs=300, \\\n",
    "                           dropout = 0.3, lr = 0.01, weight_decay = 0.01, mini_epoch_num = 5, output_period = 10, \n",
    "                                         train_part_num = 2):\n",
    "    \"\"\"\n",
    "        *** dynamically investigate the F1 score in the middle of the training after certain period ***\n",
    "        output: two dict containing F1-score and accuracy of a certain epoch index\n",
    "    \"\"\"\n",
    "    data_info_file_folder = intermediate_data_folder + 'data_info/'\n",
    "    data_info_file = data_info_file_folder + 'data_info_file.txt'\n",
    "    with open(data_info_file, \"rb\") as fp:\n",
    "        num_node_features, num_classes = pickle.load(fp)\n",
    "    \n",
    "    print('\\n' + '=' * 100)\n",
    "    print('Start generate the trainer:')\n",
    "    t0 = time.time()\n",
    "    gcn_trainer = ClusterGCNTrainer_mini_Train(intermediate_data_folder, num_node_features, num_classes, input_layers = input_layer, dropout = dropout)\n",
    "    train_create = time.time() - t0\n",
    "    print('Trainer creation costs a total of {0:.4f} seconds!'.format(train_create))\n",
    "    \n",
    "    print('Start train the model:')\n",
    "    t1 = time.time()\n",
    "    Train_period_F1, Train_period_accuracy = gcn_trainer.train_investigate_F1(epoch_num=epochs, learning_rate=lr, weight_decay=weight_decay, mini_epoch_num = mini_epoch_num, \\\n",
    "                                                            output_period = output_period, train_batch_num = train_part_num)\n",
    "    train_period = time.time() - t1\n",
    "    print('Training costs a total of {0:.4f} seconds!'.format(train_period))\n",
    "    print('-' * 80)\n",
    "    info_GPU_memory_folder = intermediate_data_folder + 'info_GPU_memory/'\n",
    "    output_GPU_memory_usage('Memory_use_train_batch_investigate.txt', info_GPU_memory_folder, comment ='after train batch investigate: ')\n",
    "    \n",
    "    return Train_period_F1, Train_period_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test and compare different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_one_train(mini_batch_folder, trainer_id = 0, input_layer = [32], epoch_num = 300, \\\n",
    "                dropout = 0.3, lr = 0.0001, weight_decay = 0.01, mini_epoch_num = 5, \\\n",
    "                train_batch_num = 2):\n",
    "    \"\"\"\n",
    "        Perform one train for one time, store the corresponding trainer for future testing\n",
    "    \"\"\"\n",
    "    Trainer_folder = mini_batch_folder + 'GCNtrainer/'\n",
    "#     check_folder_exist(Trainer_folder)\n",
    "    os.makedirs(os.path.dirname(Trainer_folder), exist_ok=True)\n",
    "#     graph_model = ['batch_valid', 'train_batch', 'whole_graph', 'isolate']\n",
    "    Cluster_train_batch_run(trainer_id, mini_batch_folder, input_layer = input_layer, epochs=epoch_num, \\\n",
    "                             dropout = dropout, lr = lr, weight_decay = weight_decay, mini_epoch_num = mini_epoch_num, \\\n",
    "                             train_batch_num = train_batch_num)\n",
    "    \n",
    "def execute_one_validation(mini_batch_folder, trainer_list = [0]):\n",
    "    \"\"\"\n",
    "        return all test-F1 and validation-F1 for all four models\n",
    "    \"\"\"\n",
    "    validation_accuracy = {}\n",
    "    validation_f1 = {}\n",
    "    time_total_train = {}\n",
    "    time_data_load = {}\n",
    "    \n",
    "    # Each graph model corresponds to one function below\n",
    "#     graph_model = ['batch_valid', 'train_batch', 'whole_graph', 'isolate']\n",
    "    graph_model = ['batch_valid']\n",
    "    for trainer_id in trainer_list:\n",
    "        model_res = []\n",
    "        model_res.append(Cluster_valid_batch_run(trainer_id, mini_batch_folder))\n",
    "        \n",
    "        validation_accuracy[trainer_id], validation_f1[trainer_id], time_total_train[trainer_id], time_data_load[trainer_id] = zip(*model_res)\n",
    "    return graph_model, validation_accuracy, validation_f1, time_total_train, time_data_load\n",
    "\n",
    "def store_data_multi_tests(f1_data, data_name, graph_model, img_path, comments):\n",
    "    run_id = sorted(f1_data.keys())\n",
    "    run_data = {'run_id': run_id}\n",
    "    \n",
    "    run_data.update({model_name : [f1_data[key][idx] for key in run_id] for idx, model_name in enumerate(graph_model)})\n",
    "    \n",
    "    pickle_filename = img_path + data_name + '_' + comments + '.pkl'\n",
    "    os.makedirs(os.path.dirname(pickle_filename), exist_ok=True)\n",
    "    df = pd.DataFrame(data=run_data, dtype=np.int32)\n",
    "    df.to_pickle(pickle_filename)\n",
    "    return pickle_filename\n",
    "\n",
    "def draw_data_multi_tests(pickle_filename, data_name, comments, xlabel, ylabel):\n",
    "    df = pd.read_pickle(pickle_filename)\n",
    "    df_reshape = df.melt('run_id', var_name = 'model', value_name = ylabel)\n",
    "\n",
    "    plt.clf()\n",
    "    plt.figure()\n",
    "    sns.set(style='whitegrid')\n",
    "    g = sns.catplot(x=\"model\", y=ylabel, kind='box', data=df_reshape)\n",
    "    g.despine(left=True)\n",
    "    g.fig.suptitle(data_name + ' ' + ylabel + ' ' + comments)\n",
    "    g.set_xlabels(xlabel)\n",
    "    g.set_ylabels(ylabel)\n",
    "\n",
    "    img_name = pickle_filename[:-4] + '_img'\n",
    "    \n",
    "    os.makedirs(os.path.dirname(img_name), exist_ok=True)\n",
    "    plt.savefig(img_name, bbox_inches='tight')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  To test one single model for different parameter values \n",
    "def execute_tuning_train(mini_batch_folder, tune_param_name, tune_val_label, tune_val, trainer_id = 0, input_layer = [32], epoch_num = 400, \\\n",
    "                  dropout = 0.1, lr = 0.0001, weight_decay = 0.1, mini_epoch_num = 20, \\\n",
    "                  train_batch_num = 2):\n",
    "    \"\"\"\n",
    "        Tune all the hyperparameters\n",
    "        1) learning rate\n",
    "        2) dropout\n",
    "        3) layer unit number\n",
    "        4) weight decay\n",
    "    \"\"\"\n",
    "    Trainer_folder = mini_batch_folder + 'GCN_tuning/tune_' + tune_param_name + '_' + str(tune_val_label) + '/'\n",
    "#     check_folder_exist(Trainer_folder)\n",
    "    os.makedirs(os.path.dirname(Trainer_folder), exist_ok=True)\n",
    "    \n",
    "    trainer_file_name = Trainer_folder + 'GCN_trainer_' + str(trainer_id)\n",
    "    \n",
    "    gcn_trainer = Cluster_tune_train_run(mini_batch_folder, input_layer = input_layer, epochs=epoch_num, \\\n",
    "                    dropout = dropout, lr = tune_val, weight_decay = weight_decay, mini_epoch_num = mini_epoch_num, \\\n",
    "                    train_batch_num = train_batch_num)\n",
    "    with open(trainer_file_name, \"wb\") as fp:\n",
    "        pickle.dump(gcn_trainer, fp)\n",
    "\n",
    "# this tuning validation requires the image_path to store all the results as the picle file\n",
    "def execute_tuning_validation(image_path, mini_batch_folder, tune_param_name, tune_val_label, tune_val, trainer_id = 0):\n",
    "    \n",
    "    Trainer_folder = mini_batch_folder + 'GCN_tuning/tune_' + tune_param_name + '_' + str(tune_val_label) + '/'\n",
    "    trainer_file_name = Trainer_folder + 'GCN_trainer_' + str(trainer_id)\n",
    "    \n",
    "    print('Start to read the GCN trainer model (parameters: weights, bias):')\n",
    "    t1 = time.time()\n",
    "    with open(trainer_file_name, \"rb\") as fp:\n",
    "        gcn_trainer = pickle.load(fp)\n",
    "    read_trainer = (time.time() - t1) * 1000\n",
    "    print('Reading the trainer costs a total of {0:.4f} seconds!'.format(read_trainer))\n",
    "    # res are: validation_accuracy, validation_F1, time_train_total, time_data_load\n",
    "    res = Cluster_tune_validation_run(gcn_trainer, mini_batch_folder)\n",
    "    \n",
    "    # store the resulting data on the disk\n",
    "    test_res_folder = image_path + 'test_res/tune_' + tune_param_name + '_' + str(tune_val_label) + '/'\n",
    "    os.makedirs(os.path.dirname(test_res_folder), exist_ok=True)\n",
    "    test_res_file = test_res_folder + 'res_trainer_' + str(trainer_id)\n",
    "    \n",
    "    with open(test_res_file, \"wb\") as fp:\n",
    "        pickle.dump(res, fp)\n",
    "        \n",
    "    \n",
    "def summarize_tuning_res(image_path, mini_batch_folder, tune_param_name, tune_val_label_list, tune_val_list, trainer_list):\n",
    "    \"\"\"\n",
    "        tune_val_label_list :  label of the tuning parameter value for file location\n",
    "        tune_val_list  :       the real value of the tuning parameter\n",
    "    \"\"\"\n",
    "    validation_accuracy = {}\n",
    "    validation_f1 = {}\n",
    "    time_total_train = {}\n",
    "    time_data_load = {}\n",
    "    \n",
    "    res = []\n",
    "    for trainer_id in trainer_list:\n",
    "        ref = {}\n",
    "        for tune_val_label, tune_val in zip(tune_val_label_list, tune_val_list):\n",
    "            test_res_folder = image_path + 'test_res/tune_' + tune_param_name + '_' + str(tune_val_label) + '/'\n",
    "            test_res_file = test_res_folder + 'res_trainer_' + str(trainer_id)\n",
    "            with open(test_res_file, \"rb\") as fp:\n",
    "                ref[tune_val] = pickle.load(fp)\n",
    "        res.append(ref)\n",
    "    \n",
    "    for i, ref in enumerate(res):\n",
    "        validation_accuracy[i] = {tune_val : res_lst[0] for tune_val, res_lst in ref.items()}\n",
    "        validation_f1[i] = {tune_val : res_lst[1] for tune_val, res_lst in ref.items()}\n",
    "        time_total_train[i] = {tune_val : res_lst[2] for tune_val, res_lst in ref.items()}\n",
    "        time_data_load[i] = {tune_val : res_lst[3] for tune_val, res_lst in ref.items()}\n",
    "        \n",
    "    return validation_accuracy, validation_f1, time_total_train, time_data_load\n",
    "\n",
    "\n",
    "def store_data_multi_tuning(tune_params, target, data_name, img_path, comments):\n",
    "    \"\"\"\n",
    "        tune_params: is the tuning parameter list\n",
    "        target: is the result, here should be F1-score, accuraycy, load time, train time\n",
    "    \"\"\"\n",
    "    run_ids = sorted(target.keys())   # key is the run_id\n",
    "    run_data = {'run_id': run_ids}\n",
    "    # the key can be converted to string or not: i.e. str(tune_val)\n",
    "    # here we keep it as integer such that we want it to follow order\n",
    "    tmp = {tune_val : [target[run_id][tune_val] for run_id in run_ids] for tune_val in tune_params}  # the value is list\n",
    "    run_data.update(tmp)\n",
    "    \n",
    "    pickle_filename = img_path + data_name + '_' + comments + '.pkl'\n",
    "    os.makedirs(os.path.dirname(pickle_filename), exist_ok=True)\n",
    "    df = pd.DataFrame(data=run_data, dtype=np.int32)\n",
    "    df.to_pickle(pickle_filename)\n",
    "    return pickle_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Investigate the F1 score during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ======== Investigate F1-score on the fly\n",
    "def execute_investigate(image_path, mini_batch_folder, tune_param_name, tune_val_label, tune_val, trainer_id = 0, input_layer = [32], epoch_num = 300, \\\n",
    "                        dropout = 0.3, lr = 0.0001, weight_decay = 0.01, mini_epoch_num = 20, output_period = 10, \\\n",
    "                         train_part_num = 2):\n",
    "    \"\"\"\n",
    "        return all test-F1 and validation-F1 for all four models\n",
    "    \"\"\"\n",
    "    Train_peroid_f1, Train_peroid_accuracy = Cluster_train_valid_batch_investigate(mini_batch_folder, input_layer = input_layer, epochs=epoch_num, \\\n",
    "                                        dropout = dropout, lr = tune_val, weight_decay = weight_decay, mini_epoch_num = mini_epoch_num, output_period = output_period, \\\n",
    "                                                                train_part_num = train_part_num)\n",
    "    \n",
    "    # store the resulting data on the disk\n",
    "    test_res_folder = image_path + 'tune_' + tune_param_name + '_' + str(tune_val_label) + '/'\n",
    "    os.makedirs(os.path.dirname(test_res_folder), exist_ok=True)\n",
    "    test_res_file = test_res_folder + 'res_trainer_' + str(trainer_id)\n",
    "    \n",
    "    with open(test_res_file, \"wb\") as fp:\n",
    "        pickle.dump((Train_peroid_f1, Train_peroid_accuracy), fp)\n",
    "        \n",
    "def summarize_investigation_res(image_path, mini_batch_folder, trainer_list):\n",
    "    Train_peroid_f1 = {}\n",
    "    Train_peroid_accuracy = {}\n",
    "    \n",
    "    for trainer_id in trainer_list:\n",
    "        ref = {}\n",
    "        test_res_file = image_path + 'res_trainer_' + str(trainer_id)\n",
    "        with open(test_res_file, \"rb\") as fp:\n",
    "            Train_peroid_f1[trainer_id], Train_peroid_accuracy[trainer_id] = pickle.load(fp)\n",
    "        \n",
    "    return Train_peroid_f1, Train_peroid_accuracy\n",
    "        \n",
    "def store_data_multi_investigate(investigate_res, data_name, res_name, img_path, comments):\n",
    "    \"\"\"\n",
    "        investigate_res: currently either F1-score or accuracy a dict {epoch num : value}\n",
    "    \"\"\"\n",
    "    run_id = sorted(investigate_res.keys())\n",
    "    run_data = {'run_id': run_id}\n",
    "    \n",
    "    epoch_num_range = sorted(investigate_res[0].keys())  # at least one entry exists inside the dictionary and the epoch range is fixed\n",
    "    run_data.update({epoch_num : [investigate_res[key][epoch_num] for key in run_id] for epoch_num in epoch_num_range})\n",
    "    \n",
    "    pickle_filename = img_path + data_name + '_' + res_name + '_' + comments + '.pkl'\n",
    "    os.makedirs(os.path.dirname(pickle_filename), exist_ok=True)\n",
    "    df = pd.DataFrame(data=run_data, dtype=np.int32)\n",
    "    df.to_pickle(pickle_filename)\n",
    "    return pickle_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate steps of HPC execution for one single task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step0_generate_clustering_machine(data, dataset, intermediate_data_path, train_batch_num, \\\n",
    "                                      validation_ratio = 0.05, test_ratio = 0.85, mini_cluster_num = 16, round_num = 2):            \n",
    "    print('Start running for train batch num: ' + str(train_batch_num) )\n",
    "\n",
    "    # set the basic settings for the future batches generation\n",
    "    set_clustering_machine(data, dataset, intermediate_data_path, validation_ratio = validation_ratio, test_ratio = test_ratio, \\\n",
    "                           train_batch_num = train_batch_num, mini_cluster_num = mini_cluster_num, round_num = round_num)\n",
    "\n",
    "def step1_generate_train_batch(intermediate_data_path, batch_range = (0, 1), info_folder = 'info/'):            \n",
    "    # set the save path\n",
    "    print('Start running for train batch num: ' + str(batch_range) )\n",
    "    info_file = 'train_batch_size_info_{}.csv'.format(str(batch_range))\n",
    "\n",
    "    # generate the train batches\n",
    "    set_clustering_machine_train_batch(intermediate_data_path, \\\n",
    "                                       batch_range = batch_range, info_folder = info_folder, info_file = info_file)\n",
    "\n",
    "def step2_generate_validation_whole_graph(intermediate_data_path, info_folder = 'info/'):            \n",
    "    info_file = 'validation_whole_graph_size_info.csv'\n",
    "    # generate all the tensors from the  whole graph for validation\n",
    "    set_clustering_machine_validation_whole_graph(intermediate_data_path, info_folder = info_folder, info_file = info_file)\n",
    "            \n",
    "def step3_run_train_batch(intermediate_data_path, train_batch_num, GCN_layer, \\\n",
    "                    trainer_id = 0, dropout = 0.1, lr = 0.0001, weight_decay = 0.1, mini_epoch_num = 20, epoch_num = 400):            \n",
    "    print('Start running training for train batch num: ' + str(train_batch_num))\n",
    "    # start to train the model\n",
    "    execute_one_train(intermediate_data_path, trainer_id = trainer_id, input_layer = GCN_layer, epoch_num = epoch_num, \n",
    "                                    dropout = dropout, lr = lr, weight_decay = weight_decay, mini_epoch_num = mini_epoch_num, \\\n",
    "                                     train_batch_num = train_batch_num)\n",
    "            \n",
    "\n",
    "def step4_run_validation_batch(image_data_path, intermediate_data_path, train_batch_num, net_layer_num, trainer_list = [0]):   \n",
    "    \"\"\"\n",
    "        image_data_path:  path of to be stored result images\n",
    "        intermediate_data_path :  path for all the intermediate results: clustering, train batches, trained trainers\n",
    "        train_batch_num:  number of generated overlapping batches\n",
    "        hop_layer:  number of to be included neighbor layers\n",
    "        trainer_list :  list of all the trained trainer (gcn model instance) indices\n",
    "    \"\"\"\n",
    "    # set the save path\n",
    "    print('Start running validation for train batch num: ' + str(train_batch_num) )\n",
    "    img_path = image_data_path + 'cluster_num_' + str(train_batch_num) + '/' + 'net_layer_num_' + str(net_layer_num) + '/'\n",
    "    img_path += 'output_f1_score/'  # further subfolder for different task\n",
    "\n",
    "    graph_model, validation_accuracy, validation_f1, time_total_train, time_data_load = \\\n",
    "        execute_one_validation(intermediate_data_path, trainer_list = trainer_list)\n",
    "\n",
    "    validation_accuracy = store_data_multi_tests(validation_accuracy, data_name, graph_model, img_path, 'test_cluster_num_' + str(train_batch_num) + 'net_layer_' + str(net_layer_num))\n",
    "    draw_data_multi_tests(validation_accuracy, data_name, 'vali_cluster_num_' + str(train_batch_num) + 'net_layer_' + str(net_layer_num), 'models', 'Accuracy')\n",
    "\n",
    "    validation_f1 = store_data_multi_tests(validation_f1, data_name, graph_model, img_path, 'validation_cluster_num_' + str(train_batch_num) + 'net_layer_' + str(net_layer_num) )\n",
    "    draw_data_multi_tests(validation_f1, data_name, 'vali_cluster_num_' + str(train_batch_num) + 'net_layer_' + str(net_layer_num), 'models', 'F1 score')\n",
    "\n",
    "    time_train = store_data_multi_tests(time_total_train, data_name, graph_model, img_path, 'train_time_cluster_num_' + str(train_batch_num) + 'net_layer_' + str(net_layer_num) )\n",
    "    draw_data_multi_tests(time_train, data_name, 'train_time_cluster_num_' + str(train_batch_num) + 'net_layer_' + str(net_layer_num), 'models', 'Train Time (ms)')\n",
    "\n",
    "    time_load = store_data_multi_tests(time_data_load, data_name, graph_model, img_path, 'load_time_cluster_num_' + str(train_batch_num) + 'net_layer_' + str(net_layer_num) )\n",
    "    draw_data_multi_tests(time_load, data_name, 'load_time_cluster_num_' + str(train_batch_num) + 'net_layer_' + str(net_layer_num), 'models', 'Load Time (ms)')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seperate steps for parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step30_run_tune_train_batch(intermediate_data_path, tune_param_name, tune_val_label, tune_val, train_batch_num, GCN_layer, \\\n",
    "                    trainer_id = 0, dropout = 0.1, lr = 0.0001, weight_decay = 0.1, mini_epoch_num = 20, epoch_num = 400):            \n",
    "    print('Start running training for partition num: ' + str(train_batch_num))\n",
    "    # start to tune the model, run different training \n",
    "    execute_tuning_train(intermediate_data_path, tune_param_name, tune_val_label, tune_val, trainer_id = trainer_id, input_layer = GCN_layer, epoch_num = epoch_num, \\\n",
    "                                    dropout = dropout, lr = lr, weight_decay = weight_decay, mini_epoch_num = mini_epoch_num, \\\n",
    "                                  train_batch_num = train_batch_num)\n",
    "            \n",
    "def step40_run_tune_validation_whole(image_data_path, intermediate_data_path, tune_param_name, tune_val_label, tune_val, train_batch_num, net_layer_num, \\\n",
    "                    trainer_id = 0): \n",
    "    # set the save path\n",
    "    print('Start running training for partition num: ' + str(train_batch_num) )\n",
    "    img_path = image_data_path + 'cluster_num_' + str(train_batch_num) + '/' + 'net_layer_num_' + str(net_layer_num) + '/'\n",
    "    img_path += 'tuning_parameters/'  # further subfolder for different task\n",
    "\n",
    "    # start to validate the model, with different tuning parameters\n",
    "    execute_tuning_validation(img_path, intermediate_data_path, tune_param_name, tune_val_label, tune_val, trainer_id = trainer_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate steps for investigation training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step31_run_investigation_train_batch(image_data_path, intermediate_data_path, tune_param_name, tune_val_label, tune_val, train_batch_num, net_layer_num, GCN_layer, \\\n",
    "                    trainer_id = 0, dropout = 0.1, lr = 0.0001, weight_decay = 0.1, mini_epoch_num = 20, epoch_num = 400, output_period = 40):            \n",
    "    # start to tune the model, and investigate the performance in the middle\n",
    "    print('Start running investigation training for train batch num: ' + str(train_batch_num) + '_trainer_id_' + str(trainer_id))\n",
    "    img_path = image_data_path + 'cluster_num_' + str(train_batch_num) + '/' + 'net_layer_num_' + str(net_layer_num) + '/'\n",
    "    img_path += 'investigation_figures/'  # further subfolder for different task\n",
    "\n",
    "    execute_investigate(img_path, intermediate_data_path, tune_param_name, tune_val_label, tune_val, trainer_id = trainer_id, input_layer = GCN_layer, epoch_num = epoch_num, \\\n",
    "                    dropout = dropout, lr = lr, weight_decay = weight_decay, mini_epoch_num = mini_epoch_num, output_period = output_period, \\\n",
    "                     train_part_num = train_batch_num)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step50_run_tune_summarize_whole(data_name, image_data_path, intermediate_data_path, tune_param_name, tune_val_label_list, tune_val_list, \\\n",
    "                                    train_batch_num, net_layer_num, trainer_list): \n",
    "    \n",
    "    print('Start running training for partition num: ' + str(train_batch_num))\n",
    "    # set the batch for validation and train\n",
    "    img_path = image_data_path + 'cluster_num_' + str(train_batch_num) + '/' + 'net_layer_num_' + str(net_layer_num) + '/'\n",
    "    img_path += 'tuning_parameters/'  # further subfolder for different task\n",
    "\n",
    "    # start to summarize the results into images for output\n",
    "\n",
    "    validation_accuracy, validation_f1, time_total_train, time_data_load = summarize_tuning_res(img_path, intermediate_data_path, tune_param_name, tune_val_label_list, tune_val_list, trainer_list)\n",
    "\n",
    "    generate_tuning_raw_data_table(validation_accuracy, img_path, 'test_acc.csv', tune_param_name)\n",
    "    validation_accuracy_file = store_data_multi_tuning(tune_val_list, validation_accuracy, data_name, img_path, 'accuracy_cluster_num_' + str(train_batch_num) + 'net_layer_num_' + str(net_layer_num))\n",
    "    draw_data_multi_tests(validation_accuracy_file, data_name, 'test_cluster_num_' + str(train_batch_num) + 'net_layer_num_' + str(net_layer_num), 'epochs_per_batch', 'Accuracy')\n",
    "\n",
    "    generate_tuning_raw_data_table(validation_f1, img_path, 'test_f1.csv', tune_param_name)\n",
    "    validation_f1_file = store_data_multi_tuning(tune_val_list, validation_f1, data_name, img_path, 'test_cluster_num_' + str(train_batch_num) + 'net_layer_num_' + str(net_layer_num))\n",
    "    draw_data_multi_tests(validation_f1_file, data_name, 'vali_cluster_num_' + str(train_batch_num) + 'net_layer_num_' + str(net_layer_num), 'epochs_per_batch', 'F1 score')\n",
    "\n",
    "    generate_tuning_raw_data_table(time_total_train, img_path, 'time_train_total.csv', tune_param_name)\n",
    "    time_train_file = store_data_multi_tuning(tune_val_list, time_total_train, data_name, img_path, 'train_time_cluster_num_' + str(train_batch_num) + 'net_layer_num_' + str(net_layer_num))\n",
    "    draw_data_multi_tests(time_train_file, data_name, 'train_time_cluster_num_' + str(train_batch_num) + 'net_layer_num_' + str(net_layer_num), 'epochs_per_batch', 'Train Time (ms)')\n",
    "\n",
    "    generate_tuning_raw_data_table(time_data_load, img_path, 'time_load_data.csv', tune_param_name)\n",
    "    time_load_file = store_data_multi_tuning(tune_val_list, time_data_load, data_name, img_path, 'load_time_cluster_num_' + str(train_batch_num) + 'net_layer_num_' + str(net_layer_num))\n",
    "    draw_data_multi_tests(time_load_file, data_name, 'load_time_cluster_num_' + str(train_batch_num) + 'net_layer_num_' + str(net_layer_num), 'epochs_per_batch', 'Load Time (ms)')\n",
    " \n",
    "def step41_run_investigation_summarize_whole(data_name, image_data_path, intermediate_data_path, tune_param_name, tune_val_label, tune_val, \\\n",
    "                                    train_batch_num, net_layer_num, trainer_list): \n",
    "    \"\"\"\n",
    "        Train investigation post-processing\n",
    "        Train-validation at the same time\n",
    "    \"\"\"\n",
    "    print('Start summarizing for train batch num: ' + str(train_batch_num) )\n",
    "    # set the batch for validation and train\n",
    "    img_path = image_data_path + 'cluster_num_' + str(train_batch_num) + '/' + 'net_layer_num_' + str(net_layer_num) + '/'\n",
    "    img_path += 'investigation_figures/tune_' + tune_param_name + '_' + str(tune_val_label) + '/'\n",
    "    # start to summarize the results into images for output\n",
    "\n",
    "    Train_peroid_f1, Train_peroid_accuracy = summarize_investigation_res(img_path, intermediate_data_path, trainer_list)\n",
    "\n",
    "    Train_peroid_f1 = store_data_multi_investigate(Train_peroid_f1, data_name, 'F1_score', img_path, 'invest_batch_num_' + str(train_batch_num))\n",
    "    draw_data_multi_tests(Train_peroid_f1, data_name, 'Train_process_batch_num_' + str(train_batch_num), 'epoch number', 'F1 score')\n",
    "\n",
    "    Train_peroid_accuracy = store_data_multi_investigate(Train_peroid_accuracy, data_name, 'Accuracy', img_path, 'invest_batch_num_' + str(train_batch_num) )\n",
    "    draw_data_multi_tests(Train_peroid_accuracy, data_name, 'Train_process_batch_num_' + str(train_batch_num), 'epoch number', 'Accuracy')\n",
    "\n",
    "    \n",
    "def check_train_loss_converge(image_path, mini_batch_folder, subfolder, data_name, trainer_id = 0):\n",
    "    # mini-batch, but valid also in batches\n",
    "    Trainer_folder = mini_batch_folder + subfolder\n",
    "    trainer_file_name = Trainer_folder + 'GCN_trainer_' + str(trainer_id)\n",
    "    \n",
    "    print('Start to read the GCN trainer model (parameters: weights, bias):')\n",
    "    t1 = time.time()\n",
    "    with open(trainer_file_name, \"rb\") as fp:\n",
    "        gcn_trainer = pickle.load(fp)\n",
    "    read_trainer_time = (time.time() - t1) * 1000\n",
    "    print('Reading the trainer costs a total of {0:.4f} seconds!'.format(read_trainer_time))\n",
    "    \n",
    "    # store the resulting data on the disk\n",
    "    train_loss_path = image_path + 'trainer_loss/' + subfolder\n",
    "    os.makedirs(os.path.dirname(train_loss_path), exist_ok=True)\n",
    "    loss_res_file = train_loss_path + 'loss_trainer_' + str(trainer_id)\n",
    "    \n",
    "    draw_Cluster_train_valid_batch = draw_trainer_info(data_name, gcn_trainer)\n",
    "    draw_Cluster_train_valid_batch.draw_ave_loss_per_node(loss_res_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use dataset from GraphSaint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_data_root = '/home/xiangli/projects/tmpdata/GCN/GraphSaint/'\n",
    "test_folder_name = 'metis_train_10%_gch_cluster/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of data 1\n",
      "Info (attributes) of a single data instance\n",
      "Data(edge_index=[2, 450540], test_mask=[14755], train_mask=[14755], val_mask=[14755], x=[14755, 50], y=[14755, 121]) \n",
      " number of nodes:  14755 \n",
      " number of edges:  450540 \n",
      " number of features per ndoe:  50 \n",
      " number of edge features:  0 \n",
      " number of classifying labels of dataset:  121 \n",
      " all the attributes of data:  ['x', 'edge_index', 'y', 'train_mask', 'val_mask', 'test_mask']\n"
     ]
    }
   ],
   "source": [
    "from GraphSaint_dataset import print_data_info, Flickr, Yelp, PPI_large, Amazon, Reddit, PPI_small\n",
    "# suppose this is on the OSC cluster\n",
    "\n",
    "data_name = 'PPI_small'\n",
    "class_data = eval(data_name)\n",
    "dataset = class_data(root = remote_data_root + data_name)\n",
    "print('number of data', len(dataset))\n",
    "data = dataset[0]\n",
    "print_data_info(data, dataset)\n",
    "\n",
    "intermediate_data_folder = './KDD_trial_version_multi_label/'\n",
    "image_data_path = intermediate_data_folder + 'results/' + data_name + '/' + test_folder_name\n",
    "\n",
    "# this is the parts we divide the graph\n",
    "origin_train_batch_num = 4\n",
    "round_num = 2\n",
    "train_batch_num = round_num * origin_train_batch_num\n",
    "\n",
    "GCN_layer = [32]\n",
    "net_layer_num = len(GCN_layer) + 1\n",
    "# for non-optimization: hop_layer_num == net_layer_num\n",
    "hop_layer_num = net_layer_num\n",
    "\n",
    "tune_param_name = 'learning_rate'\n",
    "tune_val_label_list = [3, 4]\n",
    "tune_val_list = [10**(-label) for label in tune_val_label_list]\n",
    "\n",
    "trainer_list = list(range(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output-F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start running for train batch num: 4\n",
      "\n",
      "====================================================================================================\n",
      "Start to generate the clustering machine:\n",
      "No isolated nodes number is found \n",
      "Label shape is: torch.Size([14755, 121])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/ipykernel_launcher.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch machine creation costs a total of 1.5941 seconds!\n",
      "\n",
      "Edge number:  450540 \n",
      "Node number:  14755 \n",
      "Feature number:  50\n",
      "\n",
      " Information about the content of ./KDD_trial_version_multi_label/tmp/\n",
      "\n",
      "Start to split data into train, test, validation:\n",
      "Data splitting costs a total of 0.7071 seconds!\n",
      "Start to store the batch machine file:\n",
      "Storing batch machine after training batches generation costs a total of 0.0756 seconds!\n",
      "\n",
      "====================================================================================================\n",
      "Start running for train batch num: (0, 8)\n",
      "\n",
      "====================================================================================================\n",
      "Batch machine reading costs a total of 0.0798 seconds!\n",
      "Start to generate the training batches:\n",
      "*** Generate batch file for #   0 batch, writing the batch file costed 1.86 ms ***\n",
      "*** Generate batch file for #   1 batch, writing the batch file costed 2.30 ms ***\n",
      "*** Generate batch file for #   2 batch, writing the batch file costed 1.95 ms ***\n",
      "*** Generate batch file for #   3 batch, writing the batch file costed 2.36 ms ***\n",
      "*** Generate batch file for #   4 batch, writing the batch file costed 2.94 ms ***\n",
      "*** Generate batch file for #   5 batch, writing the batch file costed 2.04 ms ***\n",
      "*** Generate batch file for #   6 batch, writing the batch file costed 1.98 ms ***\n",
      "*** Generate batch file for #   7 batch, writing the batch file costed 1.85 ms ***\n",
      "Train batches production costs a total of 0.8913 seconds!\n",
      "\n",
      " Information about the content of ./KDD_trial_version_multi_label/train/\n",
      "File name: [ batch_3 ]; with size: 2994.271484375 KB\n",
      "File name: [ batch_2 ]; with size: 3268.591796875 KB\n",
      "File name: [ batch_4 ]; with size: 3260.212890625 KB\n",
      "File name: [ batch_7 ]; with size: 3060.259765625 KB\n",
      "File name: [ batch_1 ]; with size: 3008.29296875 KB\n",
      "File name: [ batch_6 ]; with size: 3197.482421875 KB\n",
      "File name: [ batch_0 ]; with size: 3157.205078125 KB\n",
      "File name: [ batch_5 ]; with size: 3182.908203125 KB\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "Batch machine reading costs a total of 0.0943 seconds!\n",
      "Start to generate the validation whole graph:\n",
      "*** Generate batch file for # whole graph batch, writing the batch file costed 11.17 ms ***\n",
      "Validation batches production costs a total of 0.7779 seconds!\n",
      "\n",
      " Information about the content of ./KDD_trial_version_multi_label/validation/\n",
      "File name: [ batch_whole ]; with size: 17422.2265625 KB\n",
      "\n",
      "====================================================================================================\n",
      "Start running training for train batch num: 8\n",
      "\n",
      "====================================================================================================\n",
      "Start generate the trainer:\n",
      "Trainer creation costs a total of 0.0108 seconds!\n",
      "Start train the model:\n",
      "*** During training, total IO data reading time for all batches costed 188.09 ms ***\n",
      "Training costs a total of 12.1514 seconds!\n",
      "Start to save the GCN trainer model (parameters: weights, bias):\n",
      "Storing the trainer costs a total of 0.0029 seconds!\n",
      "--------------------------------------------------------------------------------\n",
      "Start running training for train batch num: 8\n",
      "\n",
      "====================================================================================================\n",
      "Start generate the trainer:\n",
      "Trainer creation costs a total of 0.0009 seconds!\n",
      "Start train the model:\n",
      "*** During training, total IO data reading time for all batches costed 189.15 ms ***\n",
      "Training costs a total of 11.9780 seconds!\n",
      "Start to save the GCN trainer model (parameters: weights, bias):\n",
      "Storing the trainer costs a total of 0.0025 seconds!\n",
      "--------------------------------------------------------------------------------\n",
      "Start running validation for train batch num: 8\n",
      "Start to read the GCN trainer model (parameters: weights, bias):\n",
      "Reading the trainer costs a total of 3.0372 seconds!\n",
      "Start validate the model:\n",
      "*** During validation for # whole graph batch, reading batch file costed 5.04 ms ***\n",
      "Validatoin costs a total of 1.1459 seconds!\n",
      "====================================================================================================\n",
      "Start to read the GCN trainer model (parameters: weights, bias):\n",
      "Reading the trainer costs a total of 2.4168 seconds!\n",
      "Start validate the model:\n",
      "*** During validation for # whole graph batch, reading batch file costed 6.02 ms ***\n",
      "Validatoin costs a total of 1.0677 seconds!\n",
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "step0_generate_clustering_machine(data, dataset, intermediate_data_folder, origin_train_batch_num, validation_ratio = 0.05, test_ratio = 0.85, mini_cluster_num = 32, round_num = round_num)\n",
    "\n",
    "step1_generate_train_batch(intermediate_data_folder, \\\n",
    "                           batch_range = (0, train_batch_num), \n",
    "                           info_folder = 'info_train_batch/' )\n",
    "\n",
    "step2_generate_validation_whole_graph(intermediate_data_folder, info_folder = 'info_validation_whole/')\n",
    "\n",
    "for trainer_id in trainer_list:\n",
    "    step3_run_train_batch(intermediate_data_folder, train_batch_num, GCN_layer, \\\n",
    "                    trainer_id = trainer_id, dropout = 0.1, lr = 0.0001, weight_decay = 0.1, mini_epoch_num = 20, epoch_num = 400)\n",
    "\n",
    "\n",
    "step4_run_validation_batch(image_data_path, intermediate_data_folder, train_batch_num, net_layer_num, trainer_list = trainer_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start running for train batch num: 4\n",
      "\n",
      "====================================================================================================\n",
      "Start to generate the clustering machine:\n",
      "No isolated nodes number is found \n",
      "Label shape is: torch.Size([14755, 121])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/ipykernel_launcher.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch machine creation costs a total of 1.5787 seconds!\n",
      "\n",
      "Edge number:  450540 \n",
      "Node number:  14755 \n",
      "Feature number:  50\n",
      "\n",
      " Information about the content of ./KDD_trial_version_multi_label/tmp/\n",
      "\n",
      "Start to split data into train, test, validation:\n",
      "Data splitting costs a total of 0.7575 seconds!\n",
      "Start to store the batch machine file:\n",
      "Storing batch machine after training batches generation costs a total of 0.0743 seconds!\n",
      "\n",
      "====================================================================================================\n",
      "Start running for train batch num: (0, 8)\n",
      "\n",
      "====================================================================================================\n",
      "Batch machine reading costs a total of 0.0747 seconds!\n",
      "Start to generate the training batches:\n",
      "*** Generate batch file for #   0 batch, writing the batch file costed 1.80 ms ***\n",
      "*** Generate batch file for #   1 batch, writing the batch file costed 1.74 ms ***\n",
      "*** Generate batch file for #   2 batch, writing the batch file costed 1.90 ms ***\n",
      "*** Generate batch file for #   3 batch, writing the batch file costed 1.86 ms ***\n",
      "*** Generate batch file for #   4 batch, writing the batch file costed 1.67 ms ***\n",
      "*** Generate batch file for #   5 batch, writing the batch file costed 1.77 ms ***\n",
      "*** Generate batch file for #   6 batch, writing the batch file costed 2.06 ms ***\n",
      "*** Generate batch file for #   7 batch, writing the batch file costed 1.96 ms ***\n",
      "Train batches production costs a total of 0.9413 seconds!\n",
      "\n",
      " Information about the content of ./KDD_trial_version_multi_label/train/\n",
      "File name: [ batch_3 ]; with size: 3082.181640625 KB\n",
      "File name: [ batch_2 ]; with size: 3374.486328125 KB\n",
      "File name: [ batch_4 ]; with size: 3025.744140625 KB\n",
      "File name: [ batch_7 ]; with size: 3079.912109375 KB\n",
      "File name: [ batch_1 ]; with size: 2913.2890625 KB\n",
      "File name: [ batch_6 ]; with size: 3023.001953125 KB\n",
      "File name: [ batch_0 ]; with size: 3096.404296875 KB\n",
      "File name: [ batch_5 ]; with size: 3145.236328125 KB\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "Batch machine reading costs a total of 0.0780 seconds!\n",
      "Start to generate the validation whole graph:\n",
      "*** Generate batch file for # whole graph batch, writing the batch file costed 78.69 ms ***\n",
      "Validation batches production costs a total of 0.7867 seconds!\n",
      "\n",
      " Information about the content of ./KDD_trial_version_multi_label/validation/\n",
      "File name: [ batch_whole ]; with size: 17422.2265625 KB\n",
      "\n",
      "====================================================================================================\n",
      "Start running training for partition num: 8\n",
      "\n",
      "====================================================================================================\n",
      "Start generate the trainer:\n",
      "Trainer creation costs a total of 0.0079 seconds!\n",
      "Start train the model:\n",
      "*** During training, total IO data reading time for all batches costed 199.39 ms ***\n",
      "Training costs a total of 13.3567 seconds!\n",
      "--------------------------------------------------------------------------------\n",
      "Start running training for partition num: 8\n",
      "\n",
      "====================================================================================================\n",
      "Start generate the trainer:\n",
      "Trainer creation costs a total of 0.0011 seconds!\n",
      "Start train the model:\n",
      "*** During training, total IO data reading time for all batches costed 192.80 ms ***\n",
      "Training costs a total of 11.9779 seconds!\n",
      "--------------------------------------------------------------------------------\n",
      "Start running training for partition num: 8\n",
      "\n",
      "====================================================================================================\n",
      "Start generate the trainer:\n",
      "Trainer creation costs a total of 0.0008 seconds!\n",
      "Start train the model:\n",
      "*** During training, total IO data reading time for all batches costed 193.87 ms ***\n",
      "Training costs a total of 12.0469 seconds!\n",
      "--------------------------------------------------------------------------------\n",
      "Start running training for partition num: 8\n",
      "\n",
      "====================================================================================================\n",
      "Start generate the trainer:\n",
      "Trainer creation costs a total of 0.0007 seconds!\n",
      "Start train the model:\n",
      "*** During training, total IO data reading time for all batches costed 199.43 ms ***\n",
      "Training costs a total of 13.2103 seconds!\n",
      "--------------------------------------------------------------------------------\n",
      "Start running training for partition num: 8\n",
      "Start to read the GCN trainer model (parameters: weights, bias):\n",
      "Reading the trainer costs a total of 3.6960 seconds!\n",
      "Start validate the model:\n",
      "*** During validation for # whole graph batch, reading batch file costed 8.57 ms ***\n",
      "Validatoin costs a total of 1.1364 seconds!\n",
      "====================================================================================================\n",
      "Start running training for partition num: 8\n",
      "Start to read the GCN trainer model (parameters: weights, bias):\n",
      "Reading the trainer costs a total of 3.1407 seconds!\n",
      "Start validate the model:\n",
      "*** During validation for # whole graph batch, reading batch file costed 5.66 ms ***\n",
      "Validatoin costs a total of 1.1555 seconds!\n",
      "====================================================================================================\n",
      "Start running training for partition num: 8\n",
      "Start to read the GCN trainer model (parameters: weights, bias):\n",
      "Reading the trainer costs a total of 3.8209 seconds!\n",
      "Start validate the model:\n",
      "*** During validation for # whole graph batch, reading batch file costed 5.83 ms ***\n",
      "Validatoin costs a total of 1.1315 seconds!\n",
      "====================================================================================================\n",
      "Start running training for partition num: 8\n",
      "Start to read the GCN trainer model (parameters: weights, bias):\n",
      "Reading the trainer costs a total of 3.7568 seconds!\n",
      "Start validate the model:\n",
      "*** During validation for # whole graph batch, reading batch file costed 5.35 ms ***\n",
      "Validatoin costs a total of 1.0853 seconds!\n",
      "====================================================================================================\n",
      "Start running training for partition num: 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "step0_generate_clustering_machine(data, dataset, intermediate_data_folder, origin_train_batch_num, validation_ratio = 0.05, test_ratio = 0.85, mini_cluster_num = 32, round_num = 2)\n",
    "\n",
    "step1_generate_train_batch(intermediate_data_folder, \\\n",
    "                           batch_range = (0, train_batch_num), \n",
    "                           info_folder = 'info_train_batch/' )\n",
    "\n",
    "step2_generate_validation_whole_graph(intermediate_data_folder, info_folder = 'info_validation_whole/')\n",
    "\n",
    "# tuning the mini-epoch number\n",
    "for tune_val_label, tune_val in zip(tune_val_label_list, tune_val_list):\n",
    "    for trainer_id in trainer_list:\n",
    "        step30_run_tune_train_batch(intermediate_data_folder, tune_param_name, tune_val_label, tune_val, train_batch_num, GCN_layer, \\\n",
    "                            trainer_id = trainer_id, dropout = 0.1, lr = 0.0001, weight_decay = 0.1, mini_epoch_num = 20, epoch_num = 400)\n",
    "            \n",
    "for tune_val_label, tune_val in zip(tune_val_label_list, tune_val_list):\n",
    "    for trainer_id in trainer_list:\n",
    "        step40_run_tune_validation_whole(image_data_path, intermediate_data_folder, tune_param_name, tune_val_label, tune_val, train_batch_num, net_layer_num, \\\n",
    "                            trainer_id = trainer_id)\n",
    "            \n",
    "step50_run_tune_summarize_whole(data_name, image_data_path, intermediate_data_folder, tune_param_name, tune_val_label_list, tune_val_list, \\\n",
    "                                train_batch_num, net_layer_num, trainer_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train investigate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start running for train batch num: 4\n",
      "\n",
      "====================================================================================================\n",
      "Start to generate the clustering machine:\n",
      "No isolated nodes number is found \n",
      "Label shape is: torch.Size([14755, 121])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/ipykernel_launcher.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch machine creation costs a total of 1.5609 seconds!\n",
      "\n",
      "Edge number:  450540 \n",
      "Node number:  14755 \n",
      "Feature number:  50\n",
      "\n",
      " Information about the content of ./KDD_trial_version_multi_label/tmp/\n",
      "\n",
      "Start to split data into train, test, validation:\n",
      "Data splitting costs a total of 0.7270 seconds!\n",
      "Start to store the batch machine file:\n",
      "Storing batch machine after training batches generation costs a total of 0.0823 seconds!\n",
      "\n",
      "====================================================================================================\n",
      "Start running for train batch num: (0, 8)\n",
      "\n",
      "====================================================================================================\n",
      "Batch machine reading costs a total of 0.0777 seconds!\n",
      "Start to generate the training batches:\n",
      "*** Generate batch file for #   0 batch, writing the batch file costed 1.94 ms ***\n",
      "*** Generate batch file for #   1 batch, writing the batch file costed 1.68 ms ***\n",
      "*** Generate batch file for #   2 batch, writing the batch file costed 2.21 ms ***\n",
      "*** Generate batch file for #   3 batch, writing the batch file costed 1.94 ms ***\n",
      "*** Generate batch file for #   4 batch, writing the batch file costed 2.31 ms ***\n",
      "*** Generate batch file for #   5 batch, writing the batch file costed 1.84 ms ***\n",
      "*** Generate batch file for #   6 batch, writing the batch file costed 1.80 ms ***\n",
      "*** Generate batch file for #   7 batch, writing the batch file costed 1.85 ms ***\n",
      "Train batches production costs a total of 0.8974 seconds!\n",
      "\n",
      " Information about the content of ./KDD_trial_version_multi_label/train/\n",
      "File name: [ batch_3 ]; with size: 3153.884765625 KB\n",
      "File name: [ batch_2 ]; with size: 3083.072265625 KB\n",
      "File name: [ batch_4 ]; with size: 3043.537109375 KB\n",
      "File name: [ batch_7 ]; with size: 3019.025390625 KB\n",
      "File name: [ batch_1 ]; with size: 2947.880859375 KB\n",
      "File name: [ batch_6 ]; with size: 3037.525390625 KB\n",
      "File name: [ batch_0 ]; with size: 3104.619140625 KB\n",
      "File name: [ batch_5 ]; with size: 3104.119140625 KB\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "Batch machine reading costs a total of 0.0978 seconds!\n",
      "Start to generate the validation whole graph:\n",
      "*** Generate batch file for # whole graph batch, writing the batch file costed 67.62 ms ***\n",
      "Validation batches production costs a total of 0.7504 seconds!\n",
      "\n",
      " Information about the content of ./KDD_trial_version_multi_label/validation/\n",
      "File name: [ batch_whole ]; with size: 17422.2265625 KB\n",
      "\n",
      "====================================================================================================\n",
      "Start running investigation training for train batch num: 8_trainer_id_0\n",
      "\n",
      "====================================================================================================\n",
      "Start generate the trainer:\n",
      "Trainer creation costs a total of 0.0110 seconds!\n",
      "Start train the model:\n",
      "*** During validation for # whole graph for investigation batch, reading batch file costed 6.04 ms ***\n",
      "*** During training, reading all batch file I/O costed 193.27 ms ***\n",
      "Training costs a total of 118.5482 seconds!\n",
      "--------------------------------------------------------------------------------\n",
      "Start running investigation training for train batch num: 8_trainer_id_1\n",
      "\n",
      "====================================================================================================\n",
      "Start generate the trainer:\n",
      "Trainer creation costs a total of 0.0013 seconds!\n",
      "Start train the model:\n",
      "*** During validation for # whole graph for investigation batch, reading batch file costed 6.70 ms ***\n",
      "*** During training, reading all batch file I/O costed 192.18 ms ***\n",
      "Training costs a total of 117.6485 seconds!\n",
      "--------------------------------------------------------------------------------\n",
      "Start running investigation training for train batch num: 8_trainer_id_0\n",
      "\n",
      "====================================================================================================\n",
      "Start generate the trainer:\n",
      "Trainer creation costs a total of 0.0017 seconds!\n",
      "Start train the model:\n",
      "*** During validation for # whole graph for investigation batch, reading batch file costed 5.22 ms ***\n",
      "*** During training, reading all batch file I/O costed 186.84 ms ***\n",
      "Training costs a total of 115.4820 seconds!\n",
      "--------------------------------------------------------------------------------\n",
      "Start running investigation training for train batch num: 8_trainer_id_1\n",
      "\n",
      "====================================================================================================\n",
      "Start generate the trainer:\n",
      "Trainer creation costs a total of 0.0009 seconds!\n",
      "Start train the model:\n",
      "*** During validation for # whole graph for investigation batch, reading batch file costed 5.77 ms ***\n",
      "*** During training, reading all batch file I/O costed 185.54 ms ***\n",
      "Training costs a total of 114.6487 seconds!\n",
      "--------------------------------------------------------------------------------\n",
      "Start summarizing for train batch num: 8\n",
      "Start summarizing for train batch num: 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "step0_generate_clustering_machine(data, dataset, intermediate_data_folder, origin_train_batch_num, validation_ratio = 0.05, test_ratio = 0.85, mini_cluster_num = 32, round_num = 2)\n",
    "\n",
    "step1_generate_train_batch(intermediate_data_folder, \\\n",
    "                           batch_range = (0, train_batch_num), \n",
    "                           info_folder = 'info_train_batch/' )\n",
    "\n",
    "step2_generate_validation_whole_graph(intermediate_data_folder, info_folder = 'info_validation_whole/')\n",
    "\n",
    "# train-batch investigate\n",
    "for tune_val_label, tune_val in zip(tune_val_label_list, tune_val_list):\n",
    "    for tainer_id in trainer_list:\n",
    "        step31_run_investigation_train_batch(image_data_path, intermediate_data_folder, tune_param_name, tune_val_label, tune_val, train_batch_num, net_layer_num, GCN_layer, \\\n",
    "                        trainer_id = tainer_id, dropout = 0.1, lr = 0.0001, weight_decay = 0.1, mini_epoch_num = 20, epoch_num = 400, output_period = 40)\n",
    "\n",
    "for tune_val_label, tune_val in zip(tune_val_label_list, tune_val_list):\n",
    "    step41_run_investigation_summarize_whole(data_name, image_data_path, intermediate_data_folder, tune_param_name, tune_val_label, tune_val, \\\n",
    "                                    train_batch_num, net_layer_num, trainer_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Training loss convergence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output for the train loss\n",
    "subfolder = 'GCN_tuning/tune_batch_epoch_num_5/'\n",
    "check_train_loss_converge(image_data_path, intermediate_data_folder, subfolder, data_name, trainer_id = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GraphSaint_dataset import print_data_info, Flickr, Yelp, PPI_large, Amazon, Reddit\n",
    "# suppose this is on the OSC cluster\n",
    "remote_data_root = '/home/xiangli/projects/tmpdata/GCN/GraphSaint/'\n",
    "\n",
    "data_name = 'Flickr'\n",
    "dataset = Flickr(root = remote_data_root + data_name)\n",
    "print('number of data', len(dataset))\n",
    "data = dataset[0]\n",
    "print_data_info(data, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another way to create class object from a string class name using eval():\n",
    "data_name = 'Flickr'\n",
    "data_class = eval(data_name)\n",
    "print(data_class)\n",
    "dataset = data_class(root = remote_data_root + data_name)\n",
    "print('number of data', len(dataset))\n",
    "data = dataset[0]\n",
    "print_data_info(data, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = os.getcwd().split('/')\n",
    "print(current_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PubMed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "data_name = 'PubMed'\n",
    "dataset = Planetoid(root = local_data_root + 'Planetoid/PubMed', name=data_name)\n",
    "data = dataset[0]\n",
    "image_data_path = './results/' + data_name + '/' + test_folder_name\n",
    "intermediate_data_folder = './'\n",
    "partition_nums = [2, 4, 8]\n",
    "layers = [[], [64], [64, 64]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CoraFull dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import CoraFull\n",
    "data_name = 'CoraFull'\n",
    "dataset = CoraFull(root = local_data_root + 'CoralFull')\n",
    "print('number of data: ', len(dataset))\n",
    "data = dataset[0]\n",
    "\n",
    "image_data_path = './results/' + data_name + '/' + test_folder_name\n",
    "intermediate_data_folder = './intermediate_data/' + data_name + '/' + test_folder_name\n",
    "\n",
    "partition_nums = [4]\n",
    "layers = [[128, 128]]\n",
    "tune_lr = 0.0001\n",
    "check_mini_epoch = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CiteSeer Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "data_name = 'CiteSeer'\n",
    "dataset = Planetoid(root = local_data_root + 'Planetoid/CiteSeer', name=data_name)\n",
    "data = dataset[0]\n",
    "image_data_path = './results/' + data_name + '/' + test_folder_name\n",
    "\n",
    "partition_nums = [2, 4, 8]\n",
    "layers = [[], [16], [16, 16]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning the epoch number per batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking train loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PubMed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "data_name = 'PubMed'\n",
    "dataset = Planetoid(root = local_data_root + 'Planetoid/PubMed', name=data_name)\n",
    "data = dataset[0]\n",
    "image_data_path = './results/' + data_name + '/' + test_folder_name\n",
    "\n",
    "partition_nums = [2, 4, 8]\n",
    "layers = [[], [64], [64, 64], [64, 64, 64]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune epoch number per batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the train error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# free GPU memory\n",
    "# !(nvidia-smi | grep 'python' | awk '{ print $3 }' | xargs -n1 kill -9)\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_1_4_geometric]",
   "language": "python",
   "name": "conda-env-pytorch_1_4_geometric-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
