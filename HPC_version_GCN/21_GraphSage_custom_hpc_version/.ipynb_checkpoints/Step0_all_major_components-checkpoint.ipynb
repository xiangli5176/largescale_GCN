{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Post_utils import *\n",
    "# from multi_exec import *\n",
    "import torch\n",
    "import time\n",
    "\n",
    "import pickle\n",
    "import dill\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "from metric import *\n",
    "from model_graphsaint import GraphSAINT\n",
    "\n",
    "from utils import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minibatch machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import scipy.sparse as sp\n",
    "import scipy\n",
    "import numpy as np\n",
    "\n",
    "from graphsaint_cython.norm_aggr import *\n",
    "from samplers import *\n",
    "\n",
    "def _coo_scipy2torch(adj):\n",
    "    \"\"\"\n",
    "    convert a scipy sparse COO matrix to torch\n",
    "    \n",
    "    Torch supports sparse tensors in COO(rdinate) format, which can efficiently store and process tensors \n",
    "    for which the majority of elements are zeros.\n",
    "    A sparse tensor is represented as a pair of dense tensors: a tensor of values and a 2D tensor of indices. \n",
    "    A sparse tensor can be constructed by providing these two tensors, as well as the size of the sparse tensor \n",
    "    \"\"\"\n",
    "    values = adj.data\n",
    "    indices = np.vstack((adj.row, adj.col))\n",
    "    i = torch.LongTensor(indices)\n",
    "    v = torch.FloatTensor(values)\n",
    "    \n",
    "    return torch.sparse.FloatTensor(i,v, torch.Size(adj.shape))\n",
    "\n",
    "\n",
    "class Minibatch:\n",
    "    \"\"\"\n",
    "        This minibatch iterator iterates over nodes for supervised learning.\n",
    "        Data transferred to GPU:     A  init: 1) self.adj_full_norm;  2) self.norm_loss_test;\n",
    "                                     B  set_sampler:  1) self.norm_loss_train\n",
    "                                     C  one_batch : 1) subgraph adjacency matrix (adj)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, adj_full_norm, adj_train, role, train_params, cpu_eval = False, num_cpu_core = 1):\n",
    "        \"\"\"\n",
    "        role:       array of string (length |V|)\n",
    "                    storing role of the node ('tr'/'va'/'te')\n",
    "        \"\"\"\n",
    "        self.num_cpu_core = num_cpu_core\n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        if cpu_eval:\n",
    "            self.use_cuda = False\n",
    "        \n",
    "        # store all the node roles as the numpy array:\n",
    "        self.node_train = np.array(role['tr'])\n",
    "        self.node_val = np.array(role['va'])\n",
    "        self.node_test = np.array(role['te'])\n",
    "\n",
    "        # self.adj_full_norm : torch sparse tensor\n",
    "        self.adj_full_norm = _coo_scipy2torch(adj_full_norm.tocoo())\n",
    "        self.adj_train = adj_train\n",
    "\n",
    "        # below: book-keeping for mini-batch\n",
    "        self.node_subgraph = None\n",
    "        self.batch_num = -1\n",
    "\n",
    "        # all the subgraph attributes should be used for the training process\n",
    "        self.method_sample = None\n",
    "        self.subgraphs_remaining_indptr = []\n",
    "        self.subgraphs_remaining_indices = []\n",
    "        self.subgraphs_remaining_data = []\n",
    "        self.subgraphs_remaining_nodes = []\n",
    "        self.subgraphs_remaining_edge_index = []\n",
    "        \n",
    "        # What is this norm_loss aimed at?\n",
    "        self.norm_loss_train = np.zeros(self.adj_train.shape[0])\n",
    "        # norm_loss_test is used in full batch evaluation (without sampling). so neighbor features are simply averaged.\n",
    "        self.norm_loss_test = np.zeros(self.adj_full_norm.shape[0])\n",
    "        \n",
    "        _denom = len(self.node_train) + len(self.node_val) +  len(self.node_test)\n",
    "        \n",
    "        # instead of assign all elements of self.norm_loss_test to the same averaged denominator, separately assingment instead. \n",
    "        # does this mean there are other meaningless roles beyond: test, train and validation?\n",
    "        self.norm_loss_test[self.node_train] = 1./_denom     \n",
    "        self.norm_loss_test[self.node_val] = 1./_denom\n",
    "        self.norm_loss_test[self.node_test] = 1./_denom\n",
    "        self.norm_loss_test = torch.from_numpy(self.norm_loss_test.astype(np.float32))\n",
    "        \n",
    "            \n",
    "        self.norm_aggr_train = np.zeros(self.adj_train.size)\n",
    "        \n",
    "        self.sample_coverage = train_params['sample_coverage']\n",
    "        self.deg_train = np.array(self.adj_train.sum(1)).flatten()   # sum the degree of each train node, here sum along column for adjacency matrix\n",
    "\n",
    "\n",
    "    def set_sampler(self, train_phases, input_neigh_deg = [10, 5], core_par_sampler = 1, samples_per_processor = 200):\n",
    "        \"\"\"\n",
    "            Train_phases (a dict defined in the .yml file) : usually including : end, smapler, size_subg_edge\n",
    "            end:  number of total epochs to stop\n",
    "            sampler: category for sampler (e.g. edge)\n",
    "            size_subg_edge:  size of the subgraph in number of edges\n",
    "        \"\"\"\n",
    "        \n",
    "        self.subgraphs_remaining_indptr = list()\n",
    "        self.subgraphs_remaining_indices = list()\n",
    "        self.subgraphs_remaining_data = list()\n",
    "        self.subgraphs_remaining_nodes = list()\n",
    "        self.subgraphs_remaining_edge_index = list()\n",
    "        \n",
    "        self.method_sample = train_phases['sampler']   # one of the string indicators regarding sampler methods\n",
    "        if self.method_sample == 'mrw':\n",
    "            if 'deg_clip' in train_phases:\n",
    "                _deg_clip = int(train_phases['deg_clip'])\n",
    "            else:\n",
    "                _deg_clip = 100000      # setting this to a large number so essentially there is no clipping in probability\n",
    "            self.size_subg_budget = train_phases['size_subgraph']\n",
    "            self.graph_sampler = mrw_sampling(self.adj_train, self.node_train,\n",
    "                                self.size_subg_budget, train_phases['size_frontier'], _deg_clip, \n",
    "                                        core_par_sampler = core_par_sampler, samples_per_processor = samples_per_processor)\n",
    "        elif self.method_sample == 'rw':\n",
    "            self.size_subg_budget = train_phases['num_root'] * train_phases['depth']\n",
    "            self.graph_sampler = rw_sampling(self.adj_train, self.node_train,\n",
    "                                self.size_subg_budget, int(train_phases['num_root']), int(train_phases['depth']), \n",
    "                                        core_par_sampler = core_par_sampler, samples_per_processor = samples_per_processor)\n",
    "        elif self.method_sample == 'edge':\n",
    "            self.size_subg_budget = train_phases['size_subg_edge'] * 2\n",
    "            self.graph_sampler = edge_sampling(self.adj_train, self.node_train, train_phases['size_subg_edge'], \n",
    "                                        core_par_sampler = core_par_sampler, samples_per_processor = samples_per_processor)\n",
    "        elif self.method_sample == 'node':\n",
    "            self.size_subg_budget = train_phases['size_subgraph']\n",
    "            self.graph_sampler = node_sampling(self.adj_train,self.node_train, self.size_subg_budget, \n",
    "                                        core_par_sampler = core_par_sampler, samples_per_processor = samples_per_processor)\n",
    "        elif self.method_sample == 'full_batch':\n",
    "            self.size_subg_budget = self.node_train.size\n",
    "            self.graph_sampler = full_batch_sampling(self.adj_train,self.node_train, self.size_subg_budget, \n",
    "                                        core_par_sampler = core_par_sampler, samples_per_processor = samples_per_processor)\n",
    "        elif self.method_sample == 'sage_node':\n",
    "            self.size_subg_budget = train_phases['size_subgraph']\n",
    "            self.graph_sampler = sage_sampling(self.adj_train,self.node_train, self.size_subg_budget, input_neigh_deg = input_neigh_deg,\n",
    "                                        core_par_sampler = core_par_sampler, samples_per_processor = samples_per_processor)\n",
    "            print(\"using sage node sampler! \")\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        self.norm_loss_train = np.zeros(self.adj_train.shape[0])\n",
    "        self.norm_aggr_train = np.zeros(self.adj_train.size).astype(np.float32)\n",
    "\n",
    "        # For edge sampler, no need to estimate norm factors, we can calculate directly.\n",
    "        # However, for integrity of the framework, we decide to follow the same procedure for all samplers: \n",
    "        # 1. sample enough number of subgraphs\n",
    "        # 2. estimate norm factor alpha and lambda\n",
    "        tot_sampled_nodes = 0\n",
    "        while True:\n",
    "            self.par_graph_sample('train')\n",
    "            tot_sampled_nodes = sum([len(n) for n in self.subgraphs_remaining_nodes])\n",
    "            if tot_sampled_nodes > self.sample_coverage * self.node_train.size:\n",
    "                break\n",
    "        print()\n",
    "        num_subg = len(self.subgraphs_remaining_nodes)  # each subgraph nodes are stored as one list inside the self.subgraphs_remaining_nodes\n",
    "        for i in range(num_subg):\n",
    "            self.norm_aggr_train[self.subgraphs_remaining_edge_index[i]] += 1\n",
    "            self.norm_loss_train[self.subgraphs_remaining_nodes[i]] += 1\n",
    "        assert self.norm_loss_train[self.node_val].sum() + self.norm_loss_train[self.node_test].sum() == 0\n",
    "        for v in range(self.adj_train.shape[0]):\n",
    "            i_s = self.adj_train.indptr[v]\n",
    "            i_e = self.adj_train.indptr[v+1]\n",
    "            val = np.clip(self.norm_loss_train[v]/self.norm_aggr_train[i_s:i_e], 0, 1e4)\n",
    "            val[np.isnan(val)] = 0.1\n",
    "            self.norm_aggr_train[i_s:i_e] = val\n",
    "        \n",
    "        # normalize the self.norm_loss_train:\n",
    "        self.norm_loss_train[np.where(self.norm_loss_train==0)[0]] = 0.1\n",
    "        self.norm_loss_train[self.node_val] = 0\n",
    "        self.norm_loss_train[self.node_test] = 0\n",
    "        self.norm_loss_train[self.node_train] = num_subg/self.norm_loss_train[self.node_train]/self.node_train.size\n",
    "        self.norm_loss_train = torch.from_numpy(self.norm_loss_train.astype(np.float32))\n",
    "\n",
    "    # each time finish one-time sampling: generate a single sample subgraph\n",
    "    def par_graph_sample(self, phase):\n",
    "        \"\"\"\n",
    "           Phase: can be a string \"train\"\n",
    "        \"\"\"\n",
    "        t0 = time.time()\n",
    "        _indptr, _indices, _data, _v, _edge_index = self.graph_sampler.par_sample(phase)\n",
    "        t1 = time.time()\n",
    "        # create 200 subgraphs per CPU, these 200 graphs may be generated by different cores, but 200 each time, not to exceed the memory limit\n",
    "        print('sampling 200 subgraphs:   time = {:.3f} sec'.format(t1 - t0), end=\"\\r\")\n",
    "        self.subgraphs_remaining_indptr.extend(_indptr)   # add lists into the subgraphs_remaining_indptr, each list is a subgraph\n",
    "        self.subgraphs_remaining_indices.extend(_indices)\n",
    "        self.subgraphs_remaining_data.extend(_data)\n",
    "        self.subgraphs_remaining_nodes.extend(_v)\n",
    "        self.subgraphs_remaining_edge_index.extend(_edge_index)\n",
    "\n",
    "    def one_batch(self, mode='train'):\n",
    "        \"\"\"\n",
    "            self.batch_num : for train mode, create one batch and the batch number will be increased by 1\n",
    "        \"\"\"\n",
    "        if mode in ['val','test']:\n",
    "            self.node_subgraph = np.arange(self.adj_full_norm.shape[0])  # include all the nodes inside the graph\n",
    "            adj = self.adj_full_norm\n",
    "        else:\n",
    "            assert mode == 'train'\n",
    "            \n",
    "            \n",
    "            if len(self.subgraphs_remaining_nodes) == 0:\n",
    "                self.par_graph_sample('train')   # if there is no sampled subgraphs, then make one\n",
    "                print()\n",
    "\n",
    "            self.node_subgraph = self.subgraphs_remaining_nodes.pop()\n",
    "            self.size_subgraph = len(self.node_subgraph)\n",
    "            adj = sp.csr_matrix((self.subgraphs_remaining_data.pop(),\\\n",
    "                                 self.subgraphs_remaining_indices.pop(),\\\n",
    "                                 self.subgraphs_remaining_indptr.pop()),\\\n",
    "                                 shape=(self.size_subgraph,self.size_subgraph))\n",
    "            adj_edge_index = self.subgraphs_remaining_edge_index.pop()\n",
    "            #print(\"{} nodes, {} edges, {} degree\".format(self.node_subgraph.size,adj.size,adj.size/self.node_subgraph.size))\n",
    "            norm_aggr(adj.data, adj_edge_index, self.norm_aggr_train, num_proc = self.num_cpu_core)\n",
    "            adj = adj_norm(adj, deg = self.deg_train[self.node_subgraph])\n",
    "            adj = _coo_scipy2torch(adj.tocoo())\n",
    "            \n",
    "            self.batch_num += 1          # create one batch\n",
    "            \n",
    "        norm_loss = self.norm_loss_test if mode in ['val','test'] else self.norm_loss_train\n",
    "        norm_loss = norm_loss[self.node_subgraph]\n",
    "        # this self.node_subgraph is to select the target nodes, can be left on the CPU\n",
    "        \n",
    "        # for evaluation: all nodes, its adj_full_norm and norm_loss_test \n",
    "        return self.node_subgraph, adj, norm_loss\n",
    "\n",
    "\n",
    "    def num_training_batches(self):\n",
    "        return math.ceil(self.node_train.shape[0] / float(self.size_subg_budget))\n",
    "\n",
    "    def shuffle(self):\n",
    "        self.node_train = np.random.permutation(self.node_train)\n",
    "        self.batch_num = -1\n",
    "\n",
    "    def end(self):\n",
    "        return (self.batch_num + 1) * self.size_subg_budget >= self.node_train.shape[0]   # greater or equal to the number of train nodes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic execution components "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a lambda func\n",
    "f_mean = lambda l: sum(l)/len(l)\n",
    "\n",
    "def evaluate_full_batch(model, minibatch, mode='val'):\n",
    "    \"\"\"\n",
    "        Full batch evaluation: for validation and test sets only.\n",
    "        When calculating the F1 score, we will mask the relevant root nodes.\n",
    "        mode: can be val or test\n",
    "    \"\"\"\n",
    "    loss, preds, labels = model.eval_step(*minibatch.one_batch(mode = mode))\n",
    "    node_val_test = minibatch.node_val if mode=='val' else minibatch.node_test\n",
    "    # may not be necessary \n",
    "    f1_scores = calc_f1(to_numpy(labels[node_val_test]), to_numpy(preds[node_val_test]), model.sigmoid_loss)\n",
    "    return loss, f1_scores[0], f1_scores[1]\n",
    "\n",
    "\n",
    "def train_setting(dataname, datapath, train_config_file):\n",
    "    \"\"\"\n",
    "        YAML (a recursive acronym for \"YAML Ain't Markup Language\") is a human-readable data-serialization language. \n",
    "        It is commonly used for configuration files and in applications where data is being stored or transmitted.\n",
    "    \n",
    "        yaml.load is as powerful as pickle.load and so may call any Python function. Check the yaml.safe_load function though.\n",
    "        The function yaml.load converts a YAML document to a Python object.\n",
    "    \"\"\"\n",
    "    with open(train_config_file) as f_train_config:\n",
    "        train_config = yaml.load(f_train_config)\n",
    "        \n",
    "    arch_gcn = {'dim':-1,\n",
    "                'aggr':'concat',\n",
    "                'loss':'softmax',\n",
    "                'arch':'1',\n",
    "                'act':'I',\n",
    "                'bias':'norm'}\n",
    "    # check the loss:  default to be softmax, multi-class problem, each node can only belong to just one class at last\n",
    "    arch_gcn.update(train_config['network'][0])   # train_config['network'] is a list of dict\n",
    "    \n",
    "    \n",
    "    train_params = {'lr' : 0.01, 'weight_decay' : 0., 'norm_loss':True, 'norm_aggr':True, 'q_threshold' : 50, 'q_offset':0}\n",
    "    train_params.update(train_config['params'][0])\n",
    "    train_phases = train_config['phase']\n",
    "    for ph in train_phases:\n",
    "        assert 'end' in ph\n",
    "        assert 'sampler' in ph\n",
    "    print(\"Loading training data..\")\n",
    "    temp_data = load_data(dataname, datapath = datapath)\n",
    "    train_data = process_graph_data(*temp_data)\n",
    "    print(\"Done loading training data..\")\n",
    "    \n",
    "    # train_data is a tuple: adj_full, adj_train, feats, class_arr, role\n",
    "    return train_params, train_phases, train_data, arch_gcn\n",
    "\n",
    "def prepare(working_dir, train_data, train_params, arch_gcn):\n",
    "    \"\"\"\n",
    "        working_dir: main working dir for experiments\n",
    "        train_params: contain settings for the mini-batch setting\n",
    "        arch_gcn: contain all the settings \n",
    "    \"\"\"\n",
    "    adj_full, adj_train, feat_full, class_arr, role = train_data\n",
    "    adj_full = adj_full.astype(np.int32)\n",
    "    adj_train = adj_train.astype(np.int32)\n",
    "    adj_full_norm = adj_norm(adj_full)\n",
    "    num_classes = class_arr.shape[1]\n",
    "    \n",
    "    # key switch :  cpu_eval (bool)\n",
    "    # establish two models, one for train, one for evaluation, because later the model_eval will load the trained model parameters\n",
    "    \n",
    "    # for training process: on GPU\n",
    "    minibatch = Minibatch(adj_full_norm, adj_train, role, train_params)\n",
    "    model = GraphSAINT(num_classes, arch_gcn, train_params, feat_full, class_arr)\n",
    "    # for evaluation: validaiton/test  : on CPU\n",
    "    minibatch_eval = Minibatch(adj_full_norm, adj_train,role, train_params, cpu_eval=True)\n",
    "    model_eval = GraphSAINT(num_classes, arch_gcn, train_params, feat_full, class_arr, cpu_eval=True)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "        \n",
    "    # model, model_eval, mini_batch_eval can be saved as pickle file for use later\n",
    "\n",
    "    ### but cannot pickle lambda func for now\n",
    "\n",
    "    prepare_data_folder = working_dir + 'prepare_data/'\n",
    "    os.makedirs(os.path.dirname(prepare_data_folder), exist_ok=True)\n",
    "\n",
    "    train_input_file_name = prepare_data_folder + 'model_train_input'\n",
    "    with open(train_input_file_name, \"wb\") as fp:\n",
    "        dill.dump((minibatch, model), fp)\n",
    "\n",
    "    evaluation_input_file_name = prepare_data_folder + 'model_eval_input'\n",
    "    with open(evaluation_input_file_name, \"wb\") as fp:\n",
    "        dill.dump((minibatch_eval, model_eval), fp)\n",
    "    \n",
    "    # return model, minibatch, minibatch_eval, model_eval\n",
    "\n",
    "\n",
    "def train_investigate(snap_model_folder, train_phases, model, minibatch, eval_train_every, snapshot_every = 10,\n",
    "          mini_epoch_num = 5, multilabel = True, input_neigh_deg = [10, 5], core_par_sampler = 1, samples_per_processor = 200):\n",
    "    \"\"\"\n",
    "    PURPOSE:  to go through each training phase and take a snapshot of current mode and saved as pickle files\n",
    "        snap_model_folder : folder to save the model snapshots during training\n",
    "        train_phases:  use defined train fases defined in the .yml file\n",
    "        model :  graphsaint model for training\n",
    "        minibatch:   minibatch for training, usually with batches pool\n",
    "        eval_train_every :  periodically store the train loss during the training process\n",
    "        snapshot_every :  periodically store the states of the trained model for later evaluation\n",
    "        mini_epoch_num :  how long the training will focus on one single batch\n",
    "        multilabel : True if a multi-label task, otherwise a multi-class case\n",
    "        core_par_sampler : how many CPU cores  will be used on each CPU\n",
    "        samples_per_processor : how many samples will be generated from each CPU\n",
    "    return: 1) total training time;  2) data uploading time\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    epoch_ph_start = 0\n",
    "    time_train, time_upload, pure_time_train = 0, 0, 0\n",
    "    \n",
    "    # establish a new folder if it does not exist\n",
    "#     os.makedirs(snap_model_folder, exist_ok = True)\n",
    "    \n",
    "    for ip, phase in enumerate(train_phases):\n",
    "        printf('START PHASE {:4d}'.format(ip),style='underline')\n",
    "        \n",
    "        minibatch.set_sampler(phase, input_neigh_deg = input_neigh_deg, core_par_sampler = core_par_sampler, samples_per_processor = samples_per_processor)  # one of the phases defined in the phase section of the .yml file, here phase is a dict\n",
    "        num_batches = minibatch.num_training_batches()\n",
    "#         print('calculated batch number is: ', num_batches)\n",
    "        \n",
    "        \n",
    "        epoch_ph_end = int(phase['end'])\n",
    "        macro_epoch_part_num = (epoch_ph_end - epoch_ph_start) // mini_epoch_num\n",
    "        for macro_epoch_idx in range(macro_epoch_part_num):\n",
    "            \n",
    "            minibatch.shuffle()  # each time shuffle, restore the self.batch_num back to -1\n",
    "            l_loss_tr, l_f1mic_tr, l_f1mac_tr = [], [], []\n",
    "            \n",
    "            actual_batch_num = 0\n",
    "            \n",
    "#             while not minibatch.end():\n",
    "            for batch_idx in range(num_batches):\n",
    "                \n",
    "                node_subgraph, adj_subgraph, norm_loss_subgraph = minibatch.one_batch(mode='train')   # here minibatch should be an interator\n",
    "                # redefine all the function interfaces to explicitely upload and run the training\n",
    "                \n",
    "                ### =========== prepare for all the data to be used ==============\n",
    "                feat_subg = model.feat_full[node_subgraph]\n",
    "                label_subg = model.label_full[node_subgraph]\n",
    "                \n",
    "                if not multilabel:\n",
    "                    # for the multi-class, need type conversion\n",
    "                    label_full_cat = torch.from_numpy(model.label_full.numpy().argmax(axis=1).astype(np.int64))\n",
    "\n",
    "                label_subg_converted = label_subg if multilabel else label_full_cat[node_subgraph]\n",
    "                \n",
    "                t0 = time.time()\n",
    "                # transfer data to the GPU\n",
    "                feat_subg = feat_subg.cuda()\n",
    "                label_subg = label_subg.cuda()\n",
    "                adj_subgraph = adj_subgraph.cuda()\n",
    "                norm_loss_subgraph = norm_loss_subgraph.cuda()\n",
    "                label_subg_converted = label_subg_converted.cuda()\n",
    "                time_upload += time.time() - t0\n",
    "                \n",
    "                \n",
    "                for micro_epoch_idx in range(mini_epoch_num):\n",
    "                    real_epoch_idx = 1 + micro_epoch_idx + macro_epoch_idx * mini_epoch_num + epoch_ph_start\n",
    "                    printf('Epoch {:4d}, Batch ID {}'.format(real_epoch_idx, batch_idx),style='bold')\n",
    "                    # pure training process:\n",
    "                    t1 = time.time()\n",
    "                    loss_train, preds_train = \\\n",
    "                            model.train_step(node_subgraph, adj_subgraph, norm_loss_subgraph, feat_subg, label_subg_converted)\n",
    "                    \n",
    "                    pure_time_train += time.time() - t1\n",
    "                    \n",
    "                    # take a snapshot of current model\n",
    "                    if batch_idx == num_batches - 1 and real_epoch_idx % snapshot_every == 0:\n",
    "                        snap_model_file = snap_model_folder + 'snapshot_epoch_' + str(real_epoch_idx) + '.pkl'\n",
    "                        torch.save(model.state_dict(), snap_model_file)  # store the current state_dict() into the file: 'tmp.pkl'\n",
    "                    \n",
    "                    labels_train = label_subg\n",
    "                    # periodically calculate all the statistics and store them\n",
    "                    if not minibatch.batch_num % eval_train_every:\n",
    "                        # to_numpy already convert tensor onto CPU\n",
    "                        f1_mic, f1_mac = calc_f1(to_numpy(labels_train), to_numpy(preds_train), model.sigmoid_loss)\n",
    "                        l_loss_tr.append(loss_train)\n",
    "                        l_f1mic_tr.append(f1_mic)\n",
    "                        l_f1mac_tr.append(f1_mac)\n",
    "            \n",
    "            \n",
    "        # for different training phase, train it continuously \n",
    "        epoch_ph_start = int(phase['end'])\n",
    "        printf(\"Optimization Finished!\", style=\"yellow\")\n",
    "    \n",
    "    time_train = pure_time_train + time_upload\n",
    "    # after going through all the training phases, print out the total time\n",
    "    printf(\"Total training time: {:6.2f} ms\".format(time_train * 1000), style='red')\n",
    "    printf(\"Total train data uploading time: {:6.2f} ms\".format(time_upload * 1000), style='red')\n",
    "    \n",
    "    return time_train * 1000, time_upload * 1000\n",
    "            \n",
    "\n",
    "def evaluate(snap_model_folder, minibatch_eval, model_eval, epoch_idx, mode='val'):\n",
    "    \"\"\"\n",
    "        Perform the evaluation: either validaiton or test offline from saved snapshot of the models\n",
    "        generate evaluation results from a single timepoint snapshot of the trained model\n",
    "        return : micro_f1 score, macro_f1 score\n",
    "        \n",
    "    \"\"\"\n",
    "    ### location to output the evaluation result\n",
    "    \n",
    "    snap_model_file = snap_model_folder + 'snapshot_epoch_' + str(epoch_idx) + '.pkl'\n",
    "\n",
    "    model_eval.load_state_dict(torch.load(snap_model_file, map_location=lambda storage, loc: storage))\n",
    "\n",
    "    loss_val, f1mic_val, f1mac_val = evaluate_full_batch(model_eval, minibatch_eval, mode = mode)\n",
    "\n",
    "    return f1mic_val, f1mac_val\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multi-execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiexec module:\n",
    "def execute_train_investigate(image_path, work_dir, train_phases, model, minibatch, eval_train_every, \n",
    "                              tune_param_name, tune_val_label, tune_val, trainer_id = 0,\n",
    "                         snapshot_every = 5, mini_epoch_num = 5, multilabel = True, input_neigh_deg = [10, 5],\n",
    "                              core_par_sampler = 1, samples_per_processor = 200):\n",
    "    \"\"\"\n",
    "        return all validation-F1 for all four models\n",
    "    \"\"\"\n",
    "    # run the training process for the model\n",
    "    tune_model_folder = work_dir + 'model_snapshot/tune_' + tune_param_name + '_' + str(tune_val_label) + \\\n",
    "                        '/model_trainer_' + str(trainer_id) + '/'\n",
    "    \n",
    "    os.makedirs(os.path.dirname(tune_model_folder), exist_ok=True)\n",
    "    \n",
    "    # to apply any tuning values\n",
    "    total_time_train, time_upload = train_investigate(tune_model_folder, train_phases, model, minibatch, eval_train_every, \n",
    "                                    snapshot_every = snapshot_every, mini_epoch_num = tune_val, multilabel = multilabel, input_neigh_deg = input_neigh_deg,\n",
    "                              core_par_sampler = core_par_sampler, samples_per_processor = samples_per_processor)\n",
    "    \n",
    "    time_info_folder = image_path + 'train_res/tune_' + tune_param_name + '_' + str(tune_val_label) + \\\n",
    "                                    '/model_trainer_' + str(trainer_id) + '/'\n",
    "    \n",
    "    os.makedirs(os.path.dirname(time_info_folder), exist_ok=True)\n",
    "    \n",
    "    time_info_file_name = time_info_folder + 'train_time'\n",
    "    with open(time_info_file_name, \"wb\") as fp:\n",
    "        pickle.dump((total_time_train, time_upload), fp)\n",
    "            \n",
    "    \n",
    "def execute_validation_investigate(image_path, work_dir, minibatch_eval, model_eval, snapshot_epoch_list, \n",
    "                                 tune_param_name, tune_val_label, tune_val, trainer_id = 0):\n",
    "    \"\"\"\n",
    "        Perform the validaiton offline from saved snapshot of the models\n",
    "        snapshot_epoch_list :  a list of the saved models to perform evaluation\n",
    "    \"\"\"\n",
    "    \n",
    "    tune_model_folder = work_dir + 'model_snapshot/tune_' + tune_param_name + '_' + str(tune_val_label) + \\\n",
    "                                    '/model_trainer_' + str(trainer_id) + '/'\n",
    "    \n",
    "    validation_res_folder = image_path + 'validation_res/tune_' + tune_param_name + '_' + str(tune_val_label) + \\\n",
    "                                    '/validation_trainer_' + str(trainer_id) + '/'\n",
    "    \n",
    "    os.makedirs(os.path.dirname(validation_res_folder), exist_ok=True)\n",
    "    \n",
    "    # start evaluation:\n",
    "    for validation_epoch in snapshot_epoch_list:\n",
    "        \n",
    "        res = evaluate(tune_model_folder, minibatch_eval, model_eval, validation_epoch)\n",
    "        \n",
    "        validation_res_file_name = validation_res_folder + 'model_epoch_' + str(validation_epoch)\n",
    "        with open(validation_res_file_name, \"wb\") as fp:\n",
    "            pickle.dump(res, fp)\n",
    "\n",
    "            \n",
    "    \n",
    "def execute_test_tuning(image_path, work_dir, minibatch_eval, model_eval, snapshot_epoch_list, \n",
    "                                 tune_param_name, tune_val_label, tune_val, trainer_id = 0):\n",
    "    \"\"\"\n",
    "        1) After the validation, select the epoch with the best validation score\n",
    "        2) use the trained model at the selected optimal epoch of validation\n",
    "        3) perform the evaluate func for the test data\n",
    "    \"\"\"\n",
    "    # start to search for the trained model epoch with the best validation f1 socre\n",
    "    f1mic_best, ep_best = 0, -1\n",
    "    validation_res_folder = image_path + 'validation_res/tune_' + tune_param_name + '_' + str(tune_val_label) + \\\n",
    "                                    '/validation_trainer_' + str(trainer_id) + '/'\n",
    "    \n",
    "    for validation_epoch in snapshot_epoch_list:\n",
    "        validation_res_file_name = validation_res_folder + 'model_epoch_' + str(validation_epoch)\n",
    "        with open(validation_res_file_name, \"rb\") as fp:\n",
    "            f1mic_val, f1mac_val = pickle.load(fp)\n",
    "        \n",
    "        if f1mic_val > f1mic_best:\n",
    "            f1mic_best, ep_best = f1mic_val, validation_epoch\n",
    "        \n",
    "    # use the selected model to perform on the test\n",
    "    tune_model_folder = work_dir + 'model_snapshot/tune_' + tune_param_name + '_' + str(tune_val_label) + \\\n",
    "                                    '/model_trainer_' + str(trainer_id) + '/'\n",
    "    \n",
    "    # return 1) micro-f1 ;  2) macro-f1\n",
    "    res = evaluate(tune_model_folder, minibatch_eval, model_eval, ep_best, mode = 'test')\n",
    "    \n",
    "    # save the selected best saved snapshot\n",
    "    best_model_file = tune_model_folder + 'snapshot_epoch_' + str(ep_best) + '.pkl'\n",
    "    shutil.copy2(best_model_file, tune_model_folder + 'best_saved_snapshot.pkl')\n",
    "    \n",
    "    # store the resulting data on the disk\n",
    "    test_res_folder = image_path + 'test_res/tune_' + tune_param_name + '_' + str(tune_val_label) + '/'\n",
    "    os.makedirs(os.path.dirname(test_res_folder), exist_ok=True)\n",
    "    test_res_file = test_res_folder + 'res_trainer_' + str(trainer_id)\n",
    "    \n",
    "    with open(test_res_file, \"wb\") as fp:\n",
    "        pickle.dump(res, fp)\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '/home/xiangli/projects/tmpdata/GCN/GraphSaint/'\n",
    "\n",
    "working_dir = './res_step0_sage_all_in_one/'\n",
    "prepare_data_folder = working_dir + 'prepare_data/'\n",
    "img_path = working_dir + 'result/'\n",
    "\n",
    "core_par_sampler = 1\n",
    "samples_per_processor = -(-200 // core_par_sampler) # round up division\n",
    "eval_train_every = 5  # period to record the train loss\n",
    "\n",
    "### ================ Start to do flexible settings according to different dataset: \n",
    "# read the total epoch number from the yml file to determine the mini_epoch_num and eval_train_every\n",
    "data_name = 'Flickr'\n",
    "# train_config_yml = './table2/flickr2_e.yml'\n",
    "train_config_yml = './table2/flickr2_sage.yml'\n",
    "multilabel_tag = False\n",
    "\n",
    "# data_name = 'PPI_small'\n",
    "# train_config_yml = './table2/ppi2_e.yml'\n",
    "\n",
    "\n",
    "tune_param_name = 'mini_epoch_num'\n",
    "tune_val_label_list = [1, 5] \n",
    "tune_val_list = [val for val in tune_val_label_list]\n",
    "\n",
    "snapshot_period = 5   # period when to take a snapshot of the model for validation later\n",
    "\n",
    "# refer to the yml file to decide the training period:\n",
    "model_epoch_list = list(range(snapshot_period, 31, snapshot_period))    # snapshot epoch list for validation\n",
    "\n",
    "trainer_list = list(range(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/ipykernel_launcher.py:26: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data..\n",
      "Done loading training data..\n"
     ]
    }
   ],
   "source": [
    "# =============== Step1 *** prepare for the batches, models, model_evaluation\n",
    "train_params, train_phases, train_data, arch_gcn = train_setting(data_name, datapath, train_config_yml)\n",
    "prepare(working_dir, train_data, train_params, arch_gcn)\n",
    "train_phase_file_name = prepare_data_folder + 'model_train_phase'\n",
    "with open(train_phase_file_name, \"wb\") as fp:\n",
    "    dill.dump(train_phases, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Study using the adj_train to generate the train neighbor nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_full, adj_train, feat_full, class_arr, role = train_data\n",
    "adj_full = adj_full.astype(np.int32)\n",
    "adj_train = adj_train.astype(np.int32)\n",
    "node_train = np.array(role['tr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"node_train Type is: {} ; and Shape is {} \".format(type(node_train), node_train.shape) )\n",
    "print(\"adj_train.indptr info:  \", type(adj_train.indptr), adj_train.indptr.shape, adj_train.indptr[:5])\n",
    "print(\"adj_full.indptr info:  \", type(adj_full.indptr), adj_full.indptr.shape, adj_full.indptr[:5])\n",
    "v = 0\n",
    "print( sum(adj_train.data[adj_train.indptr[v]:adj_train.indptr[v+1] ] ) )\n",
    "print( adj_train.indices[adj_train.indptr[v]:adj_train.indptr[v+1] ]  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_neigh_deg = [10, 5]  # first neigh layer choose 10; second neigh layer choose 5...\n",
    "max_deg = sum(input_neigh_deg)\n",
    "neigh_adj_train = np.zeros((adj_train.indptr.shape[0], max_deg)) \n",
    "\n",
    "for train_id in node_train:\n",
    "    neighbors = [np.array([train_id])]\n",
    "    \n",
    "    for deg in input_neigh_deg:\n",
    "        neigh_layer = np.unique( np.concatenate([adj_train.indices[adj_train.indptr[train_idx]:adj_train.indptr[train_idx+1] ] for train_idx in neighbors[-1]] ) )\n",
    "        if len(neigh_layer) >= deg:\n",
    "            neighbors.append(np.random.choice(neigh_layer, deg, replace=False) )\n",
    "        elif len(neigh_layer) > 0:\n",
    "            neighbors.append( neigh_layer )\n",
    "        else:\n",
    "            break\n",
    "    # no neighbors for the current train node, then skip:\n",
    "    if len(neighbors) == 1:\n",
    "        continue\n",
    "    # otherwise: store all the neighbor nodes of each train node inside the array:\n",
    "    neighbors = np.unique(np.concatenate(neighbors[1:]))\n",
    "    neigh_adj_train[train_id][:len(neighbors)] = neighbors[:]\n",
    "    \n",
    "neigh_adj_train_csr = sp.csr_matrix(neigh_adj_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the dense form of the sparse matrix\n",
    "print(neigh_adj_train[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the sparse form, investigate how to retrieve a specific train node's neighbors:\n",
    "print(type(neigh_adj_train_csr.data), neigh_adj_train_csr.data.shape)\n",
    "\n",
    "neigh_adj_train_csr_data = neigh_adj_train_csr.data.astype(np.int32)\n",
    "#\n",
    "target_train_node = 0\n",
    "print( neigh_adj_train_csr_data[neigh_adj_train_csr.indptr[target_train_node]:neigh_adj_train_csr.indptr[target_train_node+1] ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique( np.concatenate([neigh_adj_train.indices[neigh_adj_train.indptr[train_idx]:neigh_adj_train.indptr[train_idx+1] ] for train_idx in node_train] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== Step2 *** conduct the training process\n",
    "train_input_file_name = prepare_data_folder + 'model_train_input'\n",
    "with open(train_input_file_name, \"rb\") as fp:\n",
    "    minibatch, model = dill.load(fp)\n",
    "\n",
    "\n",
    "train_phase_file_name = prepare_data_folder + 'model_train_phase'\n",
    "with open(train_phase_file_name, \"rb\") as fp:\n",
    "    train_phases = dill.load(fp)\n",
    "\n",
    "for tune_val_label, tune_val in zip(tune_val_label_list, tune_val_list):\n",
    "    for trainer_id in trainer_list:\n",
    "        execute_train_investigate(img_path, working_dir, train_phases, model, minibatch, eval_train_every, \n",
    "                                  tune_param_name, tune_val_label, tune_val, trainer_id = trainer_id,\n",
    "                                  snapshot_every = snapshot_period, mini_epoch_num = 5, multilabel = multilabel_tag, input_neigh_deg = [10, 5],\n",
    "                                  core_par_sampler = core_par_sampler, samples_per_processor = samples_per_processor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================ Step3*** investigate validation:\n",
    "evaluation_input_file_name = prepare_data_folder + 'model_eval_input'\n",
    "with open(evaluation_input_file_name, \"rb\") as fp:\n",
    "    minibatch_eval, model_eval = dill.load(fp)\n",
    "\n",
    "for tune_val_label, tune_val in zip(tune_val_label_list, tune_val_list):\n",
    "    for trainer_id in trainer_list:\n",
    "        execute_validation_investigate(img_path, working_dir, minibatch_eval, model_eval, model_epoch_list, \n",
    "                                tune_param_name, tune_val_label, tune_val, trainer_id = trainer_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ================= Step4*** investigate test:\n",
    "evaluation_input_file_name = prepare_data_folder + 'model_eval_input'\n",
    "with open(evaluation_input_file_name, \"rb\") as fp:\n",
    "    minibatch_eval, model_eval = dill.load(fp)\n",
    "\n",
    "for tune_val_label, tune_val in zip(tune_val_label_list, tune_val_list):\n",
    "    for trainer_id in trainer_list:\n",
    "        execute_test_tuning(img_path, working_dir, minibatch_eval, model_eval, model_epoch_list, \n",
    "                                tune_param_name, tune_val_label, tune_val, trainer_id = trainer_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tune_val_label, tune_val in zip(tune_val_label_list, tune_val_list):\n",
    "    for trainer_id in trainer_list:\n",
    "        step51_run_investigation_summarize_whole(data_name, img_path,\n",
    "                                         tune_param_name, tune_val_label, tune_val,\n",
    "                                            trainer_list, model_epoch_list)\n",
    "    \n",
    "for tune_val_label, tune_val in zip(tune_val_label_list, tune_val_list):\n",
    "    for trainer_id in trainer_list:\n",
    "        step50_run_tune_summarize_whole(data_name, img_path, \n",
    "                                    tune_param_name, tune_val_label_list, tune_val_list,\n",
    "                                    trainer_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_1_4_geometric]",
   "language": "python",
   "name": "conda-env-pytorch_1_4_geometric-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
