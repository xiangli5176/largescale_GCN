{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Post_utils import *\n",
    "# from multi_exec import *\n",
    "import torch\n",
    "import time\n",
    "\n",
    "import pickle\n",
    "import dill\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "from metric import *\n",
    "from model_graphsaint import GraphSAINT\n",
    "\n",
    "from utils import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minibatch machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import scipy.sparse as sp\n",
    "import scipy\n",
    "import numpy as np\n",
    "\n",
    "from graphsaint_cython.norm_aggr import *\n",
    "from samplers import *\n",
    "\n",
    "def _coo_scipy2torch(adj):\n",
    "    \"\"\"\n",
    "    convert a scipy sparse COO matrix to torch\n",
    "    \n",
    "    Torch supports sparse tensors in COO(rdinate) format, which can efficiently store and process tensors \n",
    "    for which the majority of elements are zeros.\n",
    "    A sparse tensor is represented as a pair of dense tensors: a tensor of values and a 2D tensor of indices. \n",
    "    A sparse tensor can be constructed by providing these two tensors, as well as the size of the sparse tensor \n",
    "    \"\"\"\n",
    "    values = adj.data\n",
    "    indices = np.vstack((adj.row, adj.col))\n",
    "    i = torch.LongTensor(indices)\n",
    "    v = torch.FloatTensor(values)\n",
    "    \n",
    "    return torch.sparse.FloatTensor(i,v, torch.Size(adj.shape))\n",
    "\n",
    "\n",
    "class Minibatch:\n",
    "    \"\"\"\n",
    "        This minibatch iterator iterates over nodes for supervised learning.\n",
    "        Data transferred to GPU:     A  init: 1) self.adj_full_norm;  2) self.norm_loss_test;\n",
    "                                     B  set_sampler:  1) self.norm_loss_train\n",
    "                                     C  one_batch : 1) subgraph adjacency matrix (adj)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, adj_full_norm, adj_train, role, train_params, cpu_eval = False, num_cpu_core = 1):\n",
    "        \"\"\"\n",
    "        role:       array of string (length |V|)\n",
    "                    storing role of the node ('tr'/'va'/'te')\n",
    "        \"\"\"\n",
    "        self.num_cpu_core = num_cpu_core\n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        if cpu_eval:\n",
    "            self.use_cuda = False\n",
    "        \n",
    "        # store all the node roles as the numpy array:\n",
    "        self.node_train = np.array(role['tr'])\n",
    "        self.node_val = np.array(role['va'])\n",
    "        self.node_test = np.array(role['te'])\n",
    "\n",
    "        # self.adj_full_norm : torch sparse tensor\n",
    "        self.adj_full_norm = _coo_scipy2torch(adj_full_norm.tocoo())\n",
    "        self.adj_train = adj_train\n",
    "        print(\"adj train type is: {}\".format(type(adj_train)))\n",
    "\n",
    "        # below: book-keeping for mini-batch\n",
    "        self.node_subgraph = None\n",
    "        self.batch_num = -1\n",
    "\n",
    "        # all the subgraph attributes should be used for the training process\n",
    "        self.method_sample = None\n",
    "        self.subgraphs_remaining_indptr = []\n",
    "        self.subgraphs_remaining_indices = []\n",
    "        self.subgraphs_remaining_data = []\n",
    "        self.subgraphs_remaining_nodes = []\n",
    "        self.subgraphs_remaining_edge_index = []\n",
    "        \n",
    "        # What is this norm_loss aimed at?\n",
    "        self.norm_loss_train = np.zeros(self.adj_train.shape[0])\n",
    "        # norm_loss_test is used in full batch evaluation (without sampling). so neighbor features are simply averaged.\n",
    "        self.norm_loss_test = np.zeros(self.adj_full_norm.shape[0])\n",
    "        \n",
    "        _denom = len(self.node_train) + len(self.node_val) +  len(self.node_test)\n",
    "        \n",
    "        # instead of assign all elements of self.norm_loss_test to the same averaged denominator, separately assingment instead. \n",
    "        # does this mean there are other meaningless roles beyond: test, train and validation?\n",
    "        self.norm_loss_test[self.node_train] = 1./_denom     \n",
    "        self.norm_loss_test[self.node_val] = 1./_denom\n",
    "        self.norm_loss_test[self.node_test] = 1./_denom\n",
    "        self.norm_loss_test = torch.from_numpy(self.norm_loss_test.astype(np.float32))\n",
    "        \n",
    "            \n",
    "        self.norm_aggr_train = np.zeros(self.adj_train.size)\n",
    "        \n",
    "        self.sample_coverage = train_params['sample_coverage']\n",
    "        self.deg_train = np.array(self.adj_train.sum(1)).flatten()   # sum the degree of each train node, here sum along column for adjacency matrix\n",
    "\n",
    "\n",
    "    def set_sampler(self, train_phases, core_par_sampler = 1, samples_per_processor = 200):\n",
    "        \"\"\"\n",
    "            Train_phases (a dict defined in the .yml file) : usually including : end, smapler, size_subg_edge\n",
    "            end:  number of total epochs to stop\n",
    "            sampler: category for sampler (e.g. edge)\n",
    "            size_subg_edge:  size of the subgraph in number of edges\n",
    "        \"\"\"\n",
    "        self.subgraphs_remaining_indptr = list()\n",
    "        self.subgraphs_remaining_indices = list()\n",
    "        self.subgraphs_remaining_data = list()\n",
    "        self.subgraphs_remaining_nodes = list()\n",
    "        self.subgraphs_remaining_edge_index = list()\n",
    "        \n",
    "        self.method_sample = train_phases['sampler']   # one of the string indicators regarding sampler methods\n",
    "        if self.method_sample == 'mrw':\n",
    "            if 'deg_clip' in train_phases:\n",
    "                _deg_clip = int(train_phases['deg_clip'])\n",
    "            else:\n",
    "                _deg_clip = 100000      # setting this to a large number so essentially there is no clipping in probability\n",
    "            self.size_subg_budget = train_phases['size_subgraph']\n",
    "            self.graph_sampler = mrw_sampling(self.adj_train, self.node_train,\n",
    "                                self.size_subg_budget, train_phases['size_frontier'], _deg_clip, \n",
    "                                        core_par_sampler = core_par_sampler, samples_per_processor = samples_per_processor)\n",
    "        elif self.method_sample == 'rw':\n",
    "            self.size_subg_budget = train_phases['num_root'] * train_phases['depth']\n",
    "            self.graph_sampler = rw_sampling(self.adj_train, self.node_train,\n",
    "                                self.size_subg_budget, int(train_phases['num_root']), int(train_phases['depth']), \n",
    "                                        core_par_sampler = core_par_sampler, samples_per_processor = samples_per_processor)\n",
    "        elif self.method_sample == 'edge':\n",
    "            self.size_subg_budget = train_phases['size_subg_edge'] * 2\n",
    "            self.graph_sampler = edge_sampling(self.adj_train, self.node_train, train_phases['size_subg_edge'], \n",
    "                                        core_par_sampler = core_par_sampler, samples_per_processor = samples_per_processor)\n",
    "        elif self.method_sample == 'node':\n",
    "            self.size_subg_budget = train_phases['size_subgraph']\n",
    "            self.graph_sampler = node_sampling(self.adj_train,self.node_train, self.size_subg_budget, \n",
    "                                        core_par_sampler = core_par_sampler, samples_per_processor = samples_per_processor)\n",
    "        elif self.method_sample == 'full_batch':\n",
    "            self.size_subg_budget = self.node_train.size\n",
    "            self.graph_sampler = full_batch_sampling(self.adj_train,self.node_train, self.size_subg_budget, \n",
    "                                        core_par_sampler = core_par_sampler, samples_per_processor = samples_per_processor)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        self.norm_loss_train = np.zeros(self.adj_train.shape[0])\n",
    "        self.norm_aggr_train = np.zeros(self.adj_train.size).astype(np.float32)\n",
    "\n",
    "        # For edge sampler, no need to estimate norm factors, we can calculate directly.\n",
    "        # However, for integrity of the framework, we decide to follow the same procedure for all samplers: \n",
    "        # 1. sample enough number of subgraphs\n",
    "        # 2. estimate norm factor alpha and lambda\n",
    "        tot_sampled_nodes = 0\n",
    "        while True:\n",
    "            self.par_graph_sample('train')\n",
    "            tot_sampled_nodes = sum([len(n) for n in self.subgraphs_remaining_nodes])\n",
    "            if tot_sampled_nodes > self.sample_coverage * self.node_train.size:\n",
    "                break\n",
    "        print()\n",
    "        num_subg = len(self.subgraphs_remaining_nodes)  # each subgraph nodes are stored as one list inside the self.subgraphs_remaining_nodes\n",
    "        for i in range(num_subg):\n",
    "            self.norm_aggr_train[self.subgraphs_remaining_edge_index[i]] += 1\n",
    "            self.norm_loss_train[self.subgraphs_remaining_nodes[i]] += 1\n",
    "        assert self.norm_loss_train[self.node_val].sum() + self.norm_loss_train[self.node_test].sum() == 0\n",
    "        for v in range(self.adj_train.shape[0]):\n",
    "            i_s = self.adj_train.indptr[v]\n",
    "            i_e = self.adj_train.indptr[v+1]\n",
    "            val = np.clip(self.norm_loss_train[v]/self.norm_aggr_train[i_s:i_e], 0, 1e4)\n",
    "            val[np.isnan(val)] = 0.1\n",
    "            self.norm_aggr_train[i_s:i_e] = val\n",
    "        \n",
    "        # normalize the self.norm_loss_train:\n",
    "        self.norm_loss_train[np.where(self.norm_loss_train==0)[0]] = 0.1\n",
    "        self.norm_loss_train[self.node_val] = 0\n",
    "        self.norm_loss_train[self.node_test] = 0\n",
    "        self.norm_loss_train[self.node_train] = num_subg/self.norm_loss_train[self.node_train]/self.node_train.size\n",
    "        self.norm_loss_train = torch.from_numpy(self.norm_loss_train.astype(np.float32))\n",
    "\n",
    "    # each time finish one-time sampling: generate a single sample subgraph\n",
    "    def par_graph_sample(self, phase):\n",
    "        \"\"\"\n",
    "           Phase: can be a string \"train\"\n",
    "        \"\"\"\n",
    "        t0 = time.time()\n",
    "        _indptr, _indices, _data, _v, _edge_index = self.graph_sampler.par_sample(phase)\n",
    "        t1 = time.time()\n",
    "        # create 200 subgraphs per CPU, these 200 graphs may be generated by different cores, but 200 each time, not to exceed the memory limit\n",
    "        print('sampling 200 subgraphs:   time = {:.3f} sec'.format(t1 - t0), end=\"\\r\")\n",
    "        self.subgraphs_remaining_indptr.extend(_indptr)   # add lists into the subgraphs_remaining_indptr, each list is a subgraph\n",
    "        self.subgraphs_remaining_indices.extend(_indices)\n",
    "        self.subgraphs_remaining_data.extend(_data)\n",
    "        self.subgraphs_remaining_nodes.extend(_v)\n",
    "        self.subgraphs_remaining_edge_index.extend(_edge_index)\n",
    "\n",
    "    def one_batch(self, mode='train'):\n",
    "        \"\"\"\n",
    "            self.batch_num : for train mode, create one batch and the batch number will be increased by 1\n",
    "        \"\"\"\n",
    "        if mode in ['val','test']:\n",
    "            self.node_subgraph = np.arange(self.adj_full_norm.shape[0])  # include all the nodes inside the graph\n",
    "            adj = self.adj_full_norm\n",
    "        else:\n",
    "            assert mode == 'train'\n",
    "            if len(self.subgraphs_remaining_nodes) == 0:\n",
    "                self.par_graph_sample('train')   # if there is no sampled subgraphs, then make one\n",
    "                print()\n",
    "\n",
    "            self.node_subgraph = self.subgraphs_remaining_nodes.pop()\n",
    "            self.size_subgraph = len(self.node_subgraph)\n",
    "            adj = sp.csr_matrix((self.subgraphs_remaining_data.pop(),\\\n",
    "                                 self.subgraphs_remaining_indices.pop(),\\\n",
    "                                 self.subgraphs_remaining_indptr.pop()),\\\n",
    "                                 shape=(self.size_subgraph,self.size_subgraph))\n",
    "            adj_edge_index = self.subgraphs_remaining_edge_index.pop()\n",
    "            #print(\"{} nodes, {} edges, {} degree\".format(self.node_subgraph.size,adj.size,adj.size/self.node_subgraph.size))\n",
    "            norm_aggr(adj.data, adj_edge_index, self.norm_aggr_train, num_proc = self.num_cpu_core)\n",
    "            adj = adj_norm(adj, deg = self.deg_train[self.node_subgraph])\n",
    "            adj = _coo_scipy2torch(adj.tocoo())\n",
    "            \n",
    "            self.batch_num += 1          # create one batch\n",
    "            \n",
    "        norm_loss = self.norm_loss_test if mode in ['val','test'] else self.norm_loss_train\n",
    "        norm_loss = norm_loss[self.node_subgraph]\n",
    "        # this self.node_subgraph is to select the target nodes, can be left on the CPU\n",
    "        \n",
    "        # for evaluation: all nodes, its adj_full_norm and norm_loss_test \n",
    "        return self.node_subgraph, adj, norm_loss\n",
    "\n",
    "\n",
    "    def num_training_batches(self):\n",
    "        return math.ceil(self.node_train.shape[0] / float(self.size_subg_budget))\n",
    "\n",
    "    def shuffle(self):\n",
    "        self.node_train = np.random.permutation(self.node_train)\n",
    "        self.batch_num = -1\n",
    "\n",
    "    def end(self):\n",
    "        return (self.batch_num + 1) * self.size_subg_budget >= self.node_train.shape[0]   # greater or equal to the number of train nodes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic execution components "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a lambda func\n",
    "f_mean = lambda l: sum(l)/len(l)\n",
    "\n",
    "def evaluate_full_batch(model, minibatch, mode='val'):\n",
    "    \"\"\"\n",
    "        Full batch evaluation: for validation and test sets only.\n",
    "        When calculating the F1 score, we will mask the relevant root nodes.\n",
    "        mode: can be val or test\n",
    "    \"\"\"\n",
    "    loss, preds, labels = model.eval_step(*minibatch.one_batch(mode = mode))\n",
    "    node_val_test = minibatch.node_val if mode=='val' else minibatch.node_test\n",
    "    # may not be necessary \n",
    "    f1_scores = calc_f1(to_numpy(labels[node_val_test]), to_numpy(preds[node_val_test]), model.sigmoid_loss)\n",
    "    return loss, f1_scores[0], f1_scores[1]\n",
    "\n",
    "\n",
    "def train_setting(dataname, datapath, train_config_file):\n",
    "    \"\"\"\n",
    "        YAML (a recursive acronym for \"YAML Ain't Markup Language\") is a human-readable data-serialization language. \n",
    "        It is commonly used for configuration files and in applications where data is being stored or transmitted.\n",
    "    \n",
    "        yaml.load is as powerful as pickle.load and so may call any Python function. Check the yaml.safe_load function though.\n",
    "        The function yaml.load converts a YAML document to a Python object.\n",
    "    \"\"\"\n",
    "    with open(train_config_file) as f_train_config:\n",
    "        train_config = yaml.load(f_train_config)\n",
    "        \n",
    "    arch_gcn = {'dim':-1,\n",
    "                'aggr':'concat',\n",
    "                'loss':'softmax',\n",
    "                'arch':'1',\n",
    "                'act':'I',\n",
    "                'bias':'norm'}\n",
    "    # check the loss:  default to be softmax, multi-class problem, each node can only belong to just one class at last\n",
    "    arch_gcn.update(train_config['network'][0])   # train_config['network'] is a list of dict\n",
    "    \n",
    "    \n",
    "    train_params = {'lr' : 0.01, 'weight_decay' : 0., 'norm_loss':True, 'norm_aggr':True, 'q_threshold' : 50, 'q_offset':0}\n",
    "    train_params.update(train_config['params'][0])\n",
    "    train_phases = train_config['phase']\n",
    "    for ph in train_phases:\n",
    "        assert 'end' in ph\n",
    "        assert 'sampler' in ph\n",
    "    print(\"Loading training data..\")\n",
    "    temp_data = load_data(dataname, datapath = datapath)\n",
    "    train_data = process_graph_data(*temp_data)\n",
    "    print(\"Done loading training data..\")\n",
    "    \n",
    "    # train_data is a tuple: adj_full, adj_train, feats, class_arr, role\n",
    "    return train_params, train_phases, train_data, arch_gcn\n",
    "\n",
    "def prepare(working_dir, train_data, train_params, arch_gcn):\n",
    "    \"\"\"\n",
    "        working_dir: main working dir for experiments\n",
    "        train_params: contain settings for the mini-batch setting\n",
    "        arch_gcn: contain all the settings \n",
    "    \"\"\"\n",
    "    adj_full, adj_train, feat_full, class_arr, role = train_data\n",
    "    adj_full = adj_full.astype(np.int32)\n",
    "    adj_train = adj_train.astype(np.int32)\n",
    "    adj_full_norm = adj_norm(adj_full)\n",
    "    num_classes = class_arr.shape[1]\n",
    "    \n",
    "    # key switch :  cpu_eval (bool)\n",
    "    # establish two models, one for train, one for evaluation, because later the model_eval will load the trained model parameters\n",
    "    \n",
    "    # for training process: on GPU\n",
    "    minibatch = Minibatch(adj_full_norm, adj_train, role, train_params)\n",
    "    model = GraphSAINT(num_classes, arch_gcn, train_params, feat_full, class_arr)\n",
    "    # for evaluation: validaiton/test  : on CPU\n",
    "    minibatch_eval = Minibatch(adj_full_norm, adj_train,role, train_params, cpu_eval=True)\n",
    "    model_eval = GraphSAINT(num_classes, arch_gcn, train_params, feat_full, class_arr, cpu_eval=True)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "        \n",
    "    # model, model_eval, mini_batch_eval can be saved as pickle file for use later\n",
    "\n",
    "    ### but cannot pickle lambda func for now\n",
    "\n",
    "    prepare_data_folder = working_dir + 'prepare_data/'\n",
    "    os.makedirs(os.path.dirname(prepare_data_folder), exist_ok=True)\n",
    "\n",
    "    train_input_file_name = prepare_data_folder + 'model_train_input'\n",
    "    with open(train_input_file_name, \"wb\") as fp:\n",
    "        dill.dump((minibatch, model), fp)\n",
    "\n",
    "    evaluation_input_file_name = prepare_data_folder + 'model_eval_input'\n",
    "    with open(evaluation_input_file_name, \"wb\") as fp:\n",
    "        dill.dump((minibatch_eval, model_eval), fp)\n",
    "    \n",
    "    # return model, minibatch, minibatch_eval, model_eval\n",
    "\n",
    "\n",
    "def train_investigate(snap_model_folder, train_phases, model, minibatch, eval_train_every, snapshot_every = 10,\n",
    "          mini_epoch_num = 5, multilabel = True, core_par_sampler = 1, samples_per_processor = 200):\n",
    "    \"\"\"\n",
    "    PURPOSE:  to go through each training phase and take a snapshot of current mode and saved as pickle files\n",
    "        snap_model_folder : folder to save the model snapshots during training\n",
    "        train_phases:  use defined train fases defined in the .yml file\n",
    "        model :  graphsaint model for training\n",
    "        minibatch:   minibatch for training, usually with batches pool\n",
    "        eval_train_every :  periodically store the train loss during the training process\n",
    "        snapshot_every :  periodically store the states of the trained model for later evaluation\n",
    "        mini_epoch_num :  how long the training will focus on one single batch\n",
    "        multilabel : True if a multi-label task, otherwise a multi-class case\n",
    "        core_par_sampler : how many CPU cores  will be used on each CPU\n",
    "        samples_per_processor : how many samples will be generated from each CPU\n",
    "    return: 1) total training time;  2) data uploading time\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    epoch_ph_start = 0\n",
    "    time_train, time_upload, pure_time_train = 0, 0, 0\n",
    "    \n",
    "    # establish a new folder if it does not exist\n",
    "#     os.makedirs(snap_model_folder, exist_ok = True)\n",
    "    \n",
    "    for ip, phase in enumerate(train_phases):\n",
    "        printf('START PHASE {:4d}'.format(ip),style='underline')\n",
    "        \n",
    "        minibatch.set_sampler(phase, core_par_sampler = core_par_sampler, samples_per_processor = samples_per_processor)  # one of the phases defined in the phase section of the .yml file, here phase is a dict\n",
    "        num_batches = minibatch.num_training_batches()\n",
    "#         print('calculated batch number is: ', num_batches)\n",
    "        \n",
    "        \n",
    "        epoch_ph_end = int(phase['end'])\n",
    "        macro_epoch_part_num = (epoch_ph_end - epoch_ph_start) // mini_epoch_num\n",
    "        for macro_epoch_idx in range(macro_epoch_part_num):\n",
    "            \n",
    "            minibatch.shuffle()  # each time shuffle, restore the self.batch_num back to -1\n",
    "            l_loss_tr, l_f1mic_tr, l_f1mac_tr = [], [], []\n",
    "            \n",
    "            actual_batch_num = 0\n",
    "            \n",
    "#             while not minibatch.end():\n",
    "            for batch_idx in range(num_batches):\n",
    "                \n",
    "                node_subgraph, adj_subgraph, norm_loss_subgraph = minibatch.one_batch(mode='train')   # here minibatch should be an interator\n",
    "                # redefine all the function interfaces to explicitely upload and run the training\n",
    "                \n",
    "                ### =========== prepare for all the data to be used ==============\n",
    "                feat_subg = model.feat_full[node_subgraph]\n",
    "                label_subg = model.label_full[node_subgraph]\n",
    "                \n",
    "                if not multilabel:\n",
    "                    # for the multi-class, need type conversion\n",
    "                    label_full_cat = torch.from_numpy(model.label_full.numpy().argmax(axis=1).astype(np.int64))\n",
    "\n",
    "                label_subg_converted = label_subg if multilabel else label_full_cat[node_subgraph]\n",
    "                \n",
    "                t0 = time.time()\n",
    "                # transfer data to the GPU\n",
    "                feat_subg = feat_subg.cuda()\n",
    "                label_subg = label_subg.cuda()\n",
    "                adj_subgraph = adj_subgraph.cuda()\n",
    "                norm_loss_subgraph = norm_loss_subgraph.cuda()\n",
    "                label_subg_converted = label_subg_converted.cuda()\n",
    "                time_upload += time.time() - t0\n",
    "                \n",
    "                \n",
    "                for micro_epoch_idx in range(mini_epoch_num):\n",
    "                    real_epoch_idx = 1 + micro_epoch_idx + macro_epoch_idx * mini_epoch_num + epoch_ph_start\n",
    "                    printf('Epoch {:4d}, Batch ID {}'.format(real_epoch_idx, batch_idx),style='bold')\n",
    "                    # pure training process:\n",
    "                    t1 = time.time()\n",
    "                    loss_train, preds_train = \\\n",
    "                            model.train_step(node_subgraph, adj_subgraph, norm_loss_subgraph, feat_subg, label_subg_converted)\n",
    "                    \n",
    "                    pure_time_train += time.time() - t1\n",
    "                    \n",
    "                    # take a snapshot of current model\n",
    "                    if batch_idx == num_batches - 1 and real_epoch_idx % snapshot_every == 0:\n",
    "                        snap_model_file = snap_model_folder + 'snapshot_epoch_' + str(real_epoch_idx) + '.pkl'\n",
    "                        torch.save(model.state_dict(), snap_model_file)  # store the current state_dict() into the file: 'tmp.pkl'\n",
    "                    \n",
    "                    labels_train = label_subg\n",
    "                    # periodically calculate all the statistics and store them\n",
    "                    if not minibatch.batch_num % eval_train_every:\n",
    "                        # to_numpy already convert tensor onto CPU\n",
    "                        f1_mic, f1_mac = calc_f1(to_numpy(labels_train), to_numpy(preds_train), model.sigmoid_loss)\n",
    "                        l_loss_tr.append(loss_train)\n",
    "                        l_f1mic_tr.append(f1_mic)\n",
    "                        l_f1mac_tr.append(f1_mac)\n",
    "            \n",
    "            \n",
    "        # for different training phase, train it continuously \n",
    "        epoch_ph_start = int(phase['end'])\n",
    "        printf(\"Optimization Finished!\", style=\"yellow\")\n",
    "    \n",
    "    time_train = pure_time_train + time_upload\n",
    "    # after going through all the training phases, print out the total time\n",
    "    printf(\"Total training time: {:6.2f} ms\".format(time_train * 1000), style='red')\n",
    "    printf(\"Total train data uploading time: {:6.2f} ms\".format(time_upload * 1000), style='red')\n",
    "    \n",
    "    return time_train * 1000, time_upload * 1000\n",
    "            \n",
    "\n",
    "def evaluate(snap_model_folder, minibatch_eval, model_eval, epoch_idx, mode='val'):\n",
    "    \"\"\"\n",
    "        Perform the evaluation: either validaiton or test offline from saved snapshot of the models\n",
    "        generate evaluation results from a single timepoint snapshot of the trained model\n",
    "        return : micro_f1 score, macro_f1 score\n",
    "        \n",
    "    \"\"\"\n",
    "    ### location to output the evaluation result\n",
    "    \n",
    "    snap_model_file = snap_model_folder + 'snapshot_epoch_' + str(epoch_idx) + '.pkl'\n",
    "\n",
    "    model_eval.load_state_dict(torch.load(snap_model_file, map_location=lambda storage, loc: storage))\n",
    "\n",
    "    loss_val, f1mic_val, f1mac_val = evaluate_full_batch(model_eval, minibatch_eval, mode = mode)\n",
    "\n",
    "    return f1mic_val, f1mac_val\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multi-execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiexec module:\n",
    "def execute_train_investigate(image_path, work_dir, train_phases, model, minibatch, eval_train_every, \n",
    "                              tune_param_name, tune_val_label, tune_val, trainer_id = 0,\n",
    "                         snapshot_every = 5, mini_epoch_num = 5, multilabel = True, core_par_sampler = 1, samples_per_processor = 200):\n",
    "    \"\"\"\n",
    "        return all validation-F1 for all four models\n",
    "    \"\"\"\n",
    "    # run the training process for the model\n",
    "    tune_model_folder = work_dir + 'model_snapshot/tune_' + tune_param_name + '_' + str(tune_val_label) + \\\n",
    "                        '/model_trainer_' + str(trainer_id) + '/'\n",
    "    \n",
    "    os.makedirs(os.path.dirname(tune_model_folder), exist_ok=True)\n",
    "    \n",
    "    # to apply any tuning values\n",
    "    total_time_train, time_upload = train_investigate(tune_model_folder, train_phases, model, minibatch, eval_train_every, \n",
    "                                    snapshot_every = snapshot_every, mini_epoch_num = tune_val, multilabel = multilabel, \n",
    "                              core_par_sampler = core_par_sampler, samples_per_processor = samples_per_processor)\n",
    "    \n",
    "    time_info_folder = image_path + 'train_res/tune_' + tune_param_name + '_' + str(tune_val_label) + \\\n",
    "                                    '/model_trainer_' + str(trainer_id) + '/'\n",
    "    \n",
    "    os.makedirs(os.path.dirname(time_info_folder), exist_ok=True)\n",
    "    \n",
    "    time_info_file_name = time_info_folder + 'train_time'\n",
    "    with open(time_info_file_name, \"wb\") as fp:\n",
    "        pickle.dump((total_time_train, time_upload), fp)\n",
    "            \n",
    "    \n",
    "def execute_validation_investigate(image_path, work_dir, minibatch_eval, model_eval, snapshot_epoch_list, \n",
    "                                 tune_param_name, tune_val_label, tune_val, trainer_id = 0):\n",
    "    \"\"\"\n",
    "        Perform the validaiton offline from saved snapshot of the models\n",
    "        snapshot_epoch_list :  a list of the saved models to perform evaluation\n",
    "    \"\"\"\n",
    "    \n",
    "    tune_model_folder = work_dir + 'model_snapshot/tune_' + tune_param_name + '_' + str(tune_val_label) + \\\n",
    "                                    '/model_trainer_' + str(trainer_id) + '/'\n",
    "    \n",
    "    validation_res_folder = image_path + 'validation_res/tune_' + tune_param_name + '_' + str(tune_val_label) + \\\n",
    "                                    '/validation_trainer_' + str(trainer_id) + '/'\n",
    "    \n",
    "    os.makedirs(os.path.dirname(validation_res_folder), exist_ok=True)\n",
    "    \n",
    "    # start evaluation:\n",
    "    for validation_epoch in snapshot_epoch_list:\n",
    "        \n",
    "        res = evaluate(tune_model_folder, minibatch_eval, model_eval, validation_epoch)\n",
    "        \n",
    "        validation_res_file_name = validation_res_folder + 'model_epoch_' + str(validation_epoch)\n",
    "        with open(validation_res_file_name, \"wb\") as fp:\n",
    "            pickle.dump(res, fp)\n",
    "\n",
    "            \n",
    "    \n",
    "def execute_test_tuning(image_path, work_dir, minibatch_eval, model_eval, snapshot_epoch_list, \n",
    "                                 tune_param_name, tune_val_label, tune_val, trainer_id = 0):\n",
    "    \"\"\"\n",
    "        1) After the validation, select the epoch with the best validation score\n",
    "        2) use the trained model at the selected optimal epoch of validation\n",
    "        3) perform the evaluate func for the test data\n",
    "    \"\"\"\n",
    "    # start to search for the trained model epoch with the best validation f1 socre\n",
    "    f1mic_best, ep_best = 0, -1\n",
    "    validation_res_folder = image_path + 'validation_res/tune_' + tune_param_name + '_' + str(tune_val_label) + \\\n",
    "                                    '/validation_trainer_' + str(trainer_id) + '/'\n",
    "    \n",
    "    for validation_epoch in snapshot_epoch_list:\n",
    "        validation_res_file_name = validation_res_folder + 'model_epoch_' + str(validation_epoch)\n",
    "        with open(validation_res_file_name, \"rb\") as fp:\n",
    "            f1mic_val, f1mac_val = pickle.load(fp)\n",
    "        \n",
    "        if f1mic_val > f1mic_best:\n",
    "            f1mic_best, ep_best = f1mic_val, validation_epoch\n",
    "        \n",
    "    # use the selected model to perform on the test\n",
    "    tune_model_folder = work_dir + 'model_snapshot/tune_' + tune_param_name + '_' + str(tune_val_label) + \\\n",
    "                                    '/model_trainer_' + str(trainer_id) + '/'\n",
    "    \n",
    "    # return 1) micro-f1 ;  2) macro-f1\n",
    "    res = evaluate(tune_model_folder, minibatch_eval, model_eval, ep_best, mode = 'test')\n",
    "    \n",
    "    # save the selected best saved snapshot\n",
    "    best_model_file = tune_model_folder + 'snapshot_epoch_' + str(ep_best) + '.pkl'\n",
    "    shutil.copy2(best_model_file, tune_model_folder + 'best_saved_snapshot.pkl')\n",
    "    \n",
    "    # store the resulting data on the disk\n",
    "    test_res_folder = image_path + 'test_res/tune_' + tune_param_name + '_' + str(tune_val_label) + '/'\n",
    "    os.makedirs(os.path.dirname(test_res_folder), exist_ok=True)\n",
    "    test_res_file = test_res_folder + 'res_trainer_' + str(trainer_id)\n",
    "    \n",
    "    with open(test_res_file, \"wb\") as fp:\n",
    "        pickle.dump(res, fp)\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '/home/xiangli/projects/tmpdata/GCN/GraphSaint/'\n",
    "\n",
    "working_dir = './res_step0_all_in_one/'\n",
    "prepare_data_folder = working_dir + 'prepare_data/'\n",
    "img_path = working_dir + 'result/'\n",
    "\n",
    "core_par_sampler = 1\n",
    "samples_per_processor = -(-200 // core_par_sampler) # round up division\n",
    "eval_train_every = 5  # period to record the train loss\n",
    "\n",
    "### ================ Start to do flexible settings according to different dataset: \n",
    "# read the total epoch number from the yml file to determine the mini_epoch_num and eval_train_every\n",
    "data_name = 'Flickr'\n",
    "train_config_yml = './table2/flickr2_e.yml'\n",
    "multilabel_tag = False\n",
    "\n",
    "# data_name = 'PPI_small'\n",
    "# train_config_yml = './table2/ppi2_e.yml'\n",
    "\n",
    "\n",
    "tune_param_name = 'mini_epoch_num'\n",
    "tune_val_label_list = [1, 5] \n",
    "tune_val_list = [val for val in tune_val_label_list]\n",
    "\n",
    "snapshot_period = 5   # period when to take a snapshot of the model for validation later\n",
    "\n",
    "# refer to the yml file to decide the training period:\n",
    "model_epoch_list = list(range(snapshot_period, 16, snapshot_period))    # snapshot epoch list for validation\n",
    "\n",
    "trainer_list = list(range(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/ipykernel_launcher.py:26: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data..\n",
      "Done loading training data..\n"
     ]
    }
   ],
   "source": [
    "# =============== Step1 *** prepare for the batches, models, model_evaluation\n",
    "train_params, train_phases, train_data, arch_gcn = train_setting(data_name, datapath, train_config_yml)\n",
    "prepare(working_dir, train_data, train_params, arch_gcn)\n",
    "train_phase_file_name = prepare_data_folder + 'model_train_phase'\n",
    "with open(train_phase_file_name, \"wb\") as fp:\n",
    "    dill.dump(train_phases, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4mSTART PHASE    0\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/samplers.py:58: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  self.adj_train_norm = scipy.sparse.dia_matrix((1 / self.deg_train,0),shape=adj_train.shape).dot(adj_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling 200 subgraphs:   time = 0.486 sec\n",
      "\u001b[1mEpoch    1, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    1, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    1, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    1, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch    2, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    2, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    2, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    2, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch    3, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    3, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    3, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    3, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch    4, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    4, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    4, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    4, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch    5, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    5, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    5, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    5, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch    6, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    6, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    6, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    6, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch    7, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    7, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    7, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    7, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch    8, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    8, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    8, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    8, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch    9, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    9, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    9, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    9, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch   10, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch   10, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch   10, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch   10, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch   11, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch   11, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch   11, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch   11, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch   12, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch   12, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch   12, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch   12, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch   13, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch   13, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch   13, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch   13, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch   14, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch   14, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch   14, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch   14, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch   15, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch   15, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch   15, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch   15, Batch ID 3\u001b[0m\n",
      "\u001b[93mOptimization Finished!\u001b[0m\n",
      "\u001b[91mTotal training time: 6677.68 ms\u001b[0m\n",
      "\u001b[91mTotal train data uploading time: 157.53 ms\u001b[0m\n",
      "\u001b[4mSTART PHASE    0\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/samplers.py:58: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  self.adj_train_norm = scipy.sparse.dia_matrix((1 / self.deg_train,0),shape=adj_train.shape).dot(adj_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling 200 subgraphs:   time = 0.436 sec\n",
      "\u001b[1mEpoch    1, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    1, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    1, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    1, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch    2, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    2, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    2, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    2, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch    3, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    3, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    3, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    3, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch    4, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    4, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    4, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    4, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch    5, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    5, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    5, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    5, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch    6, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    6, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    6, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    6, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch    7, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    7, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    7, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    7, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch    8, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    8, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    8, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    8, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch    9, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    9, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    9, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    9, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch   10, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch   10, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch   10, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch   10, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch   11, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch   11, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch   11, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch   11, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch   12, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch   12, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch   12, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch   12, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch   13, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch   13, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch   13, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch   13, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch   14, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch   14, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch   14, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch   14, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch   15, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch   15, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch   15, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch   15, Batch ID 3\u001b[0m\n",
      "\u001b[93mOptimization Finished!\u001b[0m\n",
      "\u001b[91mTotal training time: 1801.03 ms\u001b[0m\n",
      "\u001b[91mTotal train data uploading time: 145.16 ms\u001b[0m\n",
      "\u001b[4mSTART PHASE    0\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/samplers.py:58: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  self.adj_train_norm = scipy.sparse.dia_matrix((1 / self.deg_train,0),shape=adj_train.shape).dot(adj_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling 200 subgraphs:   time = 0.424 sec\n",
      "\u001b[1mEpoch    1, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    1, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    1, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    1, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch    2, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    2, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    2, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    2, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch    3, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    3, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    3, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    3, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch    4, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    4, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    4, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    4, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch    5, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    5, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    5, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    5, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch    6, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    6, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    6, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    6, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch    7, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    7, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    7, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    7, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch    8, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    8, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    8, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    8, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch    9, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    9, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    9, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    9, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch   10, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch   10, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch   10, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch   10, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch   11, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch   11, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch   11, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch   11, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch   12, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch   12, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch   12, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch   12, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch   13, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch   13, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch   13, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch   13, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch   14, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch   14, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch   14, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch   14, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch   15, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch   15, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch   15, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch   15, Batch ID 3\u001b[0m\n",
      "\u001b[93mOptimization Finished!\u001b[0m\n",
      "\u001b[91mTotal training time: 1857.33 ms\u001b[0m\n",
      "\u001b[91mTotal train data uploading time: 146.17 ms\u001b[0m\n",
      "\u001b[4mSTART PHASE    0\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/samplers.py:58: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  self.adj_train_norm = scipy.sparse.dia_matrix((1 / self.deg_train,0),shape=adj_train.shape).dot(adj_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling 200 subgraphs:   time = 0.425 sec\n",
      "\u001b[1mEpoch    1, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    2, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    3, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    4, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    5, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    1, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    2, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    3, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    4, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    5, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    1, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    2, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    3, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    4, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    5, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    1, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch    2, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch    3, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch    4, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch    5, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch    6, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    7, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    8, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    9, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch   10, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    6, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    7, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    8, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    9, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch   10, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    6, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    7, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    8, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    9, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch   10, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    6, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch    7, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch    8, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch    9, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch   10, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch   11, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch   12, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch   13, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch   14, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch   15, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch   11, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch   12, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch   13, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch   14, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch   15, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch   11, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch   12, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch   13, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch   14, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch   15, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch   11, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch   12, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch   13, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch   14, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch   15, Batch ID 3\u001b[0m\n",
      "\u001b[93mOptimization Finished!\u001b[0m\n",
      "\u001b[91mTotal training time: 1756.21 ms\u001b[0m\n",
      "\u001b[91mTotal train data uploading time:  28.89 ms\u001b[0m\n",
      "\u001b[4mSTART PHASE    0\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/samplers.py:58: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  self.adj_train_norm = scipy.sparse.dia_matrix((1 / self.deg_train,0),shape=adj_train.shape).dot(adj_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling 200 subgraphs:   time = 0.441 sec\n",
      "\u001b[1mEpoch    1, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    2, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    3, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    4, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    5, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    1, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    2, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    3, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    4, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    5, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    1, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    2, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    3, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    4, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    5, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    1, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch    2, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch    3, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch    4, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch    5, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch    6, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    7, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    8, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    9, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch   10, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    6, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    7, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    8, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    9, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch   10, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    6, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    7, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    8, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    9, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch   10, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    6, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch    7, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch    8, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch    9, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch   10, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch   11, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch   12, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch   13, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch   14, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch   15, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch   11, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch   12, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch   13, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch   14, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch   15, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch   11, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch   12, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch   13, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch   14, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch   15, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch   11, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch   12, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch   13, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch   14, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch   15, Batch ID 3\u001b[0m\n",
      "\u001b[93mOptimization Finished!\u001b[0m\n",
      "\u001b[91mTotal training time: 1774.53 ms\u001b[0m\n",
      "\u001b[91mTotal train data uploading time:  29.53 ms\u001b[0m\n",
      "\u001b[4mSTART PHASE    0\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/samplers.py:58: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  self.adj_train_norm = scipy.sparse.dia_matrix((1 / self.deg_train,0),shape=adj_train.shape).dot(adj_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling 200 subgraphs:   time = 0.428 sec\n",
      "\u001b[1mEpoch    1, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    2, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    3, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    4, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    5, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    1, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    2, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    3, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    4, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    5, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    1, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    2, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    3, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    4, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    5, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    1, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch    2, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch    3, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch    4, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch    5, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch    6, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    7, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    8, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    9, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch   10, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch    6, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    7, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    8, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    9, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch   10, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch    6, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    7, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    8, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    9, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch   10, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch    6, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch    7, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch    8, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch    9, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch   10, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch   11, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch   12, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch   13, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch   14, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch   15, Batch ID 0\u001b[0m\n",
      "\u001b[1mEpoch   11, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch   12, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch   13, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch   14, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch   15, Batch ID 1\u001b[0m\n",
      "\u001b[1mEpoch   11, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch   12, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch   13, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch   14, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch   15, Batch ID 2\u001b[0m\n",
      "\u001b[1mEpoch   11, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch   12, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch   13, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch   14, Batch ID 3\u001b[0m\n",
      "\u001b[1mEpoch   15, Batch ID 3\u001b[0m\n",
      "\u001b[93mOptimization Finished!\u001b[0m\n",
      "\u001b[91mTotal training time: 1806.56 ms\u001b[0m\n",
      "\u001b[91mTotal train data uploading time:  30.78 ms\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# ============== Step2 *** conduct the training process\n",
    "train_input_file_name = prepare_data_folder + 'model_train_input'\n",
    "with open(train_input_file_name, \"rb\") as fp:\n",
    "    minibatch, model = dill.load(fp)\n",
    "\n",
    "\n",
    "train_phase_file_name = prepare_data_folder + 'model_train_phase'\n",
    "with open(train_phase_file_name, \"rb\") as fp:\n",
    "    train_phases = dill.load(fp)\n",
    "\n",
    "for tune_val_label, tune_val in zip(tune_val_label_list, tune_val_list):\n",
    "    for trainer_id in trainer_list:\n",
    "        execute_train_investigate(img_path, working_dir, train_phases, model, minibatch, eval_train_every, \n",
    "                                  tune_param_name, tune_val_label, tune_val, trainer_id = trainer_id,\n",
    "                                  snapshot_every = snapshot_period, mini_epoch_num = 5, multilabel = multilabel_tag, \n",
    "                                  core_par_sampler = core_par_sampler, samples_per_processor = samples_per_processor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================ Step3*** investigate validation:\n",
    "evaluation_input_file_name = prepare_data_folder + 'model_eval_input'\n",
    "with open(evaluation_input_file_name, \"rb\") as fp:\n",
    "    minibatch_eval, model_eval = dill.load(fp)\n",
    "\n",
    "for tune_val_label, tune_val in zip(tune_val_label_list, tune_val_list):\n",
    "    for trainer_id in trainer_list:\n",
    "        execute_validation_investigate(img_path, working_dir, minibatch_eval, model_eval, model_epoch_list, \n",
    "                                tune_param_name, tune_val_label, tune_val, trainer_id = trainer_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ================= Step4*** investigate test:\n",
    "evaluation_input_file_name = prepare_data_folder + 'model_eval_input'\n",
    "with open(evaluation_input_file_name, \"rb\") as fp:\n",
    "    minibatch_eval, model_eval = dill.load(fp)\n",
    "\n",
    "for tune_val_label, tune_val in zip(tune_val_label_list, tune_val_list):\n",
    "    for trainer_id in trainer_list:\n",
    "        execute_test_tuning(img_path, working_dir, minibatch_eval, model_eval, model_epoch_list, \n",
    "                                tune_param_name, tune_val_label, tune_val, trainer_id = trainer_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start summarizing for dataset : Flickr\n",
      "Start summarizing for dataset : Flickr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = plt.subplots(nrow, ncol, **kwargs)\n",
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/Post_utils.py:76: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n",
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = plt.subplots(nrow, ncol, **kwargs)\n",
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/Post_utils.py:76: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n",
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = plt.subplots(nrow, ncol, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start summarizing for dataset : Flickr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/Post_utils.py:76: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n",
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = plt.subplots(nrow, ncol, **kwargs)\n",
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/Post_utils.py:76: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n",
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = plt.subplots(nrow, ncol, **kwargs)\n",
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/Post_utils.py:76: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n",
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = plt.subplots(nrow, ncol, **kwargs)\n",
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/Post_utils.py:76: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n",
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = plt.subplots(nrow, ncol, **kwargs)\n",
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/Post_utils.py:76: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n",
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = plt.subplots(nrow, ncol, **kwargs)\n",
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/Post_utils.py:76: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n",
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = plt.subplots(nrow, ncol, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start summarizing for dataset : Flickr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/Post_utils.py:76: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n",
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = plt.subplots(nrow, ncol, **kwargs)\n",
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/Post_utils.py:76: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n",
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = plt.subplots(nrow, ncol, **kwargs)\n",
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/Post_utils.py:76: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n",
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = plt.subplots(nrow, ncol, **kwargs)\n",
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/Post_utils.py:76: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n",
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = plt.subplots(nrow, ncol, **kwargs)\n",
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/Post_utils.py:76: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n",
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = plt.subplots(nrow, ncol, **kwargs)\n",
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/Post_utils.py:76: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n",
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = plt.subplots(nrow, ncol, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start summarizing for dataset : Flickr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/Post_utils.py:76: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n",
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = plt.subplots(nrow, ncol, **kwargs)\n",
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/Post_utils.py:76: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n",
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = plt.subplots(nrow, ncol, **kwargs)\n",
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/Post_utils.py:76: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n",
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = plt.subplots(nrow, ncol, **kwargs)\n",
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/Post_utils.py:76: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n",
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = plt.subplots(nrow, ncol, **kwargs)\n",
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/Post_utils.py:76: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n",
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = plt.subplots(nrow, ncol, **kwargs)\n",
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/Post_utils.py:76: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n",
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = plt.subplots(nrow, ncol, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start summarizing for dataset : Flickr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/Post_utils.py:76: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n",
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = plt.subplots(nrow, ncol, **kwargs)\n",
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/Post_utils.py:76: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n",
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = plt.subplots(nrow, ncol, **kwargs)\n",
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/Post_utils.py:76: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n",
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = plt.subplots(nrow, ncol, **kwargs)\n",
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/Post_utils.py:76: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n",
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = plt.subplots(nrow, ncol, **kwargs)\n",
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/Post_utils.py:76: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n",
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = plt.subplots(nrow, ncol, **kwargs)\n",
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/Post_utils.py:76: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n",
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = plt.subplots(nrow, ncol, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start running training for dataset: Flickr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/Post_utils.py:178: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n",
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = plt.subplots(nrow, ncol, **kwargs)\n",
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/Post_utils.py:178: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n",
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = plt.subplots(nrow, ncol, **kwargs)\n",
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/Post_utils.py:178: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n",
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = plt.subplots(nrow, ncol, **kwargs)\n",
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/Post_utils.py:178: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n",
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = plt.subplots(nrow, ncol, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start running training for dataset: Flickr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/Post_utils.py:178: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n",
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = plt.subplots(nrow, ncol, **kwargs)\n",
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/Post_utils.py:178: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n",
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = plt.subplots(nrow, ncol, **kwargs)\n",
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/Post_utils.py:178: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n",
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = plt.subplots(nrow, ncol, **kwargs)\n",
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/Post_utils.py:178: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n",
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = plt.subplots(nrow, ncol, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start running training for dataset: Flickr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/Post_utils.py:178: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n",
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = plt.subplots(nrow, ncol, **kwargs)\n",
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/Post_utils.py:178: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n",
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = plt.subplots(nrow, ncol, **kwargs)\n",
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/Post_utils.py:178: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n",
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = plt.subplots(nrow, ncol, **kwargs)\n",
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/Post_utils.py:178: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n",
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = plt.subplots(nrow, ncol, **kwargs)\n",
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/Post_utils.py:178: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n",
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = plt.subplots(nrow, ncol, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start running training for dataset: Flickr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/Post_utils.py:178: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n",
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = plt.subplots(nrow, ncol, **kwargs)\n",
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/Post_utils.py:178: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n",
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = plt.subplots(nrow, ncol, **kwargs)\n",
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/Post_utils.py:178: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n",
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = plt.subplots(nrow, ncol, **kwargs)\n",
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/Post_utils.py:178: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n",
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = plt.subplots(nrow, ncol, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start running training for dataset: Flickr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/Post_utils.py:178: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n",
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = plt.subplots(nrow, ncol, **kwargs)\n",
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/Post_utils.py:178: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n",
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = plt.subplots(nrow, ncol, **kwargs)\n",
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/Post_utils.py:178: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n",
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = plt.subplots(nrow, ncol, **kwargs)\n",
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/Post_utils.py:178: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n",
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = plt.subplots(nrow, ncol, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start running training for dataset: Flickr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/Post_utils.py:178: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n",
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = plt.subplots(nrow, ncol, **kwargs)\n",
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/Post_utils.py:178: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n",
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = plt.subplots(nrow, ncol, **kwargs)\n",
      "/home/xiangli/projects/GCN_program/largescale_GCN/HPC_version_GCN/11_GraphSaint_hpc/gold_all_in_one/Post_utils.py:178: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure()\n",
      "/home/xiangli/anaconda3/envs/pytorch_1_4_geometric/lib/python3.7/site-packages/seaborn/axisgrid.py:324: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = plt.subplots(nrow, ncol, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for tune_val_label, tune_val in zip(tune_val_label_list, tune_val_list):\n",
    "    for trainer_id in trainer_list:\n",
    "        step51_run_investigation_summarize_whole(data_name, img_path,\n",
    "                                         tune_param_name, tune_val_label, tune_val,\n",
    "                                            trainer_list, model_epoch_list)\n",
    "    \n",
    "for tune_val_label, tune_val in zip(tune_val_label_list, tune_val_list):\n",
    "    for trainer_id in trainer_list:\n",
    "        step50_run_tune_summarize_whole(data_name, img_path, \n",
    "                                    tune_param_name, tune_val_label_list, tune_val_list,\n",
    "                                    trainer_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_1_4_geometric]",
   "language": "python",
   "name": "conda-env-pytorch_1_4_geometric-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
