{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import metis\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partition GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Parameter\n",
    "from torch_scatter import scatter_add\n",
    "from torch_geometric.nn import MessagePassing\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import add_remaining_self_loops\n",
    "import math\n",
    "\n",
    "def glorot(tensor):\n",
    "    if tensor is not None:\n",
    "        stdv = math.sqrt(6.0 / (tensor.size(-2) + tensor.size(-1)))\n",
    "        tensor.data.uniform_(-stdv, stdv)\n",
    "#         tensor.data.fill_(1.0)   # trivial example\n",
    "        \n",
    "def zeros(tensor):\n",
    "    if tensor is not None:\n",
    "        tensor.data.fill_(0)\n",
    "\n",
    "class custom_GCNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels, improved=False, cached=False,\n",
    "                 bias=True, **kwargs):\n",
    "        super().__init__(aggr='add', **kwargs)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.improved = improved\n",
    "        self.cached = cached\n",
    "\n",
    "        self.weight = Parameter(torch.Tensor(in_channels, out_channels))\n",
    "\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.Tensor(out_channels))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        self.reset_parameters()\n",
    "#         print('display the initial weight: ', self.weight)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        glorot(self.weight)\n",
    "        zeros(self.bias)\n",
    "        self.cached_result = None\n",
    "        self.cached_num_edges = None\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def norm(edge_index, num_nodes, edge_weight=None, improved=False, dtype=None):\n",
    "        \n",
    "        if edge_weight is None:\n",
    "            edge_weight = torch.ones((edge_index.size(1), ), dtype=dtype, device=edge_index.device)\n",
    "        \n",
    "        fill_value = 1 if not improved else 2\n",
    "        \n",
    "        edge_index, edge_weight = add_remaining_self_loops(\n",
    "            edge_index, edge_weight, fill_value, num_nodes)\n",
    "        \n",
    "        row, col = edge_index\n",
    "        deg = scatter_add(edge_weight, row, dim=0, dim_size=num_nodes)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "        \n",
    "        return edge_index, deg_inv_sqrt[row] * edge_weight * deg_inv_sqrt[col]\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight=None):\n",
    "        \"\"\"\"\"\"\n",
    "#         print('\\n Inside the GCNConv forward: \\n display current weights: ', self.weight)\n",
    "        x = torch.matmul(x, self.weight)\n",
    "        \n",
    "        \n",
    "        if self.cached and self.cached_result is not None:\n",
    "            if edge_index.size(1) != self.cached_num_edges:\n",
    "                raise RuntimeError(\n",
    "                    'Cached {} number of edges, but found {}. Please '\n",
    "                    'disable the caching behavior of this layer by removing '\n",
    "                    'the `cached=True` argument in its constructor.'.format(\n",
    "                        self.cached_num_edges, edge_index.size(1)))\n",
    "        \n",
    "        if not self.cached or self.cached_result is None:\n",
    "            self.cached_num_edges = edge_index.size(1)\n",
    "            edge_index, norm = self.norm(edge_index, x.size(0), edge_weight,\n",
    "                                         self.improved, x.dtype)\n",
    "            self.cached_result = edge_index, norm\n",
    "\n",
    "        edge_index, norm = self.cached_result\n",
    "#         print('\\n *********May use the topology info: \\n')\n",
    "#         print('shape of edge_index: ', edge_index.shape)\n",
    "#         print('shapes of normalized of the edge_weight (edge_weight)', norm.shape)\n",
    "        \n",
    "        res = self.propagate(edge_index, x=x, norm=norm)\n",
    "#         print('\\n display the forward result from a single GCNConv, aggregated features ')\n",
    "#         print('print type shape and values: ', type(res), res.shape, res)\n",
    "#         print('\\n End of the GCNCOnv foward')\n",
    "        \n",
    "        return res\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        return norm.view(-1, 1) * x_j\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        if self.bias is not None:\n",
    "            aggr_out = aggr_out + self.bias\n",
    "        return aggr_out\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}({}, {})'.format(self.__class__.__name__, self.in_channels,\n",
    "                                   self.out_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) Establish a simple model based on a customized single GCNConv layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ListModule(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Abstract list layer class.\n",
    "    \"\"\"\n",
    "    def __init__(self, *args):\n",
    "        \"\"\"\n",
    "        Module initializing.\n",
    "        \"\"\"\n",
    "        super(ListModule, self).__init__()\n",
    "        idx = 0\n",
    "        for module in args:\n",
    "            self.add_module(str(idx), module)\n",
    "            idx += 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Getting the indexed layer.\n",
    "        \"\"\"\n",
    "        if idx < 0 or idx >= len(self._modules):\n",
    "            raise IndexError('index {} is out of range'.format(idx))\n",
    "        it = iter(self._modules.values())\n",
    "        for i in range(idx):\n",
    "            next(it)\n",
    "        return next(it)\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "        Iterating on the layers.\n",
    "        \"\"\"\n",
    "        return iter(self._modules.values())\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Number of layers.\n",
    "        \"\"\"\n",
    "        return len(self._modules)\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, input_layers = [32, 16], dropout=0.3):\n",
    "        \"\"\"\n",
    "        input layers: list of integers\n",
    "        dropout: probability of droping out \n",
    "        \"\"\"\n",
    "        super(Net, self).__init__()\n",
    "        # one trivial example\n",
    "#         self.conv1 = custom_GCNConv(in_channels, out_channels)\n",
    "#         self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.input_layers = input_layers\n",
    "        self.dropout = dropout\n",
    "        self.setup_layers()\n",
    "\n",
    "    def setup_layers(self):\n",
    "        \"\"\"\n",
    "        Creating the layes based on the args.\n",
    "        \"\"\"\n",
    "        self.layers = []\n",
    "        self.input_layers = [self.in_channels] + self.input_layers + [self.out_channels]\n",
    "        for i, _ in enumerate(self.input_layers[:-1]):\n",
    "            self.layers.append(custom_GCNConv(self.input_layers[i],self.input_layers[i+1]))\n",
    "        self.layers = ListModule(*self.layers)\n",
    "\n",
    "\n",
    "    def forward(self, edge_index, features):\n",
    "#         print('\\n Inside the foward of the Net model, before call the conv1: ')\n",
    "#         print('used type and shape of edge_index: ', type(edge_index), edge_index.shape)\n",
    "#         print('used type and shape of features: ', type(features), features.shape)\n",
    "        # single layer case\n",
    "#         features = self.conv1(features, edge_index)\n",
    "#         print('after call the conv1: ')\n",
    "#         print('aggregated features , type, shape, values : ', type(features), features.shape, features)\n",
    "        \n",
    "        for i, _ in enumerate(self.input_layers[:-2]):\n",
    "            features = F.relu(self.layers[i](features, edge_index))\n",
    "            if i>1:\n",
    "                features = F.dropout(features, p = self.dropout, training = self.training)\n",
    "        features = self.layers[i+1](features, edge_index)\n",
    "        predictions = F.log_softmax(features, dim=1)\n",
    "#         print('calculated predictions , type, shape, values : ', type(predictions), predictions.shape, predictions)\n",
    "#         print('End of calling the Net model foward \\n')\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partition method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import metis\n",
    "import random\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class ClusteringMachine(object):\n",
    "    \"\"\"\n",
    "    Clustering the graph, feature set and label. Performed on the CPU side\n",
    "    \"\"\"\n",
    "    def __init__(self, edge_index, features, label, partition_num = 2):\n",
    "        \"\"\"\n",
    "        :param edge_index: COO format of the edge indices.\n",
    "        :param features: Feature matrix (ndarray).\n",
    "        :param label: label vector (ndarray).\n",
    "        \"\"\"\n",
    "        tmp = edge_index.t().numpy().tolist()\n",
    "#         tmp = edge_index.t().cpu().numpy().tolist()\n",
    "        self.graph = nx.from_edgelist(tmp)\n",
    "        self.edge_index = edge_index\n",
    "        self.features = features\n",
    "        self.label = label\n",
    "        self.partition_num = partition_num\n",
    "        self._set_sizes()\n",
    "\n",
    "    def _set_sizes(self):\n",
    "        \"\"\"\n",
    "        Setting the feature and class count.\n",
    "        \"\"\"\n",
    "        self.node_count = self.features.shape[0]\n",
    "        self.feature_count = self.features.shape[1]    # features all always in the columns\n",
    "        self.label_count = torch.max(self.label)+1\n",
    "\n",
    "    def decompose(self, test_ratio):\n",
    "        \"\"\"\n",
    "        Decomposing the graph, partitioning the features and label, creating Torch arrays.\n",
    "        \"\"\"\n",
    "        # ways of generating isolated clusters\n",
    "#         self.random_clustering()\n",
    "        self.metis_clustering()\n",
    "        # initial settings for the linking between different isolated clusters\n",
    "        self._set_inter_clusters()\n",
    "        \n",
    "        self.general_data_partitioning(test_ratio)\n",
    "        self.general_data_intersect(test_ratio)\n",
    "        # transfer the data segments to other devices such as GPU\n",
    "        self.transfer_edges_and_nodes()\n",
    "\n",
    "    # just allocate each node to arandom cluster, store the membership inside each dict\n",
    "    def random_clustering(self):\n",
    "        \"\"\"\n",
    "        Random clustering the nodes.\n",
    "        \"\"\"\n",
    "        print(\"\\nRandom graph clustering started.\\n\")\n",
    "        self.clusters = [cluster for cluster in range(self.partition_num)]\n",
    "        # randomly divide into two clusters\n",
    "        self.cluster_membership = {node: random.choice(self.clusters) for node in self.graph.nodes()}\n",
    "        # for trial case : half-half devision, single part one or two partitions\n",
    "#         self.cluster_membership = {node: 0 for node in range(self.node_count // self.partition_num)}\n",
    "#         if self.partition_num > 1:\n",
    "#             self.cluster_membership.update({node: 1 for node in range(self.node_count // self.partition_num, self.node_count)})\n",
    "        \n",
    "    def metis_clustering(self):\n",
    "        \"\"\"\n",
    "        Clustering the graph with Metis. For details see:\n",
    "        \"\"\"\n",
    "        print(\"\\n metis graph clustering started.\\n\")\n",
    "        (st, parts) = metis.part_graph(self.graph, self.partition_num)\n",
    "        self.clusters = list(set(parts))\n",
    "        self.cluster_membership = {node: membership for node, membership in enumerate(parts)}\n",
    "\n",
    "    def _set_inter_clusters(self):\n",
    "        # independent of the clustering method:\n",
    "        self.intersect_cluster = []\n",
    "        for i in range(1, self.partition_num):\n",
    "            tmp = [(m, n) for m, n in zip(self.clusters, self.clusters[i:])]\n",
    "            self.intersect_cluster.extend(tmp)\n",
    "        # initialize as the totla edges (without duplicates) all over the whole graph\n",
    "        self.macro_inter_edges = set(self.graph.edges())\n",
    "        \n",
    "    def general_data_partitioning(self, test_ratio):\n",
    "        \"\"\"\n",
    "        Creating data partitions and train-test splits.\n",
    "        \"\"\"\n",
    "        self.sg_nodes = {}\n",
    "        self.sg_edges = {}\n",
    "        \n",
    "        self.sg_train_nodes = {}\n",
    "        self.sg_test_nodes = {}\n",
    "        \n",
    "        self.sg_features = {}\n",
    "        self.sg_labels = {}\n",
    "        \n",
    "        \n",
    "        # for each cluster we have six dicts to separate overall attributes into different clusters\n",
    "        for cluster in self.clusters:\n",
    "            # Returns a SubGraph view of the subgraph induced on nodes.\n",
    "            # The induced subgraph of the graph contains the nodes in nodes and the edges between those nodes.\n",
    "\n",
    "            subgraph = self.graph.subgraph([node for node in sorted(self.graph.nodes()) if self.cluster_membership[node] == cluster])\n",
    "            self.sg_nodes[cluster] = [node for node in sorted(subgraph.nodes())]\n",
    "            \n",
    "            # what about the edges outside? Currently ignore those in-between clusters edges\n",
    "\n",
    "            # map each node into it's index inside its own cluster\n",
    "            # create own indices of each node inside its cluster, can we still use the global index ? yes\n",
    "            # we sort the nodes is to make sure it is consistent with the features and labels, nothing to do with edges\n",
    "            mapper = {node: i for i, node in enumerate(sorted(self.sg_nodes[cluster]))}\n",
    "\n",
    "            # the edges inside its own partition, from two directions since it is an undirected graph\n",
    "            # the edges order does not matter\n",
    "            self.sg_edges[cluster] = [[mapper[edge[0]], mapper[edge[1]]] for edge in subgraph.edges()] +  \\\n",
    "                                       [[mapper[edge[1]], mapper[edge[0]]] for edge in subgraph.edges()]\n",
    "            \n",
    "            # update the macro inter-sect edges:\n",
    "            # because graph.subgraph's edge index may not follow the same order as graph.edges()\n",
    "            self.macro_inter_edges -= set([(edge[0], edge[1]) for edge in subgraph.edges()] +  \\\n",
    "                                       [(edge[1], edge[0]) for edge in subgraph.edges()])\n",
    "#             print('cluster: ', cluster, 'mcro_inter_edges: ', self.macro_inter_edges)\n",
    "            \n",
    "            # for each cluster divide into train/test groups:\n",
    "            self.sg_train_nodes[cluster], self.sg_test_nodes[cluster] = train_test_split(list(mapper.values()), test_size = test_ratio)\n",
    "            \n",
    "            self.sg_test_nodes[cluster] = sorted(self.sg_test_nodes[cluster])\n",
    "            self.sg_train_nodes[cluster] = sorted(self.sg_train_nodes[cluster])\n",
    "\n",
    "            # extract specific rows from the feature matrix\n",
    "            self.sg_features[cluster] = self.features[self.sg_nodes[cluster],:]\n",
    "            # labels are 1-D tensor with class labels\n",
    "            self.sg_labels[cluster] = self.label[self.sg_nodes[cluster]]\n",
    "\n",
    "    def general_data_intersect(self, test_ratio):\n",
    "        \"\"\"\n",
    "            create data intersection between different isolate partitions of data\n",
    "        \"\"\"\n",
    "        self.inter_nodes = defaultdict(set)\n",
    "        self.inter_edges = defaultdict(list)\n",
    "        \n",
    "        self.inter_train_nodes = {}\n",
    "        self.inter_test_nodes = {}\n",
    "        \n",
    "        self.inter_features = {}\n",
    "        self.inter_labels = {}\n",
    "        \n",
    "        # first we have to divide the remaining inter-cluster nodes and edges, in isolate cluster, we know that be graph.nodes() or graph.edges()\n",
    "        # here we only know the edges as stored inside the macro_inter_edges\n",
    "        for start, end in self.macro_inter_edges:\n",
    "            start_cluster_id = self.cluster_membership[start]\n",
    "            end_cluster_id = self.cluster_membership[end]\n",
    "            \n",
    "            # make sure the smaller is before the larger, to be consistent with the rule as indicated by the self.intersect_cluster\n",
    "            if start_cluster_id > end_cluster_id:\n",
    "                start_cluster_id, end_cluster_id = end_cluster_id, start_cluster_id\n",
    "            \n",
    "            self.inter_nodes[(start_cluster_id, end_cluster_id)] |= {start, end}\n",
    "            \n",
    "            # the edges inside its own partition, from two directions since it is an undirected graph\n",
    "            self.inter_edges[(start_cluster_id, end_cluster_id)].append([start, end])\n",
    "        \n",
    "        for inter_cluster in self.intersect_cluster:\n",
    "            self.inter_nodes[inter_cluster] = sorted(list(self.inter_nodes[inter_cluster]))\n",
    "            \n",
    "            # need to use the mapper re-index the edges\n",
    "            mapper = {node: i for i, node in enumerate(self.inter_nodes[inter_cluster])}\n",
    "            self.inter_edges[inter_cluster] = [[mapper[edge[0]], mapper[edge[1]]] for edge in self.inter_edges[inter_cluster]] +  \\\n",
    "                                       [[mapper[edge[1]], mapper[edge[0]]] for edge in self.inter_edges[inter_cluster]]\n",
    "            \n",
    "            # for each cluster divide into train/test groups:\n",
    "            self.inter_train_nodes[inter_cluster], self.inter_test_nodes[inter_cluster] = train_test_split(list(mapper.values()), test_size = test_ratio)\n",
    "            \n",
    "            self.inter_test_nodes[inter_cluster] = sorted(self.inter_test_nodes[inter_cluster])\n",
    "            self.inter_train_nodes[inter_cluster] = sorted(self.inter_train_nodes[inter_cluster])\n",
    "\n",
    "            # extract specific rows from the feature matrix\n",
    "            self.inter_features[inter_cluster] = self.features[self.inter_nodes[inter_cluster],:]\n",
    "            # labels are 1-D tensor with class labels\n",
    "            self.inter_labels[inter_cluster] = self.label[self.inter_nodes[inter_cluster]]\n",
    "        \n",
    "            \n",
    "    def transfer_edges_and_nodes(self):\n",
    "        \"\"\"\n",
    "        Transfering the data to PyTorch format.\n",
    "        \"\"\"\n",
    "        for cluster in self.clusters:\n",
    "            # for the isolated-cluster data\n",
    "            self.sg_nodes[cluster] = torch.LongTensor(self.sg_nodes[cluster])\n",
    "\n",
    "            self.sg_edges[cluster] = torch.LongTensor(self.sg_edges[cluster]).t()\n",
    "            # Expects input to be <= 2-D tensor and transposes dimensions 0 and 1.\n",
    "            self.sg_train_nodes[cluster] = torch.LongTensor(self.sg_train_nodes[cluster])\n",
    "            self.sg_test_nodes[cluster] = torch.LongTensor(self.sg_test_nodes[cluster])\n",
    "            self.sg_features[cluster] = torch.FloatTensor(self.sg_features[cluster])\n",
    "            self.sg_labels[cluster] = torch.LongTensor(self.sg_labels[cluster])\n",
    "        \n",
    "        for inter_cluster in self.intersect_cluster:\n",
    "            # for the inter-cluster data\n",
    "            self.inter_nodes[inter_cluster] = torch.LongTensor(self.inter_nodes[inter_cluster])\n",
    "\n",
    "            self.inter_edges[inter_cluster] = torch.LongTensor(self.inter_edges[inter_cluster]).t()\n",
    "            # Expects input to be <= 2-D tensor and transposes dimensions 0 and 1.\n",
    "            self.inter_train_nodes[inter_cluster] = torch.LongTensor(self.inter_train_nodes[inter_cluster])\n",
    "            self.inter_test_nodes[inter_cluster] = torch.LongTensor(self.inter_test_nodes[inter_cluster])\n",
    "            self.inter_features[inter_cluster] = torch.FloatTensor(self.inter_features[inter_cluster])\n",
    "            self.inter_labels[inter_cluster] = torch.LongTensor(self.inter_labels[inter_cluster])\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partition Graph with trainiing and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class ClusterGCNTrainer(object):\n",
    "    \"\"\"\n",
    "    Training a ClusterGCN.\n",
    "    \"\"\"\n",
    "    def __init__(self, clustering_machine, in_channels, out_channels):\n",
    "        \"\"\"\n",
    "        :param ags: Arguments object.\n",
    "        :param clustering_machine:\n",
    "        \"\"\"  \n",
    "        self.clustering_machine = clustering_machine\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.create_model(in_channels, out_channels)\n",
    "\n",
    "    def create_model(self, in_channels, out_channels):\n",
    "        \"\"\"\n",
    "        Creating a StackedGCN and transferring to CPU/GPU.\n",
    "        \"\"\"\n",
    "        self.model = Net(in_channels, out_channels)\n",
    "#         self.model = StackedGCN(self.args, self.clustering_machine.feature_count, self.clustering_machine.class_count)\n",
    "        self.model = self.model.to(self.device)\n",
    "    \n",
    "    # call the forward function batch by batch\n",
    "    def do_forward_pass(self, cluster):\n",
    "        \"\"\"\n",
    "        Making a forward pass with data from a given partition.\n",
    "        :param cluster: Cluster index.\n",
    "        :return average_loss: Average loss on the cluster.\n",
    "        :return node_count: Number of nodes.\n",
    "        \"\"\"\n",
    "        # the edges inside each clustered have been re-mark with local indices inside the cluster\n",
    "        edges = self.clustering_machine.sg_edges[cluster].to(self.device)\n",
    "        macro_nodes = self.clustering_machine.sg_nodes[cluster].to(self.device)\n",
    "        \n",
    "        # already re-index each node inside its local cluster\n",
    "        train_nodes = self.clustering_machine.sg_train_nodes[cluster].to(self.device)\n",
    "        # features has the implicit index, for N1 by K matrix, it always implies node indices: [0, N1-1]\n",
    "        features = self.clustering_machine.sg_features[cluster].to(self.device)\n",
    "        # torch.squeeze()  removes all the dimension with value 1, change the target from 2-D  (N by 1) into 1-D N tensor\n",
    "        \n",
    "        target = self.clustering_machine.sg_labels[cluster].to(self.device)\n",
    "        \n",
    "        # calculate the probabilites from log_sofmax\n",
    "        predictions = self.model(edges, features)\n",
    "#         print('info about predictions the isolated cluster batch number: #', cluster)\n",
    "#         print(predictions)\n",
    "        # trial sum loss\n",
    "        ave_loss = torch.nn.functional.nll_loss(predictions[train_nodes], target[train_nodes])\n",
    "        \n",
    "#         print('info about sum loss of the batch number: #', cluster)\n",
    "#         print(ave_loss)\n",
    "#         print('after the GCN based model forward, loss type and shape: ', type(ave_loss), ave_loss.shape, ave_loss.item())\n",
    "        \n",
    "        node_count = train_nodes.shape[0]\n",
    "\n",
    "        # for each cluster keep track of the counts of the nodes\n",
    "        return ave_loss, node_count\n",
    "    def do_forward_pass_inter(self, inter_cluster):\n",
    "        \"\"\"\n",
    "        Making a forward pass with data from a given partition.\n",
    "        :param inter_cluster: inter_inter_cluster index.\n",
    "        :return ave_loss: total loss on the inter inter_cluster.\n",
    "        :return node_count: Number of nodes.\n",
    "        \"\"\"\n",
    "        edges = self.clustering_machine.inter_edges[inter_cluster].to(self.device)\n",
    "        macro_nodes = self.clustering_machine.inter_nodes[inter_cluster].to(self.device)\n",
    "        \n",
    "        train_nodes = self.clustering_machine.inter_train_nodes[inter_cluster].to(self.device)\n",
    "        features = self.clustering_machine.inter_features[inter_cluster].to(self.device)\n",
    "        target = self.clustering_machine.inter_labels[inter_cluster].to(self.device)\n",
    "        \n",
    "        predictions = self.model(edges, features)\n",
    "#         print('info about predictions the inter inter_cluster batch number: #', inter_cluster)\n",
    "#         print(predictions)\n",
    "        ave_loss = torch.nn.functional.nll_loss(predictions[train_nodes], target[train_nodes])\n",
    "        \n",
    "#         print('info about sum loss of the inter inter_cluster batch number: #', inter_cluster)\n",
    "#         print(ave_loss)\n",
    "#         print('after the GCN based model forward, inter inter_cluster loss type and shape: ', type(ave_loss), ave_loss.shape, ave_loss.item())\n",
    "        node_count = train_nodes.shape[0]\n",
    "\n",
    "        return ave_loss, node_count\n",
    "\n",
    "\n",
    "    def update_average_loss(self, batch_average_loss, node_count, isolate = True):\n",
    "        \"\"\"\n",
    "        Updating the average loss in the epoch.\n",
    "        :param batch_average_loss: Loss of the cluster. \n",
    "        :param node_count: Number of nodes in currently processed cluster.\n",
    "        :return average_loss: Average loss in the epoch.\n",
    "        \"\"\"\n",
    "        self.accumulated_training_loss = self.accumulated_training_loss + batch_average_loss.item()*node_count\n",
    "        if isolate:\n",
    "            self.node_count_seen = self.node_count_seen + node_count\n",
    "        average_loss = self.accumulated_training_loss / self.node_count_seen\n",
    "        return average_loss\n",
    "\n",
    "    def do_prediction(self, cluster):\n",
    "        \"\"\"\n",
    "        Scoring a cluster.\n",
    "        :param cluster: Cluster index.\n",
    "        :return prediction: Prediction matrix with probabilities.\n",
    "        :return target: Target vector.\n",
    "        \"\"\"\n",
    "        edges = self.clustering_machine.sg_edges[cluster].to(self.device)\n",
    "        macro_nodes = self.clustering_machine.sg_nodes[cluster].to(self.device)\n",
    "        test_nodes = self.clustering_machine.sg_test_nodes[cluster].to(self.device)\n",
    "        features = self.clustering_machine.sg_features[cluster].to(self.device)\n",
    "        target = self.clustering_machine.sg_labels[cluster].to(self.device)\n",
    "        prediction = self.model(edges, features)\n",
    "        \n",
    "        return prediction[test_nodes], target[test_nodes]\n",
    "\n",
    "    # iterate through epoch and also the clusters\n",
    "    def train(self, epoch_num=10, learning_rate=0.01):\n",
    "        \"\"\"\n",
    "        Training a model.\n",
    "        \"\"\"\n",
    "#         print(\"Training started.\\n\")\n",
    "\n",
    "#         epochs = trange(epoch_num, desc = \"Train Loss\")\n",
    "        epochs = tqdm(range(epoch_num), desc = \"Train Loss\")\n",
    "        # A shortcut for tqdm(xrange(args), *kwargs). On Python3+ range is used instead of xrange.\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "        self.model.train()\n",
    "\n",
    "        for epoch in epochs:\n",
    "            print('\\n during the training epoch: # ', epoch)\n",
    "            random.shuffle(self.clustering_machine.clusters)\n",
    "            self.node_count_seen = 0\n",
    "            self.accumulated_training_loss = 0\n",
    "            # calculate each isolated cluster:\n",
    "            print('\\nstart training the isolated cluster:')\n",
    "            for cluster in self.clustering_machine.clusters:\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                batch_ave_loss, node_count = self.do_forward_pass(cluster)\n",
    "                batch_ave_loss.backward()\n",
    "                self.optimizer.step()\n",
    "                ave_loss = self.update_average_loss(batch_ave_loss, node_count)\n",
    "            \n",
    "            print(\"Train sum loss of isolated clusters: %g\" % round(self.accumulated_training_loss,4))\n",
    "            print(\"Train ave loss of isolated clusters over all nodes : %g\" % round(ave_loss,4))\n",
    "            # calculate inter-cluster:\n",
    "            print('\\nstart training the inter-cluster:')\n",
    "            for inter_cluster in self.clustering_machine.intersect_cluster:\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                batch_ave_loss, node_count = self.do_forward_pass_inter(inter_cluster)\n",
    "                batch_ave_loss.backward()\n",
    "                self.optimizer.step()\n",
    "                ave_loss = self.update_average_loss(batch_ave_loss, node_count, isolate = False)\n",
    "                \n",
    "            print(\"Train sum loss of all clusters including inter linking edges: %g\" % round(self.accumulated_training_loss,4))\n",
    "            print(\"Train ave loss of all clusters including inter linking edges over all nodes : %g\" % round(ave_loss,4))\n",
    "#             epochs.set_description(\"Total Train sum Loss: %g\" % round(self.accumulated_training_loss,4))\n",
    "            epochs.set_description(\"Ave Train Loss over all nodes: %g\" % round(ave_loss,4))\n",
    "\n",
    "    def test(self):\n",
    "        \"\"\"\n",
    "        Scoring the test and printing the F-1 score.\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        self.predictions = []\n",
    "        self.targets = []\n",
    "        for cluster in self.clustering_machine.clusters:\n",
    "            prediction, target = self.do_prediction(cluster)\n",
    "\n",
    "            self.predictions.append(prediction.cpu().detach().numpy())\n",
    "            self.targets.append(target.cpu().detach().numpy())\n",
    "        \n",
    "        # concatenate all the ndarrays inside this list\n",
    "        self.targets = np.concatenate(self.targets)\n",
    "        # along axis:    axis == 1\n",
    "        self.predictions = np.concatenate(self.predictions).argmax(1)  # return the indices of maximum probability \n",
    "#         print('shape of the targets and predictions are: ', self.targets.shape, self.predictions.shape)\n",
    "        \n",
    "        score = f1_score(self.targets, self.predictions, average=\"micro\")\n",
    "        print(\"\\nF-1 score: {:.4f}\".format(score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 0.],\n",
      "        [1., 1.],\n",
      "        [0., 1.]]) torch.Size([10, 2])\n"
     ]
    }
   ],
   "source": [
    "'''Trivial data'''\n",
    "edge_index = torch.tensor([[0, 1, 0, 8, 1, 3, 1, 2, 4, 2, 4, 6, 6, 7, 7, 9, 2, 5, 5, 9, 9, 8], \n",
    "                           [1, 0, 8, 0, 3, 1, 2, 1, 2, 4, 6, 4, 7, 6, 9, 7, 5, 2, 9, 5, 8, 9]])\n",
    "# features = torch.rand(10, 3)\n",
    "features = torch.tensor([[0, 1], [1, 0], [0, 1], [1, 0], [1, 1],  \n",
    "                           [1, 1], [0, 1], [0, 0], [1, 1], [0, 1]], dtype = torch.float)\n",
    "label = torch.tensor([0, 0, 1, 1, 1, 0, 1, 0, 1, 1])\n",
    "\n",
    "print(features, features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAADnCAYAAAC9roUQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO2deXxU5fX/37MkM1lJCCEB2WQ3wQTZBBQJLvCViqDFr1qotZbCt1h3VBS1tT9RtCKttoCiaCuKC3VFWwRZVCAoUEAJIQTIBmQnGbLMZJb7+yNMyGRmMpNk5t47yfN+vXgZ7jz3ucfL3E/OPc95ztFIkiQhEAgEAlnQKm2AQCAQdCWE6AoEAoGMCNEVCAQCGRGiKxAIBDIiRFcgEAhkRIiuQCAQyIgQXYFAIJARIboCgUAgI0J0BQKBQEaE6AoEAoGMCNEVCAQCGdErbYBAnZTXWNiwr4jsYhMms41Yo57hybHcMroPCdEGpc0TCEIWjSh4I2jOwcIq/r49lx05ZQBYbI6mz4x6LRKQMSyRhZMHk943TiErBYLQRYiuH3QVr29dZh5Lv8zGbLPT2rdCowGjXseS6cOZO36AbPYJBJ0BIbqt0JW8vkbBPUK91eF78HkiwrQsmX6JEF5BpyeQjpcQXS90Ja/vYGEVt63JpN5qdzku2Ro4u3UttdnfIjXUE540iPhr5mHoPaxpTESYjvfnjyetT2j/0hEIPBEMx0tkL3jggtfXuuACSBLUW+0s/fII6zLzZLEv0Px9ey5mm93teOWW1zi3fyO6qDgihozHciqbkveewF5X3TTGbLOzcnuunOYKBLKwLjOP29ZksvlICRabw0VwAcznj32VVcJtazL9fv6F6LbgYGEVS7/MbtNrNkC91cHSL7M5VFQVJMuCQ3mNhR05ZW6/XOy1VdQc2gIaLUm3LSVx5iNEpWYgNdRzbt/GpnGSBNuOllFRY5HZcoEgeATT8RKi2wJvXp+T2qwd5C+7gfxlN1C55TWXz0LR69uwr8jjcWt5AThs6GIT0UU1vjaFJw8GoKH0pMtYDbBhv+d5BIJQI9iOl8jTbYY3r8+JzVRO5aaVoNWBw12Ym3t9oZLVkF1scnttArDXngVAG25sOqY5/7PzMydmm4PsM+eCaKVAIB/eHK+GkhOc3f4mDWdykWwN6Lv1JGb0DcSM+lnTGKfjtXruGK/zC0+3Gd68PgBJkqj44iV0MQlEDpvodVyoeX0ms83jcV1UPACOBnPTMen8z87PXOexBsE6gUBeWnO8Sv/1DOaT/0UXk0DEoNFYK4qo/GoV5vxDTWP8CbcJ0W2GN68P4NwPn2IuyqLHjEVodOFe5wg1ry/W6PllJ6xHX9DqsZvKmjxby5kcAMJ7XuxhnrDgGSkQyIQ3x0uy27CfKwegx42LSLzpccKTBwFgqy5xGevL8RLhhWZ48/oayvI4u+MfxE2aS3jSQD/mCR2vb3hyLAZ9sdsvG11UPNGXXkPNwU2UrF9CWGJ/6o58hyY8gpjRN7iMNeq1DO8VI6fZAkFQ8OZ4aXR6YsbM4NwPn1L+2YuEde9NQ/FxwnpeTOTQCS5jfTleQnSb4c3rqzu6C+w2zAU/Yik83LSQVH9sD2f14cRn3NlintDx+maP7sOKLTkeP4u/dj7o9NQd+Rbr2TMYLhpG/NW/QRfZzWWcBMwe1UcGawWC4OLN8QKIHDKBupxMrGV5WMvyQKsncsh4NOERHubx7ngJ0W2GN6+vMcAjYT6xz+WwrboEy6lsl2Oh5vX1iDYweWgim4+UuMWxtGEGEqb+joSpv/N6vkYDU4YlhszCoUDQGt4cL3u9idIP/4BktZA053nCEvtT+v6TVO9cjy4qzmUxrXEe746XiOk2Y/Zoz95a3KQ59F+8selP1IhrAIgZcyPJc5a5jA1Fr+/ujMEY9bp2nWvU61iYMTjAFgkEytDoeLnLoq2qBMlqAa0eQ6+h6IzRhCX0BcBaXugy1pfjJUS3GU6vT6Np3/mh6vWl941jyfThRIS17evQWHthuNgCLOg0eHO8whL6ojXGgMNGyXtLKN/4ErVZ3wBg6JviMtaX4yVqL7TAWx0Cfwj1OgR+15sAJJuFJ2eM4DdXDZXNPrXSVarQdRXmv73XY7jNcvooVd+8TUPx8aY83eiR/0Ps2JlNYzQamJaS1GqerhBdD3TliluHiqpYuT2XbUfL0NC4EuvEWeBjyrBESra9zYBYLStWrFDMVqXpSlXouhLBdryE6HphXWYef/r8MA02B2i9v3ZrAGNYaFcZ80RFjYUN+4vIPnMOk9lKrDGM4b1imD2q0XurqKhgxIgRfPzxx4wfP15pc2WnK1Wh64oE0/ESousFSZIYde0sel/7a3LrDB69vgarjURbKWvu/3nIhhQ6wvvvv8+f/vQn9u/fj8HQdV6ju/KbUFciWL9Yheh6YcOGDTz77LPs3buXs3VWj15fRj8jE0ZdyuHDh+nVq5fSJsuOJEnMnDmTUaNG8cc//lFpc2TB26tn+caXMOcdwF5vQhseSXjyYOIn/6pp1xKEfsy/K+IMt319pARrQwPoL+xGbR5uW5gx2O9/VyG6HrDZbKSmpvLyyy8zbdq0Vsfed999hIeH8+c//1km69RFUVERl112Gdu2bWPEiBFKmxN0vC2yFL+zGF1MAlpDJOb8Q9gqT6GLTaTPwjebxvizyCJQJytWruHzw2WkXzXdY7itLQjR9cBrr73G+++/z5YtW9D4yB8rKioiPT2dnJwcEhISZLJQXbz66qu8+eab7Ny5E52uffm+oUB5jYUrnt/qtT6HE0txLsVv3Q8aLf0WfYRGdyHh3qDXsuvRq0VWQ4hx5513MnHiRObPn9/huUSebgvq6up4+umnWbZsmU/BBejTpw8333wzL7/8sgzWqZPf/va3GI1GXnnlFaVNCSqtVaEDMO37nIpNKyn/rPGtJ3bcLBfBhdCrQidoZNeuXUyYMMH3QD8QotuCv/71r0ycOJGxY8f6fc6jjz7KypUrMZlMQbRMvWi1WtasWcMzzzzDyZMnfZ8QorRWhQ6gLnsnNf/9sjG0ENMDw0UpbmNCrQqdAMrKyigpKSElxf3fsz0I0W1GZWUly5cvZ+nSpW06b/DgwUydOpWVK1cGyTL1M2TIEB555BHmz59PZ41YtVYMBSB5zjL6LfqIxJufwF5TSdknz2GrKnEbF0pV6ASwe/duxo8fH7DQmRDdZjz33HPMnj2boUPbvsvqscce4y9/+Qt1dXVBsCw0ePDBB6msrOStt95S2pSg4K0YisNqQTrfSUSjDydi4OjGLhsOu1ut1cZ5QqcKnaBRdCdO9N64oK2IKmPnKSgo4I033uCnn35q1/kjRoxgwoQJvP7669x7770Bti400Ov1vPHGG0ydOpXrr7+e5ORkpU0KKN6q0DWcPkr55y9i6JuK1hiNpfAwkqUObWQ3wpMGuYwNtSp0gsZ47pIlSwI2n8heOM9dd91FcnIyzz77bLvn2Lt3LzfddBPHjx8nPNx7d4nOzpIlSzh69CgbNmxQ2pSA4i17wVp5iop/v4K1LB9HQz26yFgMfVLodsVthCcOcBkrshdCC6vVSnx8PKdOnaJbt26+T/AD4ekCWVlZbNy4kZwcz8W8/WXMmDGkpqbyz3/+k3nz5gXIutDjySefZOTIkXz00UfcfPPNSpsTMHpEG7hyUHe+zi4FzYXIXFj3i9xKfHoiVKvQdWUOHDjAwIEDAya4IGK6ADz++OM8+uijxMV1fKfQkiVLWLZsGTZb64sunRmj0cjrr7/OPffcw9mzZ32fECKcPHmSPW/+Ca3UttbcTkTt4dAj0PFcEKLLzp072b9/P3fffXdA5ps0aRK9e/fmgw8+CMh8ocqVV17JrFmzWLRokdKmBIQtW7YwYcIE5v98Gk/PShe1h7sIgczPddKlY7qSJHHVVVdx11138etf/zpg827atImHHnqIQ4cOoW2lQllnx2Qycemll7J27VquueYapc1pF5IksXz5cpYvX8769evJyMgARJWxrkK/fv34+uuvGTJkSMDm7LqKAHzxxRecPXuWO+64I6DzTp06FaPRyKeffhrQeUON2NhYVq1axW9/+1tqa2uVNqfN1NXVMWfOHNavX8+ePXuaBBdg7vgBvD9/PNNSkjDotRhbtHgx6rUY9FqmpSTx/vzxQnBDkKKiIurr6xk8OLAhoS7r6drtdkaOHMnSpUu58cYbAz7/xx9/zNKlS/nhhx/82k7cmZk7dy5JSUksX75caVP85uTJk9x0001ceumlvPbaa0REuHd8deKr9rAgNPnwww9Zt25d4J0nqYvy1ltvSVdccYXkcDiCMr/dbpdSU1Ol//znP0GZP5QoKyuTkpKSpD179ihtil9s3rxZSkpKkv7yl78E7fshUD/333+/9NxzzwV83i4puvX19VK/fv2kb7/9NqjXWbdunTRp0qSgXiNUePfdd6URI0ZIFotFaVO84nA4pBdffFFKTk6Wtm7dqrQ5AoUZN26ctGPHjoDP2yXDCytWrGDbtm189tlnQb2OzWZj2LBhvPXWW0yaNCmo11I7kiQxY8YMxo0bx1NPPaW0OW7U1dUxb948jh49ykcffUT//v2VNkmgIPX19fTo0YOysjIiIyMDOneXW0irrq7mueee69DOM3/R6/U89thjbS6g0xnRaDSsWrWKV155haysLKXNceHkyZNMnDgRnU7Hd999JwRXwL59+0hNTQ244EInXUhrrSX2imX/j6KiItmKsjQ0NDBo0CA+/vhjBgy/tMu36l69ejX/+Mc/+O6771RR8HzLli3MnTuXxx57jHvvvbfLL3oKGnnhhRc4deoUf/3rXwM+d6cSXV8tsR2SRG3uD6xddCvTxgyXza7HX3yVL/JsmOMHerSrK7XqdjgcTJkyhZ///OeKFgaSJImXXnqJF198kXfffZcpU6YoZotAfcyaNYvbb7+dW2+9NeBzdxrR9TdZHclBRHiYbMnq6zLzeObLI9RbbGhaa+XehZLoc3JymDhxInv37mXAgAGyX1/EbwWtIUkSSUlJ7Nu3j759+wZ8/k4R073QEtuH4AJotNRb7Sz98gjrMvNksctsdbQquACShGx2Kc3QoUNZtGgRCxYskL3guYjfCnxx4sQJDAZDUAQXOoGn66kldsW/X8ZSdASbqQyNLozw3kOJn3IX4YmuD1gwW2J7a9Vdd3QX1bs/xFqeDzo94YkDSJz9FDpjtCx2qQWr1crll1/Offfdx69+9StZrinitwJ/ePvtt/n888+DVj8l5D3dv2/PxWxzFbaag1+hMUQSlXIVGkMk5hP7KP3gKSRbg8s4s83Oyu25stlVm7WDso+fpaEsj4ghlxM17Eocljokq1k2u9RCWFgYb7zxBg8//DAlJe7dFQKJdL5+wi9/+UvWr1/PfffdJwRX4JVdu3YFvLJYc0K6nm55jYUdOWVuIYWkuX/G2OcSAGxVJZxa/Rvs5ypoKC/AkHxhH7UkwbajZVTUWAKaPeDJLkmSOLv9rUb7/vdpjP3TvJ4fLLvUxmWXXcZvfvMb7rnnnqB5Fc3jt5mZmSKcIPDJ7t27A1oAqyUh7el6a4ntFFwAyXG+rq1Giy66u9vYYLTE9mSX7exp7KYyNHoD1Xv+RcHy2Zxa/VvO7dvocY6u0qr7qaee4sCBA3zyyScBn1vEbwVtxWQykZuby8iRI4N2jZAWXV8tsR0N9VR8sQKA2HGz0HsQ3WC0xPZkl72usT27ZLNgqyohcviV2GsqqNy8mrqc3bLYpUYiIiJ4/fXX+f3vf09VVVXA5nXWv/31r3/NP//5z1YL1ggETr7//nsuu+yyoLbbCmnRba0ltr2umpL1j2M5lU10+jTiMry/LgS6JbYnu3SRsU0/95jxID1+dj9RadcBUHdsjyx2qZWrrrqKGTNm8PDDD3d4LhG/FXSEYMdzIcRF11tLbFt1KcXrHqHhzDFix88m4fp7Wn3wAt0S25Nd+m490RhabCk8H/TVhnv2wrpSq+7nn3+eTZs2sXXr1nbP4ax/++6775KZmSk2PAjaTDDa87QkpBfSvLXELn57EfaaSnSxiUi2Biq3vAZAVMpkDL2HuYwNRktsT3ZpdGHEjplJ9c71lG98CUPv4dQd+QY0WqJSM9zm6GqtumNjY1m5ciXz58/n0KFDREZGtrqdu+UCY15eHjfddBMjRozgu+++E+EEQZtxOBxkZmbyj3/8I6jXCek8XW8tsfOX3eBxfML0+4lOu9blWDBaYnuzS3LYqfrmbWp//BpHQx1hCf2Im/QLIgaNdZujq7bq/sUvfkHERcPRpU33up275bbpr7/+mjlz5rB48WIRThC0m8OHDzNz5kxyc4ObrhnSnm6PaAOThyay+UiJS3pW/8WeMwJaEqyW2N7s0mh1xGfcSXzGnYrYFQpMuutxlm3KQZtVgidvwHxegL/KKmFHThnjDaf5zytLWL9+vQgnCDqEHPFcCPGYLsDdGYMx6ttXrSqYLbHVapeaWZeZx8vfFKLRGzwKbnMkCcxWB9uru/PY2i+F4Ao6jBzxXOgEopveN44l04erriW2Wu1SKwcLq1j6ZTb11guhBNMPn3L6jd+T//yN5C+7gapv33E/URfO6sxSDhUFLt1M0DURnm4bmDt+AEumX0JEmA4k73m70PjqHhGmY8n0S4Jezau5Xb7CjHLapUY8bZtuKM5Fa4xGF9Oj1XO7wrZpQXApLy/nzJkzpKamBv1aIR3Tbc7c8QOIslRw7+oviBg0Fq3mQvwPQI8DuyQxLbU3CzMGy+ZJzh0/gLQ+cazcnsu2o2VocLXLuTA0ZViirHapCW/buXvMeAiA0n89Q72p1Ov5XWXbtCB4ZGZmMm7cOFkK63ca0QXY8NpL/H5kGvPuvtqtJXZyhJ0/L5zN3/KOodfL+7+d1ieO1XPHNLXq/nTHD5RX13HF2FGiVTfet3O3Bee26QVXDeq4QYIuh1zxXOhEopubm8tXX33FqlWriI02eHz4Pni6Ozt37mTy5MkKWAgJ5+2KyNvJli3bWXHrXYrYoTZ8bef2h66ybVoQHHbt2sXixYtluVaniOkCLFu2jLvvvpvY2FivY2bOnBmUwiptJSYmhnPnhEA4aW07d9vm6RrbpgWBxWq1snfvXi6//HJZrtcpRLegoICPP/7YZ8+tWbNm8emnn8reraAlQnRd8badu+3zdJ1t04LAcejQIfr3709cnDzrKZ0ivPDCCy8wb948und3ryLWnEsvvRRJkvjxxx9JS/NezzbYxMTEYDKZFLu+2vC2nfvcwU1YCrNoKDkOQN2xTGzVpUQOHU/k0AkuY7vatmlB4JAzngudwNMtLi7m3Xff5cEHH/Q5VqPRNHm7SiI8XVdmj+7j8bilMIvan77GbmrcDmwtPUntT1/TUHLCbawEzB7leR6BoDXkys91EtK1FwAefvhhLBYLL7/8sl/jt2/fzqJFi9i7d2+QLfNOYWEhEyZMoKio8xcp95f5b+912zbtLxoNTEtJYvXcMYE3TNDpGTBgAJs2bWLYsGG+BweAkPZ0KyoqWLt2bZvqsF555ZXk5eVRWFgYRMtaR3i67oht0wIlOH36NOfOnWPo0KGyXTOkRfevf/0rP//5z9vUKlmv1/Ozn/2Mzz77LIiWtU50dDQ1NTWKL+ipCbFtWqAEzniunJXpQlZ0q6urWblyJY8++mibz1U6dUyv12MwGKirq1PMBjUitk0L5EbueC6EsOiuXLmS66+/nkGD2r4DaerUqezZsyegPbnaiggxeGbu+AG8P38801KSMOi1SFaLy+dGvRaDXsu0lCTenz9eCK6gQ+zatYsJEyb4HhhAQnIhrba2loEDB7Jt2zZSUlLaNceMGTP4xS9+we233x5g6/xj8ODB/Pvf/2bIkCGKXD8UOH6qlAm338ecux853zkiTGybFgQMs9lMQkICpaWlREVFyXbdduXptqWNSjBYs2YNkyZNarfgwoUQg1KiKzxd39SUnyHp7E+suPUypU0RdEL279/PJZdcIqvgQhtF92BhFX/fnuuljUoxK7bkuLRRCQYWi4U///nPbNzoX3cIb8yYMYNFixZhsVgwGOT3moTo+iY/P5/+/fsrbYagk6JEPBfaENNdl5nHbWsy2XykBIvN4bZ7yHz+2FdZJdy2JpN1mXmBthWAt956i5EjR3LZZR3zfpKSkkhNTWXbtm0BsqxtCNH1TUFBAf369VPaDEEnRYl4Lvgpuusy81j65RHqrXafyeuSBPVWO0u/PBJw4bVarSxbtownnngiIPPNnDlTsd1pQnR9IzxdQbCQJEm9nq6nNir+UG91sPTL7IC2UVm/fj0XX3xxwH47zZo1i88++wyHo2NlBduDEF3fCE9XECzy8vLQ6XSKfL98xnQ9tVEp3/gS5rwD2OtNaMMjCU8eTPzkXxGe7Jq+5WyjEojtmXa7nWeffZaVK1d2eC4nQ4cOJTY2lr179zJu3LiAzesPQnR9IzxdQbBwerlybopw0qqn662Niq26FEO/S4lOuw5tRAzmk/sp/egZt/Obt1HpKP/617+Ij48PeNdXpUIMQnR9IzxdQbBQKp4LPkTXWxuV5DnLSLzxYRKm3U2PGxvrHtjPVSDZ3YtRO9uodARJkli6dClPPPFEwH8zzZo1S5HdaUJ0W8disVBRUUGvXr2UNkXQCZG7nGNzWg0vtNZGxbTvc6zlhZjzDwIQO24WGp37dIFoo7Jx40a0Wi3Tp0/v0DyeGDduHJWVleTm5jJ4sHxFU2JiYsjJyZHteqFGUVERvXv3lqVRYGdH6bx6tVFTU0NOTk6HM6DaS6ui21oblbrsnVgKfwJAF9MDw0XeNyp0pI2K08tdsmRJUOIvWq2WGTNm8Omnn/LQQw8FfH5vCE+3dUQ8t+OoIa9ejXz//feMHDlSkfx88BFeaK2NSvKcZfRb9BGJNz+BvaaSsk+ew1ZV4mWe9rdR+frrrzGZTNx8883tnsMXSoQYhOi2Tn5+vojndgC15NWrESXjueBDdBvbqLgOcVgtSI7GbAaNPpyIgaPRhBvBYcdW7S66HW2jsnTpUh577DG02uDV5rn66qs5dOgQpaWlQbtGS4Totk5BQYHwdNuJWvLq1YqS8VzwEV6YPboPK7a4xh0bTh+l/PMXMfRNRWuMxlJ4GMlShzayG+FJ7hW/OtJGZefOneTn5we9PoLRaGTq1Kls3LiRu+6Spy26EN3Wyc/PV9QbCVVay6uvO7qL6t0fYi3PB52e8MQBJM5+Cp0xuimvPq1PXKeuTexwONi9ezdvvPGGYja06j72iDYweWiiS21TXUwC+vjemE8eoObgZhzmGiKHX0nS7UvRGl0LR2iAKcMS2x2sX7p0KYsXL0avD37/TLlTx4Toto7wdNuHp7x6gNqsHZR9/CwNZXlEDLmcqGFX4rDUIVnNTWOcefWdmaNHjxIfH09ycrJiNvhUs7szBvPtsXLqrY3/kGHdLyJ5zjK/JndYLQxuOIEkjfa6COZtZXVoWCU//vgjH3/8cRv+d9rP9OnTufuhxbyy5QjHK8xBX+UVHYFbRyyktQ9PefWSJHF2+1sAJP3v0xj7e+6E3TyvviPfdzVnSygdzwU/6+leiBH5v102IkzL3NQo3nn6/xgxYgQrV66kR48eTZ+3vrKqxdLQwKAIM8t/My3oK6tOWzb/dAq9TodVuvALwqjXIkHAV3lramro2bOn6B7hAYfDQWRkJJWVlURGRiptTkgx7Ml/uy2aWStPcfq1BWj0Bgz9RmApPIwuKp7YsTOJGX2Dy1ijXssD1w1lwVVtbw7g65kOxnPUVubNm8eoUaNYuHChItcHPwvetLeNypJbr2Lfvn3069ePtLQ0Pv/8c8C/lVVJq+e4JTroK6vNbZG0ehfBddoSjFXeqKgoLBYLNpv3tLyuSmlpKbGxsUJw24GnvHp7XeMblWSzYKsqIXL4ldhrKqjcvJq6nN0uY9ubVx8q2RJKFblpjt/B0rnjB5DWJ46V23PZdrQMDY030onzN9mUYYkszBjcFIyPiIjgxRdf5MYbb+TOO+/k5X8foDBhjMu53pC4sLLqtCGQtMWDb77KGwhbNBoNUVFR1NTUEBfXeRcu2oPY/htYdJGxTT/3mPEghl5DqQgzULP/C+qO7SFyqOvrdlvz6pV8jtpCZWUlRUVFjBgxQrZreqJNK1RpfeJYPXcMFTUWNuwvIvvMOUxmq19tVK666ire+c93zFn7A44Wgmv64VNqDm3GWl4AkoNuV9xO3KQ5TZ8HY2XV2ypv8TuLmzZ9OAnr0Y/e81YG3BbnYpoQXVdEPDew6Lv1RGOIRLI0C2WdjypqwyPcxh/P/olPPz3N5Zdf7nPBydNzZM4/RMn6xz2OT5h+P9Fp1yqSLZGZmcnYsWNlWZhvjXZdPSHa0K6Yz5t7TiNp9Y0ubDMainPRGqPRxfTAbvKcKxvIimXgfZXXScyYG5t+1kV3D4otsbGxIoPBA8LTbT8Gvdbt1V6jCyN2zEyqd66nfONLGHoPp+7IN6DREpWa4TI2TAMJGjOrV6/mrrvuIioqissvv5zLL7+ccePGMXr0aJf2Np6eI11sD5fnR2owU3PoKwD08RdqaQT6mfaF0vm5TmSTfG8VywB6zGjcflv6r2eo9yK6gVpZ9WWLk+7Xzvf6WaBsEWljnsnPz2fgwIFKm9Gp6HbFbUh2K7U/fk1d9reE9ehP3KRfYOg9zGWcVqfltUfvIiH6d0iSRG5uLnv27OH777/nww8/5KeffmLIkCGMGzeOEaMnsK2gp9tzFBbf2+X5Me1tXMsJTxqEsW9q0/FAPtP+sGvXLhYtWhT06/hCNtH1VrGsLTgrlrXHy26rLYUrbgUgPHkQcRl3Yug1NOC2CNH1TEFBARkZGUqbEZJMHprYuCjcQgg1Wh3xGXcSn3Gn13M1Gte8eo1Gw5AhQxgyZAhz584FGqu/HTx4kD179vCvA6ewRseBPtzrnJIkcW5fo+jGjJ3pfk0C80x7onnqWnW9laxuY8nW9GWcTCLvDdlEt7WKZf4SiIplvmzRhkcQMWgsupgELKeyMecfovT9p+g9bxW66PiA2iJE1zMiptt+WubVtx/Zm2UAABzdSURBVAWjXsfCjNYr7RkMBsaNG8e4ceM4/v5/yTtwutXx9bnfYzt7Gl1UPFGXTHL7PFDPdHO8pa4Zhk3i1Z2FrN5ZqGjqmmyi21rFsrbN0/6KZRfm8G5L4uynmjZySHYrp15dgN1UirngEFEpkwNqixBdz4hiN+0nvW8cS6YPb1de/ZLpw9u0qOXPM31ub+Muz+hR09HoPBe+CsQz7aQxkyIbs81z3Qln1tRXWSV8k1POkunDZc2ggDZ0A+4orVUsa9s87a9YdmEOz7Y4rGbsNZWeT9K436qO2iJE151z585hsVhcNtII2kZ78+rbKj6+numG0jzM+YfQ6MOJucx7Leyik8fYtWsXZrPZ6xh/CJVCP7J5uo0Vy4o9vtafO7gJS2EWDSXHAag7lomtupTIoeNdcgg7WrHMly2O2mpOrVmAsX86+thELKeysZtK0UbFuW2dDIQtQnTdcWYuKNG7qjPR3rz6ttDaMw1gOu/lRqVkoIvs5nGMXiOhrT7NPfcsJzs7m7S0NCZMmND0p08f/4pldbSBrpypa7KJrqeKZU4shVnU/vR109+tpSexlp5E362ni+h2pGKZP7ZoI2KIHnE15vxDWAp+RGOIJGLIeOKu+qXblyYQtgjRdUekiwWOjuTV+0Nrz7S9rpq6rB0AxIy90eMYAJ1Ox7r/dw8J0Yuora3lhx9+YPfu3bz99tssXLiQiIiIJgGeOHEiI0eOJDzcfeHOU+paQ3kBVdvexHL6KJLdirF/Ot2vnY++W0+XcXKnrskmus6KZZ5WVnvc8AA9bnig1fNbrqwGwxatIZKE6+/1eX6gbImJiZG1hm8oIBbRAk978+p90dozrYvsRr9FH7V6fsvnKCoqioyMjKbMFWfK2u7du9m9ezdvvfUWubm5jBw5skmEJ0yYgD463i0F1GGuofS9xgYLEYPGotGFUZezi9Kzp+n1m7+haRYulDt1TbaYLjSurBr17et55c/KaqjZIjxdd4SnG1oE8zlypqzdcccdrFq1igMHDnDmzBmefvppunXrxuuvv05qaipjbrmbhoYGl3PNRUew11Si65ZEz1v+QOLNjxPW82Ks5QXUHd3tfi063kDXX2QVXefKakRY2y7bnpXVULBFiK47wtMNLeR+jmJiYrjmmmt44okn+OKLLygvL+fqm3/ZuNO1GRp94yK3o96EtaoYm6m8aZHcWnrSbd5gpK55Q/ZNyM4V0tbSOpxoNI2/DYOV1qG0LUJ03RGebuih5HOk0WggPBKocTlu7Hcphj4pWIqyOL16nstn9tqzHucKZOpaayhS+UGOldVQsEWIrjvC0w1NlHyOPKWuabQ6km5/ltrsb7GWF6KPTcRc+BN1WTvQesmkCEQ6qj8oVm7H08pqUWkF//1+Fw/89hcdXlntqC3V9Q188cmHPHj3XcyZMDAotgjRdcVms1FcXMxFF12ktCmCdhDsbAlveE9dk4hOnQI0ZlNUffM2ABEDRrrNEah0VH/wq3OEXJSWljJixAjVrOhfeumlvP3224wc6f6PFAhOnjzJlClTyMvLC8r8oUZ+fj5XXnklhYWFSpsiCCHKayxc8fxWN9EtfmcxushYNIYozCf2NWUy9LzlD25zGPRadj16defLXvBFQkICVVVVWK3yxFZ8MWzYMI4ePRq0+YWn64rY/itoD54a6AKE97wYc2EWtT9tBa2O2PGzSbzpMbfzA5mO6g/KVvNtgU6no0ePHpSVldG7d2+lzWHo0KHk5HhO/g4ETtGVJEnswEJ0ABa0H0+Ffrpft4Du1y3weW6g01F9oSpPFyA5OZni4mKlzQCCL7oGQ+NvVovFErRrhBJiEU3QXtSQAuovQnRbIdjhBRAhhuaIdDFBR5Cr0E9HUVV4AdQluk5PNxiv/84CyzHX/Z57NmSR3D2W4cmx3DJavqwNtZGfn8/Mme6FrgUCf1FTOqo3hOi2QkJCAjqdjrKyMnr27On7BD9oWWCZi8eRWVADBTUY9cWs2JKjaIFlJRGeriAQeEpdO5ZfRMHxo9w9Z5as6aieUJ3oJiUlcfz4caXNaMIZYgiE6IZCgWWlkCRJZC8IAkrzQj8FBd25/PLfsuDVhxS2SsR0fRKoxbRQKbCsFJWVlYSHhxMbG6u0KYJOSN++fbFYLJSUlChtivo83c4oup4KLJvzD1Gy/nGP4xOm30902rWKFFhWCpG5IAgmGo2G9PR0Dh48yNSpUxW1RXi6PghEBoOnAsu62B7EjLmx6U902oUvgj6+V9PPzgLLnR0RzxUEm5EjR3Lw4EGlzRCeri866umW11jcCiwDhMX3pvu185v+btrb2KY6PGkQxr6pTcflLrCsFMLTFQSb9PR0tmzZorQZ6vN0Y2NjsVqt1NbWKm0KAIMHD+bkyZPY7W1vaQ2wYZ/vwsiSJHFuX6Poxox1T5mSs8CyUohFNEGwSU9P58CBA0qboT7R1Wg0JCcnqyLgDRAREUFSUlK7i9JkF5u8Nu5zUp/7Pbazp9FFxRN1ySS3z+UssKwUYguwINikpKRw4sSJDncd7iiqE13oXCEGk9nmc8y5811To0dNR6PzXNNTrgLLSiE8XUGwMRgMDB48mKysLEXtUK3oqsXThY6JrqcCy81pKM3DnH8IjT6cmMumtzKPPAWWlUJ4ugI5UEOIQbWiqyZPtyMZDI0Flr3fZtN5LzcqJcOtzbsTOQssK0F9fT3V1dUkJSUpbYqgk6OGDAYhun7QEU939ug+Xj+z11VTl7UDgJixN3odJwGzR3mfJ9QpLCykT58+aLWq/DoKOhFq8HRVlzIGjaK7f/9+pc1ooiOi6yywvPlIiVvamC6yG/0WfdTq+XIXWFYCkS4mkIv09HQOHTqkaA1rVboWavN0+/XrR1lZWbvT2O7OGIxRr2vXuXIXWFYCsTFCIBeJiYlERkZSUFCgmA1CdP1Ap9MxaNAgcnPbtzMslAosK4HwdAVyonSIQZWim5SUpCrRhY7vTHMWWDaGaZEcreftKllgWQmEpyuQE6UX01QtuipqVByQGgxzxw/gth5n6HYuD4Nei7FFVoNRr8Wg1zItJYn354/vEoILwtMVyIvSnq4qF9IiIiKIiIigqqqK+Ph4pc0BGj3dbdu2dWgOu93OO688x5tvvsklI8c2FVg2ma3EGsMY3itG8QLLcuHsnJFdbOJkv//h3RNhHNMf79KdMwTykJ6ezuOPe67wJweqFF24ENdVk+i++uqrHZrjo48+IjExkSuuuAKNRtNUYLkr0bJzhsXmgN4j+PrEOXYW5HTpzhkCeRgyZAglJSWYTCZF6jerMrwA6ltMc4YX2hvykCSJ559/nkcffbTLtltfl5nHbWsy2XykBIvN4VaTwnz+2FdZJdy2JrPLFHAXyItOpyM1NZVDhw4pcn0hun6SkJCARqOhvLy8Xedv3bqVuro6ZsyYEWDLQgPROUOgJpwFzZVA9eEFtaDRaJoyGBITE9t8/gsvvMDDDz/cJXddteycUfHvl7EUHcFmKkOjCyO891Dip9xFeKLrYlpX6pwhkJeRI0cqtpimWgVQm+hC+zMY/vvf/3L48GHmzJkTBKvUT8vOGTUHv0JjiCQq5So0hkjMJ/ZR+sFTSLYGt3O7SucMgbwomcGgak/3yJEjSpvhQntzdV944QXuv/9+wsPDg2CVuvHUOSNp7p8x9rkEAFtVCadW/wb7uQoaygswJLvuvusqnTME8pKWlsbhw4ex2Wzo9fLKoPB020B7RPfEiRNs3ryZ+fPn+x7cCfHUOcMpuACS43y9YY0WXXR3j3N0hc4ZAnmJiYmhV69eHDt2TPZrC9FtA+0JLyxfvpz58+d32dbirXXOcDTUU/HFCgBix81C70V0u0LnDIH8KLWYpmrRVVMhc2jsl3bixAm/+6WVlZWxfv167r333iBbpl68dc6w11VTsv5xLKeyiU6fRlzGr33M07k7ZwjkR6ntwKoV3cTERCorK9vdEDIYREZGkpiY6HeFoldeeYVbbrmF5OTkIFumXjx1zrBVl1K87hEazhwjdvxsEq6/x2fucmfvnCGQH6UW01S7kKbT6ejevTtlZWWqEi1niOHiiy9udVxNTQ2rVq1i165dMlmmTho7ZxS7hBiK316EvaYSXWwikq2Byi2vARCVMhlD72Fuc3T2zhkCZRDhBQ+EcrWx119/nYyMDIYMGSKDVerFU+cMe01l439NZZzb+1nTH2t5occ5OnvnDIEy9OvXj/r6ekpLS2W9rmo9XVDnYpo/omu1WnnppZf46KPWu0J0BTx1zui/eKPf53eFzhkCZdBoNE3e7nXXXSfbdVXt6apRdP3JYHjvvfcYMmQIY8aMkckqdSM6ZwjUihKLaUJ024gvT1eSJF544QUeeeQRGa1SN6JzhkCtKLGYJkS3jfTv35+SkhLq6+s9fv7ll1+i1+uZOnWqzJapG2fnjIgwHb6KrHW1zhkC5VBiMU2IbhvR6XQMHDjQ606W559/nkceeaTLlm9sjbnjB/D+/PFMS0nCoNdCi1oLXbVzhkA5UlJSOH78OGazWbZrioW0djBs2DBycnJIS0tzOb57926Kioq45ZZbFLJM/aT1iWP13DGUnatn2LRfMfeeR6ltcHS5zhkCdWA0Ghk0aBBZWVmMGjVKlmsK0W0H3uK6L7zwAg899JDsBTRCEVtNFeEnvuHl2z9Q2hRBF8cZYhCiizpFt7zGQnniSLYVVpL7jx+INeoZnhzLyG5mdu3axTvvvKO0iSFBQUEBffv2VdoMgUD22rqqFt24uDjq6+upr68nIiJCUVua9/ZyOGKxRsayNbsxqdqoL6bBamX4vOUcq2ggPTJSUVtDAdF2XaAW0tPT2bjR/9zxjqLqhTSNRqOKwjcte3tZWxTNMtscODQ6ChzxoreXnwjRFagFZ3ihvf0P24qqRReUDzG0qbcXoreXvxQWFgrRFaiCnj17EhER4Xchq46i6vACKCu6LXt7OWkoL6Bq25tYTh9Fslsx9k+n+7Xz0XfrCYjeXv5QUFDApEmTlDZDIAAueLv9+/f3PbiDqN7TVbLoTcveXgAOcw2l7z1B/fEfMPQeRsSAy6g/lknph39Eki6Is+jt1TpiIU2gJuTcDqx60VXK0/XU2wvAXHSksSxhtyR63vIHEm9+nLCeF2MtL6Du6O6mcc17ewncETFdgZqQcztwSIiuEgtpnnp7AWj0jcW0HfUmrFXF2EzlTaUKraUnXccient5or6+HpPJRM+ePZU2RSAA5N0OHBIx3c2bN8t+XW+9vYz9LsXQJwVLURanV89z+cxee9bl76K3l2eKioro06cPWq3qf+cLughDhw7lzJkzmEymoPczDAnRVSK84K23l0arI+n2Z6nN/hZreSH62ETMhT9Rl7UDbWQ3D/OI3l4tEfFcgdrQ6XSkpqby448/csUVVwT1Wqp3NZQSXU+9vS4gEZ06hfjJdxA5bCLmk/8FIGLASA/ziN5eLRHxXIEakWsxTfWerjN7QZIkWSt3eert5aTkvSfRRcaiMURhPrEPR72JiEFjMfZ3LYAjent5RoiuQI3ItZimek83KiqKsLAwTCaTrNf11NvLSXjPizEXZlH701bQ6ogdP5vEmx5zGyd6e3lGbIwQqBG5FtNU7emW11jYsK+IhBseYv66/fTqEcfw5FhuGR388n+eens56X7dArpft6DV80VvL+8UFBSI8pcC1ZGWlsbhw4ex2+3odO1rL+UPqhTd5sVlAKT+Y9hTVAdFdRj1xazYkkPGsEQWTh5Met/g7fi6O2Mw3x4rp95q9z24BaK3l3fEQppAjcTGxpKUlMSxY8cYPnx40K6juvBCy+IyLWOq5vPHvsoqCXpxGdHbK/BIkiREV6Ba5AgxqEp021RcRpKnuEzz3l6NUVrviN5evqmoqMBoNBITIxYYBepDjtq6qgkveCsuI9kaOLt1LbXZ3yI11BOeNIj4a+Zh6D0MkKe4zNzxA0hJjmbWklUYBoxCp9VibuaBG/VaJBpjuAszBgsPtxXEIppAzaSnp/Pqq68G9RqqEV1PxWUAKre8Rs2B/xCW2J+w/unUHfmWkvee4KL/ex3d+c0IzuIyq+eOCZp92bu+YtDprWx49RE27C8i+8w5TGar6O3VRkRoQaBm5MjVVYXoeisuY6+toubQFtBoSbptKbqoOMq1OmoPb+Pcvo3ETZoDuBaXCYbwSZLE8uXLefrpp0mINrDgqkEBv0ZXQeToCtRMv379qKuro6ysjMTExKBcQxUxXW/FZazlBeCwoYtNRBfV+MoentyYEdAgY3GZHTt2UFtby/Tp04Myf1dCiK5AzWg0GtLS0oLq7apCdL0Vl3EWkNGGG5uOac7/LGdxmeXLl/PAAw+IAi0BQMR0BWon2ItpqlARb8VldFHxADgazE3HpPM/Oz9znSfwxWWys7P5/vvvueOOOwI+d1dEeLoCtRPstDFViK634jJhPfqCVo/dVNbk2VrO5ACNW3Hd5wl8cZkVK1bwf//3f4p3I+4siIU0gdoJtuiqYiHNW3EZXVQ80ZdeQ83BTZSsX0JYYn/qjnyHJjyCmNE3uIwNRnGZsrIyPvjgA44ePRrQebsqVquV0tJSevfurbQpAoFXUlNTOXbsGBaLBYMh8AvzqvB0WysuE3/tfKJH/Qx7bRV1OZkYLhpG0q1/akoXcxKM4jKrVq1i9uzZosNBgDh16hTJycno9ar4XS8QeMRoNDJo0CCysrKCMr8qvv2tFZfRhhlImPo7Eqb+zuv5wSguYzabWblyJVu3bg3YnF0dsYgmCBWcIYbLLrss4HOrwtOFxuIyRn37KvsEo7jMunXrGDVqFCkpKQGdtysj4rmCUCGYGQyqEV01FZdxOBy89NJLPPTQQwGbUyAyFwShQzAX01QjuuBaXMZXkwgNgK2Bn/VuCHhxmU2bNhEeHs7VV18d0Hm7OkJ0BaGCs4uE5KvyVjtQlehCo/C+P38801KSMOi1GPWuJhr1Wgx6LdNSk/jT5Hje/dPvqKioCKgNy5cv56GHHpK1PVBXQMR0BaFCUlISRqORwsLCgM+tioW0lqT1iWP13DFU1Fh8Fpf57623ct9997Fu3bqAXPvAgQMcOXKEW2+9NSDzCS4gPF1BKOEMMQT6O6uRguE/y0hdXR3p6em8+OKLzJw5s8Pz3XHHHaSkpLB48eIAWCdoTlxcHCdOnKB79+5KmyIQ+GTx4sVERUXx5JNPBnRe1YUX2kpkZCRr165l4cKFVFZWdmiuU6dOsXHjRhYsaL3/maDtVFdXY7PZiI93374tEKiRYC2mhbzoAkyaNInZs2dz//33d2iev/3tb8ydO1cIQxBwxnNFnFwQKgjR9cGzzz7Lzp07+fzzz9t1fk1NDWvWrOmwcAs8IxbRBKHG0KFDOX36NOfOBbZ6YacR3aioKNauXcvvfvc7zp496/uEFrz55ptMnjyZgQMHBsE6gdgYIQg19Ho9KSkp/PjjjwGdt9OILsDkyZO56aabeOCBB9p0nt1u5y9/+YvYDBFEROaCIBQJxs60TiW6AM899xzffPMNX3zxhd/nfPLJJ/Ts2ZOJEycG0bKujRBdQSgSjLhupxPd6Oho1q5dy4IFC/wOMzg3QwiCh4jpCkKRYIiuKjdHdJSMjAxmzZrFgw8+yJtvvtnq2N27d1NcXMxNN90kk3VdE+HpCkKRiwYN53j4xdz33n7OWezEGvUMT47lltHt7/4d8psjvFFTU0NaWhp/+9vfmD59OuU1FjbsKyK72ITJbGu6ef9Z+QemTBzLfffdp7TJnRa73U5kZCQmkykoRaEFgkBzsLCKv2/PZUdOGRazGfThTZ8Z9VokIGNYIgsnDya9b9uKbXVKTxcawwyvv/46v3rwKa4tjmfXySoAl+4U4bozWPr9nITYXhwsrGrzzRP4R0lJCfHx8UJwBSHBusw8ln6Zjdlmb6zv3UxwobEJLsBXWSV8k1POkunD21R0S/fHP/7xj4EzV13sLNHwjW0QJyvqsUtgd7g69XYJNFodeZX1fHLgNHER+oCWiOzKlNdY+OfufNbtyWf9njxM0X0Ji+/NxT2iiAzvtL/rBSFOo+Aeod7q3p3cEzaHxO4TFcRFhPmtHZ02vNDWmwfO2ryXBLxUZFei+WsZuL5ZdPS1TCAIJgcLq7htTSb1VrvL8eJ3FmMp/MnlWFiPfvSet7Lp7xFhOt6fP94v4e2ULsfBwiqWfpntJrgNJSc4u/1NGs7kItka0HfrSczoG4gZ9TMA6q0Oln6ZTVqfOOHxtgO317IWdPS1TCAIJn/fnovZZvf6ecyYG5t+1kW7Fm0y2+ys3J7L6rljfF6nU4qut5tX+q9nsJtKCUscQFj33tQd3U3lV6sIS+iLsX8a0LabJ7hAW94sJAnqrXaWfnkEQAivQHHKayzsyCnz6Cw46X7tfK+fSRJsO1pGRY3FZ1ZDp8vT9XbzJLsN+7lyAHrcuIjEmx4nPHkQALbqkgvjmt08gX94e7PwhfPN4lBRVZAsEwj8Y8O+Ip9jClfcSuGKWylZ/ziWMzlun2uADft9z9PpRNfbzdPo9MSMmQFA+WcvUvbxszQUHyes58VEDp3gOhb/bp6gEV+vZbVZO8hfdgP5y26gcstrLp853ywEAiXJLja5rD80RxseQcSgsUReMgldbCLm/EOUvv8U9hrXzVdmm4PsM76L43S68EJrNy9yyATqcjKxluVhLcsDrZ7IIePRhEe4jPP35gl8v5bZTOVUbloJWh043IW5La9lAkGwMJltXj9LnP1UU0lSyW7l1KsLsJtKMRccIiplcot5rD6v1ek8XW83z15vovTDP2CvLiFpzvP0uf89wpMupnrnemoO/MfDPL5vnqD11zJJkqj44iV0MQlEDvNe10K8WQiUJtbo2f90WM3Ya7w0R9C4y2esMczntTqdp+vt5tmqSpCsFtDqMfQaikYfRlhCXxrOHMNa7t58zp+bJ2j9zeLcD59iLsqi1x0vYfrhU69ziDcLgdIMT47FoC92+y47aqs5tWYBxv7p6GMTsZzKxm4qRRsV17T47sSo1zK8V4zPa3U6T7fx5rn/b4Ul9EVrjAGHjZL3llC+8SVqs74BwNA3xWWsvzdP4P3NoqEsj7M7/kHcpLmEJ/muUSzeLARKMnt0H4/HtRExRI+4GlvlKWp/2oq9roqIIeNJum0pushuLmMlYPYoz/M0p9N5urNH92HFFveVRW24kZ7/+0eqvnmbhuLjjYto8b2IHvk/RF1ylctYf2+ewPubRd3RXWC3YS74EUvhYRpKTwJQf2wPZ/XhxGfc2WIe8WYhUI4e0QYmD01k85ESl/UJrSGShOvv9Xm+RgNThiX6tS7R6UTX280DMPQeRtJtz7R6fltunsD7a1njzZcwn9jncthWXYLlVLbLMfFmIVADd2cM5ttj5W470vzBqNexMGOwX2M7XXgBGm+eUa9r17ltuXkC769lcZPm0H/xxqY/USOuARp39STPWeYyVrxZCNRAet84lkwfTkRY22SxsXzAcL93sXZK0ZXr5gkuvFm0t8mveLMQqIm54wewZPolRITpfH6nNZrGmgttrdfSaQvegO9aAE40mkYPV9QCaB/eCoX4Q1sKhQgEcnGoqIqV23PZdrQMDRfqhsCFwk1ThiWyMGNwm7+7nVp0Ibg3T3ABUdVN0BmpqLGwYX8R2WfOYTJbiTWGMbxXDLNHic4RPgnGzRO4It4sBALfdBnRFciDeLMQCFpHiK4gKIg3C4HAM0J0BQKBQEY6ZcqYQCAQqBUhugKBQCAjQnQFAoFARoToCgQCgYwI0RUIBAIZEaIrEAgEMiJEVyAQCGREiK5AIBDIiBBdgUAgkBEhugKBQCAjQnQFAoFARv4/Y9d2htX6xgsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# draw the draph\n",
    "def custom_clustering(graph, partition_num):\n",
    "    clusters = [cluster for cluster in range(partition_num)]\n",
    "    node_count = len(graph.nodes())\n",
    "    cluster_membership = {node: 0 for node in range(node_count // partition_num)}\n",
    "    if partition_num > 1:\n",
    "        cluster_membership.update({node: 1 for node in range(node_count // partition_num, node_count)})\n",
    "    subgraphs = [graph.subgraph([node for node in sorted(graph.nodes()) if cluster_membership[node] == cluster]) for cluster in clusters]\n",
    "    return subgraphs\n",
    "\n",
    "# 1) the whole graph\n",
    "tmp = edge_index.t().numpy().tolist()\n",
    "whole_graph = nx.from_edgelist(tmp)\n",
    "# print(len(whole_graph.nodes()) )\n",
    "subgraphs = custom_clustering(whole_graph, 2)\n",
    "print(len(subgraphs))\n",
    "\n",
    "plt.subplot(131)\n",
    "nx.draw(whole_graph, with_labels=True, font_weight='bold')\n",
    "# 2) the two halves of the graph\n",
    "plt.subplot(132)\n",
    "nx.draw(subgraphs[0], with_labels=True, font_weight='bold')\n",
    "plt.subplot(133)\n",
    "nx.draw(subgraphs[1], with_labels=True, font_weight='bold')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " metis graph clustering started.\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# first use two batches\n",
    "clustering_machine = ClusteringMachine(edge_index, features, label, partition_num = 2)\n",
    "clustering_machine.decompose(0.8)\n",
    "whole_graph = clustering_machine.graph\n",
    "subgraphs = [clustering_machine.graph.subgraph([node for node in sorted(clustering_machine.graph.nodes()) if clustering_machine.cluster_membership[node] == cluster]) for cluster in clustering_machine.clusters]\n",
    "plt.subplot(131)\n",
    "nx.draw(whole_graph, with_labels=True, font_weight='bold')\n",
    "# 2) the two halves of the graph\n",
    "plt.subplot(132)\n",
    "nx.draw(subgraphs[0], with_labels=True, font_weight='bold')\n",
    "plt.subplot(133)\n",
    "nx.draw(subgraphs[1], with_labels=True, font_weight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total node count:  10\n",
      "cluster membership in a dict:  {0: 1, 1: 1, 2: 0, 3: 1, 4: 1, 5: 0, 6: 0, 7: 0, 8: 0, 9: 1}\n",
      "\n",
      "sub_isolated_graph_nodes:  {0: tensor([2, 5, 6, 7, 8]), 1: tensor([0, 1, 3, 4, 9])}\n",
      "sub_isolated_graph_edges:  {0: tensor([[0, 2, 1, 3],\n",
      "        [1, 3, 0, 2]]), 1: tensor([[0, 1, 1, 2],\n",
      "        [1, 2, 0, 1]])}\n",
      "Intersecting cluster combinations:  [(0, 1)]\n",
      "total inter clustering edges: {(1, 2), (4, 6), (8, 9), (9, 5), (0, 8), (2, 4), (7, 9)}\n",
      "total nodes participating the inter-cluster:  defaultdict(<class 'set'>, {(0, 1): tensor([0, 1, 2, 4, 5, 6, 7, 8, 9])})\n",
      "total edges cross intersecting clusters:  defaultdict(<class 'list'>, {(0, 1): tensor([[1, 3, 7, 8, 0, 2, 6, 2, 5, 8, 4, 7, 3, 8],\n",
      "        [2, 5, 8, 4, 7, 3, 8, 1, 3, 7, 8, 0, 2, 6]])})\n",
      "\n",
      "total graph edges(remove duplicates for undirect):  [(0, 1), (0, 8), (1, 3), (1, 2), (8, 9), (2, 4), (2, 5), (4, 6), (6, 7), (7, 9), (9, 5)]\n",
      "=============== Cluster Infor above =====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39ce36037e6345789ef82fb2ffdde5fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Train Loss', max=20, style=ProgressStyle(description_width='i"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " during the training epoch: #  0\n",
      "\n",
      "start training the isolated cluster:\n",
      "Train sum loss of isolated clusters: 1.4336\n",
      "Train ave loss of isolated clusters over all nodes : 0.7168\n",
      "\n",
      "start training the inter-cluster:\n",
      "Train sum loss of all clusters including inter linking edges: 2.1621\n",
      "Train ave loss of all clusters including inter linking edges over all nodes : 1.0811\n",
      "\n",
      " during the training epoch: #  1\n",
      "\n",
      "start training the isolated cluster:\n",
      "Train sum loss of isolated clusters: 1.3574\n",
      "Train ave loss of isolated clusters over all nodes : 0.6787\n",
      "\n",
      "start training the inter-cluster:\n",
      "Train sum loss of all clusters including inter linking edges: 2.0191\n",
      "Train ave loss of all clusters including inter linking edges over all nodes : 1.0095\n",
      "\n",
      " during the training epoch: #  2\n",
      "\n",
      "start training the isolated cluster:\n",
      "Train sum loss of isolated clusters: 1.3746\n",
      "Train ave loss of isolated clusters over all nodes : 0.6873\n",
      "\n",
      "start training the inter-cluster:\n",
      "Train sum loss of all clusters including inter linking edges: 1.9335\n",
      "Train ave loss of all clusters including inter linking edges over all nodes : 0.9668\n",
      "\n",
      " during the training epoch: #  3\n",
      "\n",
      "start training the isolated cluster:\n",
      "Train sum loss of isolated clusters: 1.3629\n",
      "Train ave loss of isolated clusters over all nodes : 0.6815\n",
      "\n",
      "start training the inter-cluster:\n",
      "Train sum loss of all clusters including inter linking edges: 1.8354\n",
      "Train ave loss of all clusters including inter linking edges over all nodes : 0.9177\n",
      "\n",
      " during the training epoch: #  4\n",
      "\n",
      "start training the isolated cluster:\n",
      "Train sum loss of isolated clusters: 1.3153\n",
      "Train ave loss of isolated clusters over all nodes : 0.6577\n",
      "\n",
      "start training the inter-cluster:\n",
      "Train sum loss of all clusters including inter linking edges: 1.73\n",
      "Train ave loss of all clusters including inter linking edges over all nodes : 0.865\n",
      "\n",
      " during the training epoch: #  5\n",
      "\n",
      "start training the isolated cluster:\n",
      "Train sum loss of isolated clusters: 1.3571\n",
      "Train ave loss of isolated clusters over all nodes : 0.6785\n",
      "\n",
      "start training the inter-cluster:\n",
      "Train sum loss of all clusters including inter linking edges: 1.705\n",
      "Train ave loss of all clusters including inter linking edges over all nodes : 0.8525\n",
      "\n",
      " during the training epoch: #  6\n",
      "\n",
      "start training the isolated cluster:\n",
      "Train sum loss of isolated clusters: 1.3654\n",
      "Train ave loss of isolated clusters over all nodes : 0.6827\n",
      "\n",
      "start training the inter-cluster:\n",
      "Train sum loss of all clusters including inter linking edges: 1.6607\n",
      "Train ave loss of all clusters including inter linking edges over all nodes : 0.8303\n",
      "\n",
      " during the training epoch: #  7\n",
      "\n",
      "start training the isolated cluster:\n",
      "Train sum loss of isolated clusters: 1.3468\n",
      "Train ave loss of isolated clusters over all nodes : 0.6734\n",
      "\n",
      "start training the inter-cluster:\n",
      "Train sum loss of all clusters including inter linking edges: 1.6136\n",
      "Train ave loss of all clusters including inter linking edges over all nodes : 0.8068\n",
      "\n",
      " during the training epoch: #  8\n",
      "\n",
      "start training the isolated cluster:\n",
      "Train sum loss of isolated clusters: 1.3769\n",
      "Train ave loss of isolated clusters over all nodes : 0.6885\n",
      "\n",
      "start training the inter-cluster:\n",
      "Train sum loss of all clusters including inter linking edges: 1.6099\n",
      "Train ave loss of all clusters including inter linking edges over all nodes : 0.8049\n",
      "\n",
      " during the training epoch: #  9\n",
      "\n",
      "start training the isolated cluster:\n",
      "Train sum loss of isolated clusters: 1.365\n",
      "Train ave loss of isolated clusters over all nodes : 0.6825\n",
      "\n",
      "start training the inter-cluster:\n",
      "Train sum loss of all clusters including inter linking edges: 1.584\n",
      "Train ave loss of all clusters including inter linking edges over all nodes : 0.792\n",
      "\n",
      " during the training epoch: #  10\n",
      "\n",
      "start training the isolated cluster:\n",
      "Train sum loss of isolated clusters: 1.3582\n",
      "Train ave loss of isolated clusters over all nodes : 0.6791\n",
      "\n",
      "start training the inter-cluster:\n",
      "Train sum loss of all clusters including inter linking edges: 1.5663\n",
      "Train ave loss of all clusters including inter linking edges over all nodes : 0.7832\n",
      "\n",
      " during the training epoch: #  11\n",
      "\n",
      "start training the isolated cluster:\n",
      "Train sum loss of isolated clusters: 1.356\n",
      "Train ave loss of isolated clusters over all nodes : 0.678\n",
      "\n",
      "start training the inter-cluster:\n",
      "Train sum loss of all clusters including inter linking edges: 1.5463\n",
      "Train ave loss of all clusters including inter linking edges over all nodes : 0.7732\n",
      "\n",
      " during the training epoch: #  12\n",
      "\n",
      "start training the isolated cluster:\n",
      "Train sum loss of isolated clusters: 1.3433\n",
      "Train ave loss of isolated clusters over all nodes : 0.6717\n",
      "\n",
      "start training the inter-cluster:\n",
      "Train sum loss of all clusters including inter linking edges: 1.5297\n",
      "Train ave loss of all clusters including inter linking edges over all nodes : 0.7649\n",
      "\n",
      " during the training epoch: #  13\n",
      "\n",
      "start training the isolated cluster:\n",
      "Train sum loss of isolated clusters: 1.3199\n",
      "Train ave loss of isolated clusters over all nodes : 0.66\n",
      "\n",
      "start training the inter-cluster:\n",
      "Train sum loss of all clusters including inter linking edges: 1.4939\n",
      "Train ave loss of all clusters including inter linking edges over all nodes : 0.747\n",
      "\n",
      " during the training epoch: #  14\n",
      "\n",
      "start training the isolated cluster:\n",
      "Train sum loss of isolated clusters: 1.3036\n",
      "Train ave loss of isolated clusters over all nodes : 0.6518\n",
      "\n",
      "start training the inter-cluster:\n",
      "Train sum loss of all clusters including inter linking edges: 1.468\n",
      "Train ave loss of all clusters including inter linking edges over all nodes : 0.734\n",
      "\n",
      " during the training epoch: #  15\n",
      "\n",
      "start training the isolated cluster:\n",
      "Train sum loss of isolated clusters: 1.2803\n",
      "Train ave loss of isolated clusters over all nodes : 0.6401\n",
      "\n",
      "start training the inter-cluster:\n",
      "Train sum loss of all clusters including inter linking edges: 1.4375\n",
      "Train ave loss of all clusters including inter linking edges over all nodes : 0.7187\n",
      "\n",
      " during the training epoch: #  16\n",
      "\n",
      "start training the isolated cluster:\n",
      "Train sum loss of isolated clusters: 1.2528\n",
      "Train ave loss of isolated clusters over all nodes : 0.6264\n",
      "\n",
      "start training the inter-cluster:\n",
      "Train sum loss of all clusters including inter linking edges: 1.4045\n",
      "Train ave loss of all clusters including inter linking edges over all nodes : 0.7023\n",
      "\n",
      " during the training epoch: #  17\n",
      "\n",
      "start training the isolated cluster:\n",
      "Train sum loss of isolated clusters: 1.2227\n",
      "Train ave loss of isolated clusters over all nodes : 0.6114\n",
      "\n",
      "start training the inter-cluster:\n",
      "Train sum loss of all clusters including inter linking edges: 1.3689\n",
      "Train ave loss of all clusters including inter linking edges over all nodes : 0.6845\n",
      "\n",
      " during the training epoch: #  18\n",
      "\n",
      "start training the isolated cluster:\n",
      "Train sum loss of isolated clusters: 1.2043\n",
      "Train ave loss of isolated clusters over all nodes : 0.6021\n",
      "\n",
      "start training the inter-cluster:\n",
      "Train sum loss of all clusters including inter linking edges: 1.3502\n",
      "Train ave loss of all clusters including inter linking edges over all nodes : 0.6751\n",
      "\n",
      " during the training epoch: #  19\n",
      "\n",
      "start training the isolated cluster:\n",
      "Train sum loss of isolated clusters: 1.1598\n",
      "Train ave loss of isolated clusters over all nodes : 0.5799\n",
      "\n",
      "start training the inter-cluster:\n",
      "Train sum loss of all clusters including inter linking edges: 1.2932\n",
      "Train ave loss of all clusters including inter linking edges over all nodes : 0.6466\n",
      "Sum of total training loss of two batches by nll_loss function:  1.293150544166565\n"
     ]
    }
   ],
   "source": [
    "print('total node count: ', clustering_machine.node_count)\n",
    "print('cluster membership in a dict: ', clustering_machine.cluster_membership)\n",
    "print()\n",
    "print('sub_isolated_graph_nodes: ', clustering_machine.sg_nodes)\n",
    "print('sub_isolated_graph_edges: ', clustering_machine.sg_edges)\n",
    "\n",
    "print('Intersecting cluster combinations: ', clustering_machine.intersect_cluster)\n",
    "print('total inter clustering edges:', clustering_machine.macro_inter_edges)\n",
    "\n",
    "print('total nodes participating the inter-cluster: ', clustering_machine.inter_nodes)\n",
    "print('total edges cross intersecting clusters: ', clustering_machine.inter_edges)\n",
    "\n",
    "print()\n",
    "print('total graph edges(remove duplicates for undirect): ', clustering_machine.graph.edges())\n",
    "print('=============== Cluster Infor above =====================')\n",
    "\n",
    "gcn_trainer = ClusterGCNTrainer(clustering_machine, 2, 2)\n",
    "gcn_trainer.train(20)\n",
    "print('Sum of total training loss of two batches by nll_loss function: ', gcn_trainer.accumulated_training_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F-1 score: 0.6250\n"
     ]
    }
   ],
   "source": [
    "gcn_trainer.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use data from pytorch geometric datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3 500\n",
      "Info (attributes) of a single data instance\n",
      "Data(edge_index=[2, 88648], test_mask=[19717], train_mask=[19717], val_mask=[19717], x=[19717, 500], y=[19717]) \n",
      " number of nodes:  19717 \n",
      " number of edges:  88648 \n",
      " number of features per ndoe:  500 \n",
      " number of edge features:  0 \n",
      " all the attributes of data:  ['x', 'edge_index', 'y', 'train_mask', 'val_mask', 'test_mask']\n"
     ]
    }
   ],
   "source": [
    "# this data is also used the in the trivial example of the cluster-GCN paper\n",
    "from torch_geometric.datasets import Planetoid\n",
    "dataset = Planetoid(root='~/tmp/Planetoid/PubMed', name='PubMed')\n",
    "print(len(dataset), dataset.num_classes, dataset.num_node_features)\n",
    "data = dataset[0]\n",
    "print('Info (attributes) of a single data instance')\n",
    "print(data, '\\n number of nodes: ', data.num_nodes, '\\n number of edges: ', data.num_edges, \\\n",
    "      '\\n number of features per ndoe: ', data.num_node_features, '\\n number of edge features: ', data.num_edge_features, \\\n",
    "      '\\n all the attributes of data: ', data.keys)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# data = data.to(device)\n",
    "\n",
    "# x, edge_index, y = data.x.cuda(), data.edge_index.cuda(), data.y.cuda()\n",
    "# print(edge_index[:,0])\n",
    "# tmp = edge_index.t().cpu().numpy().tolist()\n",
    "# print(tmp[1])\n",
    "\n",
    "# conv1 = custom_GCNConv(dataset.num_node_features, 2).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute the GCN partitioning graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " metis graph clustering started.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clustering_machine = ClusteringMachine(data.edge_index, data.x, data.y, partition_num = 10)\n",
    "clustering_machine.decompose(0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07cdd774ca9849acb98630d44fa68654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Train Loss', max=20, style=ProgressStyle(description_width='i"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " during the training epoch: #  0\n",
      "\n",
      "start training the isolated cluster:\n",
      "Train sum loss of isolated clusters: 3881.33\n",
      "Train ave loss of isolated clusters over all nodes : 0.9851\n",
      "\n",
      "start training the inter-cluster:\n",
      "Train sum loss of all clusters including inter linking edges: 9054.82\n",
      "Train ave loss of all clusters including inter linking edges over all nodes : 2.2982\n",
      "\n",
      " during the training epoch: #  1\n",
      "\n",
      "start training the isolated cluster:\n",
      "Train sum loss of isolated clusters: 1592.77\n",
      "Train ave loss of isolated clusters over all nodes : 0.4043\n",
      "\n",
      "start training the inter-cluster:\n",
      "Train sum loss of all clusters including inter linking edges: 5193.3\n",
      "Train ave loss of all clusters including inter linking edges over all nodes : 1.3181\n",
      "\n",
      " during the training epoch: #  2\n",
      "\n",
      "start training the isolated cluster:\n",
      "Train sum loss of isolated clusters: 1341.48\n",
      "Train ave loss of isolated clusters over all nodes : 0.3405\n",
      "\n",
      "start training the inter-cluster:\n",
      "Train sum loss of all clusters including inter linking edges: 4734.05\n",
      "Train ave loss of all clusters including inter linking edges over all nodes : 1.2015\n",
      "\n",
      " during the training epoch: #  3\n",
      "\n",
      "start training the isolated cluster:\n",
      "Train sum loss of isolated clusters: 1250.09\n",
      "Train ave loss of isolated clusters over all nodes : 0.3173\n",
      "\n",
      "start training the inter-cluster:\n",
      "Train sum loss of all clusters including inter linking edges: 4471.49\n",
      "Train ave loss of all clusters including inter linking edges over all nodes : 1.1349\n",
      "\n",
      " during the training epoch: #  4\n",
      "\n",
      "start training the isolated cluster:\n",
      "Train sum loss of isolated clusters: 1174.3\n",
      "Train ave loss of isolated clusters over all nodes : 0.298\n",
      "\n",
      "start training the inter-cluster:\n",
      "Train sum loss of all clusters including inter linking edges: 4310.16\n",
      "Train ave loss of all clusters including inter linking edges over all nodes : 1.0939\n",
      "\n",
      " during the training epoch: #  5\n",
      "\n",
      "start training the isolated cluster:\n",
      "Train sum loss of isolated clusters: 1112.1\n",
      "Train ave loss of isolated clusters over all nodes : 0.2823\n",
      "\n",
      "start training the inter-cluster:\n",
      "Train sum loss of all clusters including inter linking edges: 4133.82\n",
      "Train ave loss of all clusters including inter linking edges over all nodes : 1.0492\n",
      "\n",
      " during the training epoch: #  6\n",
      "\n",
      "start training the isolated cluster:\n",
      "Train sum loss of isolated clusters: 1060.29\n",
      "Train ave loss of isolated clusters over all nodes : 0.2691\n",
      "\n",
      "start training the inter-cluster:\n",
      "Train sum loss of all clusters including inter linking edges: 3988.2\n",
      "Train ave loss of all clusters including inter linking edges over all nodes : 1.0122\n",
      "\n",
      " during the training epoch: #  7\n",
      "\n",
      "start training the isolated cluster:\n",
      "Train sum loss of isolated clusters: 1012.24\n",
      "Train ave loss of isolated clusters over all nodes : 0.2569\n",
      "\n",
      "start training the inter-cluster:\n",
      "Train sum loss of all clusters including inter linking edges: 3870.92\n",
      "Train ave loss of all clusters including inter linking edges over all nodes : 0.9825\n",
      "\n",
      " during the training epoch: #  8\n",
      "\n",
      "start training the isolated cluster:\n",
      "Train sum loss of isolated clusters: 940.106\n",
      "Train ave loss of isolated clusters over all nodes : 0.2386\n",
      "\n",
      "start training the inter-cluster:\n",
      "Train sum loss of all clusters including inter linking edges: 3662.18\n",
      "Train ave loss of all clusters including inter linking edges over all nodes : 0.9295\n",
      "\n",
      " during the training epoch: #  9\n",
      "\n",
      "start training the isolated cluster:\n",
      "Train sum loss of isolated clusters: 897.704\n",
      "Train ave loss of isolated clusters over all nodes : 0.2278\n",
      "\n",
      "start training the inter-cluster:\n",
      "Train sum loss of all clusters including inter linking edges: 3500.72\n",
      "Train ave loss of all clusters including inter linking edges over all nodes : 0.8885\n",
      "\n",
      " during the training epoch: #  10\n",
      "\n",
      "start training the isolated cluster:\n",
      "Train sum loss of isolated clusters: 847.848\n",
      "Train ave loss of isolated clusters over all nodes : 0.2152\n",
      "\n",
      "start training the inter-cluster:\n",
      "Train sum loss of all clusters including inter linking edges: 3335.92\n",
      "Train ave loss of all clusters including inter linking edges over all nodes : 0.8467\n",
      "\n",
      " during the training epoch: #  11\n",
      "\n",
      "start training the isolated cluster:\n",
      "Train sum loss of isolated clusters: 820.622\n",
      "Train ave loss of isolated clusters over all nodes : 0.2083\n",
      "\n",
      "start training the inter-cluster:\n",
      "Train sum loss of all clusters including inter linking edges: 3211.43\n",
      "Train ave loss of all clusters including inter linking edges over all nodes : 0.8151\n",
      "\n",
      " during the training epoch: #  12\n",
      "\n",
      "start training the isolated cluster:\n",
      "Train sum loss of isolated clusters: 764.953\n",
      "Train ave loss of isolated clusters over all nodes : 0.1942\n",
      "\n",
      "start training the inter-cluster:\n",
      "Train sum loss of all clusters including inter linking edges: 3040.66\n",
      "Train ave loss of all clusters including inter linking edges over all nodes : 0.7717\n",
      "\n",
      " during the training epoch: #  13\n",
      "\n",
      "start training the isolated cluster:\n",
      "Train sum loss of isolated clusters: 714.254\n",
      "Train ave loss of isolated clusters over all nodes : 0.1813\n",
      "\n",
      "start training the inter-cluster:\n",
      "Train sum loss of all clusters including inter linking edges: 2912.76\n",
      "Train ave loss of all clusters including inter linking edges over all nodes : 0.7393\n",
      "\n",
      " during the training epoch: #  14\n",
      "\n",
      "start training the isolated cluster:\n",
      "Train sum loss of isolated clusters: 644.399\n",
      "Train ave loss of isolated clusters over all nodes : 0.1636\n",
      "\n",
      "start training the inter-cluster:\n",
      "Train sum loss of all clusters including inter linking edges: 2720.39\n",
      "Train ave loss of all clusters including inter linking edges over all nodes : 0.6905\n",
      "\n",
      " during the training epoch: #  15\n",
      "\n",
      "start training the isolated cluster:\n",
      "Train sum loss of isolated clusters: 587.251\n",
      "Train ave loss of isolated clusters over all nodes : 0.149\n",
      "\n",
      "start training the inter-cluster:\n",
      "Train sum loss of all clusters including inter linking edges: 2516.36\n",
      "Train ave loss of all clusters including inter linking edges over all nodes : 0.6387\n",
      "\n",
      " during the training epoch: #  16\n",
      "\n",
      "start training the isolated cluster:\n",
      "Train sum loss of isolated clusters: 540.115\n",
      "Train ave loss of isolated clusters over all nodes : 0.1371\n",
      "\n",
      "start training the inter-cluster:\n",
      "Train sum loss of all clusters including inter linking edges: 2393.89\n",
      "Train ave loss of all clusters including inter linking edges over all nodes : 0.6076\n",
      "\n",
      " during the training epoch: #  17\n",
      "\n",
      "start training the isolated cluster:\n",
      "Train sum loss of isolated clusters: 491.293\n",
      "Train ave loss of isolated clusters over all nodes : 0.1247\n",
      "\n",
      "start training the inter-cluster:\n",
      "Train sum loss of all clusters including inter linking edges: 2237.7\n",
      "Train ave loss of all clusters including inter linking edges over all nodes : 0.5679\n",
      "\n",
      " during the training epoch: #  18\n",
      "\n",
      "start training the isolated cluster:\n",
      "Train sum loss of isolated clusters: 462.892\n",
      "Train ave loss of isolated clusters over all nodes : 0.1175\n",
      "\n",
      "start training the inter-cluster:\n",
      "Train sum loss of all clusters including inter linking edges: 2123.08\n",
      "Train ave loss of all clusters including inter linking edges over all nodes : 0.5389\n",
      "\n",
      " during the training epoch: #  19\n",
      "\n",
      "start training the isolated cluster:\n",
      "Train sum loss of isolated clusters: 455.931\n",
      "Train ave loss of isolated clusters over all nodes : 0.1157\n",
      "\n",
      "start training the inter-cluster:\n",
      "Train sum loss of all clusters including inter linking edges: 2051.17\n",
      "Train ave loss of all clusters including inter linking edges over all nodes : 0.5206\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gcn_trainer = ClusterGCNTrainer(clustering_machine, dataset.num_node_features, dataset.num_classes)\n",
    "gcn_trainer.train(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F-1 score: 0.8434\n"
     ]
    }
   ],
   "source": [
    "gcn_trainer.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 22])\n",
      "<class 'networkx.classes.graph.Graph'>\n",
      "<class 'networkx.classes.reportviews.NodeView'> [0, 1, 8, 3, 2, 4, 6, 7, 9, 5]\n",
      "[0, 1]\n",
      "{0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1}\n",
      "<class 'networkx.classes.graph.Graph'>\n",
      "[(8, 9), (6, 7), (7, 9), (9, 5)]\n",
      "11\n",
      "[5, 6, 7, 8, 9]\n",
      "{5: 0, 6: 1, 7: 2, 8: 3, 9: 4}\n",
      "[[3, 4], [1, 2], [2, 4], [4, 0], [4, 3], [2, 1], [4, 2], [0, 4]]\n",
      "[[8, 9], [6, 7], [7, 9], [9, 5], [9, 8], [7, 6], [9, 7], [5, 9]]\n",
      "\n",
      "investigate the point of mapper:\n",
      "[4, 3, 0, 2] [1]\n",
      "valid the set use of the graph/subgraph edges:\n",
      "{(0, 1), (1, 2), (1, 3), (6, 7), (4, 6), (8, 9), (9, 5), (2, 5), (0, 8), (2, 4), (7, 9)}\n",
      "{(8, 9), (9, 5), (6, 7), (7, 9)}\n",
      "print the graph difference: \n",
      "{(0, 1), (1, 2), (1, 3), (4, 6), (2, 5), (0, 8), (2, 4)}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# trial on the subgraph\n",
    "\n",
    "edge_index = torch.tensor([[0, 1, 0, 8, 1, 3, 1, 2, 4, 2, 4, 6, 6, 7, 7, 9, 2, 5, 5, 9, 9, 8], \n",
    "                           [1, 0, 8, 0, 3, 1, 2, 1, 2, 4, 6, 4, 7, 6, 9, 7, 5, 2, 9, 5, 8, 9]])\n",
    "\n",
    "print(edge_index.shape)\n",
    "tmp = edge_index.t().numpy().tolist()\n",
    "\n",
    "graph = nx.from_edgelist(tmp)\n",
    "# or  G=nx.Graph(edgelist) # use Graph constructor\n",
    "# here Graph class is for undirected graph, for directed: use DiGraph class instead\n",
    "print(type(graph))\n",
    "# begin to partition\n",
    "partition_num = 2\n",
    "clusters = [cluster for cluster in range(partition_num)]\n",
    "print(type(graph.nodes()), graph.nodes())\n",
    "# randomdized \n",
    "# cluster_membership = {node: random.choice(clusters) for node in graph.nodes()}\n",
    "\n",
    "# trivial for test case\n",
    "node_count = 10\n",
    "cluster_membership = {node: 0 for node in range(node_count//partition_num)}\n",
    "cluster_membership.update({node: 1 for node in range(node_count//partition_num, node_count)})\n",
    "\n",
    "print(clusters)\n",
    "print(cluster_membership)\n",
    "\n",
    "# for subfgraph\n",
    "cluster = 1\n",
    "# print(graph.nodes())\n",
    "\n",
    "subgraph = graph.subgraph([node for node in sorted(graph.nodes()) if cluster_membership[node] == cluster])\n",
    "print(type(subgraph))\n",
    "# for undirected graph, it is only stored once in networkx class\n",
    "print(subgraph.edges())\n",
    "print(len(graph.edges()))\n",
    "\n",
    "sg_nodes = {}\n",
    "sg_edges = {}\n",
    "\n",
    "sg_nodes[cluster] = [node for node in sorted(subgraph.nodes())]\n",
    "print(sg_nodes[cluster])  # just convert it into a list of nodes and store inside the dict\n",
    "mapper = {node: i for i, node in enumerate(sorted(sg_nodes[cluster]))}\n",
    "print(mapper)\n",
    "mapper2 = {node: node for i, node in enumerate(sorted(sg_nodes[cluster]))}\n",
    "\n",
    "# the edges inside its own partition, from two directions since it is an undirected graph\n",
    "sg_edges[cluster] = [[mapper[edge[0]], mapper[edge[1]]] for edge in subgraph.edges()] +  \\\n",
    "                           [[mapper[edge[1]], mapper[edge[0]]] for edge in subgraph.edges()]\n",
    "# there will be no key errors since all is inside subgraph\n",
    "original = [[mapper2[edge[0]], mapper2[edge[1]]] for edge in subgraph.edges()] +  \\\n",
    "                           [[mapper2[edge[1]], mapper2[edge[0]]] for edge in subgraph.edges()]\n",
    "\n",
    "print(sg_edges[cluster])\n",
    "print(original)\n",
    "# investigate the point of mapper:\n",
    "print()\n",
    "print('investigate the point of mapper:')\n",
    "sg_train_nodes = {}\n",
    "sg_test_nodes = {}\n",
    "sg_train_nodes[cluster], sg_test_nodes[cluster] = train_test_split(list(mapper.values()), test_size = 0.1)\n",
    "\n",
    "print(sg_train_nodes[cluster], sg_test_nodes[cluster])\n",
    "\n",
    "\n",
    "# validiate the graph set\n",
    "print('valid the set use of the graph/subgraph edges:')\n",
    "print(set(graph.edges()) )\n",
    "print(set(subgraph.edges()))\n",
    "print('print the graph difference: ')\n",
    "print(set(graph.edges()) - set(subgraph.edges()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful GPU handle commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# free GPU memory\n",
    "!(nvidia-smi | grep 'python' | awk '{ print $3 }' | xargs -n1 kill -9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_geometric]",
   "language": "python",
   "name": "conda-env-pytorch_geometric-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
