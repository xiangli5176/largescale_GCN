{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrate model inter-cluster with three clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "from utils import *\n",
    "from Custom_GCNConv import Net\n",
    "from Cluster_Machine import ClusteringMachine\n",
    "from Cluster_Trainer import ClusterGCNTrainer_mini_Train\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Trivial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 2.],\n",
      "        [0., 3.],\n",
      "        [0., 4.],\n",
      "        [0., 5.],\n",
      "        [0., 6.],\n",
      "        [0., 7.],\n",
      "        [0., 8.],\n",
      "        [0., 9.]]) torch.Size([10, 2])\n"
     ]
    }
   ],
   "source": [
    "'''Trivial data'''\n",
    "edge_index = torch.tensor([[0, 1, 1, 3, 1, 2, 4, 2, 4, 6, 6, 7, 7, 9, 2, 5, 9, 8], \n",
    "                           [1, 0, 3, 1, 2, 1, 2, 4, 6, 4, 7, 6, 9, 7, 5, 2, 8, 9]])\n",
    "# features = torch.rand(10, 3)\n",
    "features = torch.tensor([[0, 0], [0, 1], [0, 2], [0, 3], [0, 4],  \n",
    "                           [0, 5], [0, 6], [0, 7], [0, 8], [0, 9]], dtype = torch.float)\n",
    "# label = torch.tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "\n",
    "label = torch.tensor([0, 1, 1, 0, 1, 1, 1, 0, 0, 0])\n",
    "print(features, features.shape)\n",
    "\n",
    "check_clustering_machine = ClusteringMachine(edge_index, features, label)\n",
    "\n",
    "clustering_folder = './res_save_batch/clustering/'\n",
    "check_folder_exist(clustering_folder)\n",
    "\n",
    "clustering_file_name = clustering_folder + 'check_clustering_machine.txt'\n",
    "os.makedirs(os.path.dirname(clustering_file_name), exist_ok=True)\n",
    "with open(clustering_file_name, \"wb\") as fp:\n",
    "    pickle.dump(check_clustering_machine, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### minibatch train nodes and batch validatioin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 0.5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_batch_folder = './res_save_batch/mini_batch_files/'\n",
    "check_folder_exist(mini_batch_folder)\n",
    "\n",
    "with open(clustering_file_name, \"rb\") as fp:\n",
    "    clustering_machine = pickle.load(fp)\n",
    "\n",
    "clustering_machine.split_whole_nodes_edges_then_cluster(0.4, 0.4)\n",
    "# generate the batches for train and validation\n",
    "clustering_machine.mini_batch_train_clustering(mini_batch_folder, 1, train_batch_num = 2) # include number of layers\n",
    "\n",
    "clustering_machine.mini_batch_validation_clustering(mini_batch_folder, 1, valid_batch_num = 2)\n",
    "\n",
    "# construct the batch trainer\n",
    "gcn_trainer_batch = ClusterGCNTrainer_mini_Train(mini_batch_folder, 2, 2, input_layers = [16], dropout=0.3)\n",
    "\n",
    "gcn_trainer_batch.train(1, 0.0001, 0.1, train_batch_num = 2)\n",
    "gcn_trainer_batch.batch_validate(valid_batch_num = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic module for execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Execute the testing program '''\n",
    "def set_clustering_machine(data, intermediate_data_folder, test_ratio = 0.05, validation_ratio = 0.85, neigh_layer = 1, train_frac = 1.0, \\\n",
    "                           valid_part_num = 1, train_part_num = 2, test_part_num = 1):\n",
    "    \"\"\"\n",
    "        Set the clustering:\n",
    "            1) data: the target dataset data\n",
    "            2) intermediate_data_folder: path to store the intermediate generated data\n",
    "            3) test_ratio, validation_ratio: data split ratio\n",
    "            4) neigh_layer: number of hops (layers) for the neighbor nodes \n",
    "            5) train_frac: each time including fraction of the neigbor nodes in each layer\n",
    "            6) valid_part_num, train_part_num, test_part_num :  batch number for validation, train and test data correspondingly\n",
    "    \"\"\"\n",
    "    connect_edge_index, connect_features, connect_label = filter_out_isolate(data.edge_index, data.x, data.y)\n",
    "    clustering_machine = ClusteringMachine(connect_edge_index, connect_features, connect_label)\n",
    "#     clustering_machine.split_cluster_nodes_edges(test_ratio, validation_ratio, partition_num = train_part_num)\n",
    "    # mini-batch only: split to train test valid before clustering\n",
    "    clustering_machine.split_whole_nodes_edges_then_cluster(test_ratio, validation_ratio)\n",
    "    \n",
    "    # generate mini-batches\n",
    "    \n",
    "    mini_batch_folder = intermediate_data_folder + 'mini_batch_files/'\n",
    "    check_folder_exist(mini_batch_folder)  # if exist then delete\n",
    "    \n",
    "    clustering_machine.mini_batch_train_clustering(mini_batch_folder, neigh_layer, fraction = train_frac, train_batch_num = train_part_num)\n",
    "    # for validation , fraction has to be 1.0 so that to include the information form original graph\n",
    "    clustering_machine.mini_batch_validation_clustering(mini_batch_folder, neigh_layer, fraction = 1.0, valid_batch_num = valid_part_num)\n",
    "    \n",
    "    # stored the clustering machine with train-batch , validation-batch \n",
    "    clustering_file_folder = intermediate_data_folder + 'clustering/'\n",
    "    check_folder_exist(clustering_file_folder)  # if exist then delete\n",
    "    clustering_file_name = clustering_file_folder + 'clustering_machine.txt'\n",
    "    os.makedirs(os.path.dirname(clustering_file_name), exist_ok=True)\n",
    "    with open(clustering_file_name, \"wb\") as fp:\n",
    "        pickle.dump(clustering_machine, fp)\n",
    "        \n",
    "    # can off-line load the clustering model with train-batch generated\n",
    "#     with open(clustering_file_name, \"rb\") as fp:\n",
    "#         clustering_machine = pickle.load(fp)\n",
    "\n",
    "    return mini_batch_folder\n",
    " \n",
    "### Different execution model\n",
    "def Cluster_train_valid_batch_run(mini_batch_folder, data_name, dataset, image_path, input_layer = [16, 16], epochs=300, \\\n",
    "                           dropout = 0.3, lr = 0.01, weight_decay = 0.01, mini_epoch_num = 5, \\\n",
    "                                 valid_part_num = 2, train_part_num = 2, test_part_num = 1):\n",
    "    \"\"\"\n",
    "    # Run the mini-batch model (train and validate both in batches)\n",
    "    Tuning parameters:  dropout, lr (learning rate), weight_decay: l2 regularization\n",
    "    return: validation accuracy value, validation F-1 value, time_training (ms), time_data_load (ms)\n",
    "    \"\"\"\n",
    "#     gcn_trainer_batch = ClusterGCNTrainer_mini_Train(mini_batch_folder, 2, 2, 2, 2, 2, input_layers = [16], dropout=0.3)\n",
    "    \n",
    "    gcn_trainer = ClusterGCNTrainer_mini_Train(mini_batch_folder, dataset.num_node_features, dataset.num_classes, input_layers = input_layer, dropout = dropout)\n",
    "    gcn_trainer.train(epoch_num=epochs, learning_rate=lr, weight_decay=weight_decay, mini_epoch_num = mini_epoch_num, train_batch_num = train_part_num)\n",
    "    \n",
    "    validation_F1, validation_accuracy = gcn_trainer.batch_validate(valid_batch_num = valid_part_num)\n",
    "    time_train_total = gcn_trainer.time_train_total\n",
    "    time_data_load = gcn_trainer.time_train_load_data\n",
    "    return validation_accuracy, validation_F1, time_train_total, time_data_load, gcn_trainer\n",
    "\n",
    "\n",
    "def Cluster_train_valid_batch_investigate(mini_batch_folder, data_name, dataset, image_path, input_layer = [16, 16], epochs=300, \\\n",
    "                           dropout = 0.3, lr = 0.01, weight_decay = 0.01, mini_epoch_num = 5, output_period = 10, \n",
    "                                         valid_part_num = 2, train_part_num = 2, test_part_num = 1):\n",
    "    \"\"\"\n",
    "        *** dynamically investigate the F1 score in the middle of the training after certain period ***\n",
    "        output: two dict containing F1-score and accuracy of a certain epoch index\n",
    "    \"\"\"\n",
    "    gcn_trainer = ClusterGCNTrainer_mini_Train(mini_batch_folder, dataset.num_node_features, dataset.num_classes, input_layers = input_layer, dropout = dropout)\n",
    "    Train_period_F1, Train_period_accuracy = gcn_trainer.train_investigate_F1(epoch_num=epochs, learning_rate=lr, weight_decay=weight_decay, mini_epoch_num = mini_epoch_num, \\\n",
    "                                                            output_period = output_period, train_batch_num = train_part_num, valid_batch_num = valid_part_num)\n",
    "    \n",
    "    return Train_period_F1, Train_period_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For specific output information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_train_loss_converge(mini_batch_folder, data_name, dataset, image_path,  comments, input_layer = [32, 16], epoch_num = 300, \\\n",
    "                              dropout = 0.3, lr = 0.0001, weight_decay = 0.01, mini_epoch_num = 5, \\\n",
    "                               valid_part_num = 2, train_part_num = 2, test_part_num = 1):\n",
    "    # mini-batch, but valid also in batches\n",
    "    a3, v3, time3, load3, Cluster_train_valid_batch_trainer = Cluster_train_valid_batch_run(mini_batch_folder, data_name, dataset, image_path, input_layer = input_layer, epochs=epoch_num, \\\n",
    "                                                                               dropout = dropout, lr = lr, weight_decay = weight_decay, mini_epoch_num = mini_epoch_num, \\\n",
    "                                                                               valid_part_num = valid_part_num, train_part_num = train_part_num, test_part_num = test_part_num)\n",
    "    \n",
    "    draw_Cluster_train_valid_batch = draw_trainer_info(data_name, Cluster_train_valid_batch_trainer, image_path, 'train_valid_batch_' + comments)\n",
    "    draw_Cluster_train_valid_batch.draw_ave_loss_per_node()\n",
    "    \n",
    "\n",
    "def execute_one(mini_batch_folder, image_path, repeate_time = 5, input_layer = [32], epoch_num = 300, \\\n",
    "                dropout = 0.3, lr = 0.0001, weight_decay = 0.01, mini_epoch_num = 5, \\\n",
    "                valid_part_num = 2, train_part_num = 2, test_part_num = 1):\n",
    "    \"\"\"\n",
    "        return validation accuracy and F1 for all four models after all epoch_num of training\n",
    "    \"\"\"\n",
    "    validation_accuracy = {}\n",
    "    validation_f1 = {}\n",
    "    time_total_train = {}\n",
    "    time_data_load = {}\n",
    "    \n",
    "    # Each graph model corresponds to one function below\n",
    "#     graph_model = ['batch_valid', 'train_batch', 'whole_graph', 'isolate']\n",
    "    graph_model = ['batch_valid']\n",
    "    for i in range(repeate_time):\n",
    "        model_res = []\n",
    "        \n",
    "        model_res.append(Cluster_train_valid_batch_run(mini_batch_folder, data_name, dataset, image_path, input_layer = input_layer, epochs=epoch_num, \\\n",
    "                                                         dropout = dropout, lr = lr, weight_decay = weight_decay, mini_epoch_num = mini_epoch_num, \\\n",
    "                                                      valid_part_num = valid_part_num, train_part_num = train_part_num, test_part_num = test_part_num)[:4])\n",
    "        \n",
    "#         model_res.append(Isolate_clustering_run(clustering_machine, data_name, dataset, image_path, input_layer = input_layer, epochs=epoch_num, neigh_layer = layer_num, frac = frac, \\\n",
    "#                                                         dropout = dropout, lr = lr, weight_decay = weight_decay)[:4])\n",
    "        \n",
    "        validation_accuracy[i], validation_f1[i], time_total_train[i], time_data_load[i] = zip(*model_res)\n",
    "    return graph_model, validation_accuracy, validation_f1, time_total_train, time_data_load\n",
    "\n",
    "def execute_investigate(mini_batch_folder, image_path, repeate_time = 5, input_layer = [32], epoch_num = 300, \\\n",
    "                        dropout = 0.3, lr = 0.0001, weight_decay = 0.01, mini_epoch_num = 5, output_period = 10, \\\n",
    "                         valid_part_num = 2, train_part_num = 2, test_part_num = 1):\n",
    "    \"\"\"\n",
    "        investigate validation accuracy and F1 periodically (after each mini_epoch_num) during the epoch_num training\n",
    "    \"\"\"\n",
    "    \n",
    "    Train_peroid_f1 = {}\n",
    "    Train_peroid_accuracy = {}\n",
    "    \n",
    "    for i in range(repeate_time):\n",
    "        Train_peroid_f1[i], Train_peroid_accuracy[i] = Cluster_train_valid_batch_investigate(mini_batch_folder, data_name, dataset, image_path, input_layer = input_layer, epochs=epoch_num, \\\n",
    "                                            dropout = dropout, lr = lr, weight_decay = weight_decay, mini_epoch_num = mini_epoch_num, output_period = output_period, \\\n",
    "                                                                    valid_part_num = valid_part_num, train_part_num = train_part_num, test_part_num = test_part_num)\n",
    "        \n",
    "    return Train_peroid_f1, Train_peroid_accuracy\n",
    "\n",
    "\"\"\"To test one single model for different parameter values\"\"\"\n",
    "def execute_tuning(tune_params, mini_batch_folder, image_path, repeate_time = 7, input_layer = [32], epoch_num = 400, \\\n",
    "                  dropout = 0.1, lr = 0.0001, weight_decay = 0.1, mini_epoch_num = 20, \\\n",
    "                  valid_part_num = 2, train_part_num = 2, test_part_num = 1):\n",
    "    \"\"\"\n",
    "        Tune all the hyperparameters\n",
    "        1) learning rate\n",
    "        2) dropout\n",
    "        3) layer unit number\n",
    "        4) weight decay\n",
    "    \"\"\"\n",
    "    validation_accuracy = {}\n",
    "    validation_f1 = {}\n",
    "    time_total_train = {}\n",
    "    time_data_load = {}\n",
    "    \n",
    "    res = [{tune_val : Cluster_train_valid_batch_run(mini_batch_folder, data_name, dataset, image_path, input_layer = input_layer, epochs=epoch_num, \\\n",
    "            dropout = dropout, lr = lr, weight_decay = weight_decay, mini_epoch_num = tune_val, \\\n",
    "            valid_part_num = valid_part_num, train_part_num = train_part_num, test_part_num = test_part_num)[:4] for tune_val in tune_params} for i in range(repeate_time)]\n",
    "    \n",
    "    for i, ref in enumerate(res):\n",
    "        validation_accuracy[i] = {tune_val : res_lst[0] for tune_val, res_lst in ref.items()}\n",
    "        validation_f1[i] = {tune_val : res_lst[1] for tune_val, res_lst in ref.items()}\n",
    "        time_total_train[i] = {tune_val : res_lst[2] for tune_val, res_lst in ref.items()}\n",
    "        time_data_load[i] = {tune_val : res_lst[3] for tune_val, res_lst in ref.items()}\n",
    "        \n",
    "    return validation_accuracy, validation_f1, time_total_train, time_data_load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-test run for convenience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_train_loss(data, data_name, dataset, image_data_path, intermediate_data_path, partition_nums, layers, \\\n",
    "                      dropout = 0.1, lr = 0.0001, weight_decay = 0.1, mini_epoch_num = 20, valid_part_num = 2):\n",
    "    for partn in partition_nums:\n",
    "        for GCN_layer in layers:\n",
    "            net_layer = len(GCN_layer) + 1\n",
    "            hop_layer = net_layer\n",
    "            print('Start checking train loss for partition num: ' + str(partn) + ' hop layer: ' + str(hop_layer))\n",
    "            img_path = image_data_path + 'cluster_num_' + str(partn) + '/' + 'net_layer_' + str(net_layer) + '_hop_layer_' + str(hop_layer) + '/'\n",
    "            intermediate_data_folder = intermediate_data_path + 'cluster_num_' + str(partn) + '/' + 'net_layer_' + str(net_layer) + '_hop_layer_' + str(hop_layer) + '/'\n",
    "            \n",
    "            # set the batch for validation and train\n",
    "            mini_batch_folder = set_clustering_machine(data, intermediate_data_folder, test_ratio = 0.05, validation_ratio = 0.85, neigh_layer = hop_layer, train_frac = 1.0, \\\n",
    "                           valid_part_num = valid_part_num, train_part_num = partn, test_part_num = 1)\n",
    "            \n",
    "            check_train_loss_converge(mini_batch_folder, data_name, dataset, img_path, 'part_num_' + str(partn), input_layer = GCN_layer, epoch_num = 400, \\\n",
    "                                     dropout = dropout, lr = lr, weight_decay = weight_decay, mini_epoch_num = mini_epoch_num, \n",
    "                                     valid_part_num = valid_part_num, train_part_num = partn, test_part_num = 1)\n",
    "            \n",
    "#             # for the large dataset and split first case, the cluster info cannot be generated\n",
    "#             clustering_machine.mini_batch_train_clustering(hop_layer)\n",
    "#             draw_cluster_info(clustering_machine, data_name, img_path, comments = '_cluster_node_distr_' + str(hop_layer) + '_hops')\n",
    "            \n",
    "def output_F1_score(data, data_name, dataset, image_data_path, intermediate_data_path, partition_nums, layers, \\\n",
    "                    dropout = 0.1, lr = 0.0001, weight_decay = 0.1, mini_epoch_num = 20, valid_part_num = 2):            \n",
    "    for partn in partition_nums:\n",
    "        for GCN_layer in layers:\n",
    "            net_layer = len(GCN_layer) + 1\n",
    "            hop_layer = net_layer\n",
    "            \n",
    "            # set the save path\n",
    "            print('Start running for partition num: ' + str(partn) + ' hop layer ' + str(hop_layer))\n",
    "            img_path = image_data_path + 'cluster_num_' + str(partn) + '/' + 'net_layer_' + str(net_layer) + '_hop_layer_' + str(hop_layer) + '/'\n",
    "            intermediate_data_folder = intermediate_data_path + 'cluster_num_' + str(partn) + '/' + 'net_layer_' + str(net_layer) + '_hop_layer_' + str(hop_layer) + '/'\n",
    "            \n",
    "            # set the batch for validation and train\n",
    "            mini_batch_folder = set_clustering_machine(data, intermediate_data_folder, test_ratio = 0.05, validation_ratio = 0.85, neigh_layer = hop_layer, train_frac = 1.0, \\\n",
    "                           valid_part_num = valid_part_num, train_part_num = partn, test_part_num = 1)\n",
    "            \n",
    "            # start to run the model, train and validation \n",
    "            graph_model, validation_accuracy, validation_f1, time_total_train, time_data_load = \\\n",
    "                execute_one(mini_batch_folder, img_path, repeate_time = 7, input_layer = GCN_layer, epoch_num = 400, \n",
    "                                            dropout = dropout, lr = lr, weight_decay = weight_decay, mini_epoch_num = mini_epoch_num, \\\n",
    "                                             valid_part_num = valid_part_num, train_part_num = partn, test_part_num = 1)\n",
    "            \n",
    "            \n",
    "            validation_accuracy = store_data_multi_tests(validation_accuracy, data_name, graph_model, img_path, 'test_cluster_num_' + str(partn) + '_hops_' + str(hop_layer))\n",
    "            draw_data_multi_tests(validation_accuracy, data_name, 'vali_cluster_num_' + str(partn) + '_hop_' + str(hop_layer), 'models', 'Accuracy')\n",
    "\n",
    "            validation_f1 = store_data_multi_tests(validation_f1, data_name, graph_model, img_path, 'validation_cluster_num_' + str(partn) + '_hops_' + str(hop_layer))\n",
    "            draw_data_multi_tests(validation_f1, data_name, 'vali_cluster_num_' + str(partn) + '_hop_' + str(hop_layer), 'models', 'F1 score')\n",
    "\n",
    "            time_train = store_data_multi_tests(time_total_train, data_name, graph_model, img_path, 'train_time_cluster_num_' + str(partn) + '_hops_' + str(hop_layer))\n",
    "            draw_data_multi_tests(time_train, data_name, 'train_time_cluster_num_' + str(partn) + '_hop_' + str(hop_layer), 'models', 'Train Time (ms)')\n",
    "\n",
    "            time_load = store_data_multi_tests(time_data_load, data_name, graph_model, img_path, 'load_time_cluster_num_' + str(partn) + '_hops_' + str(hop_layer))\n",
    "            draw_data_multi_tests(time_load, data_name, 'load_time_cluster_num_' + str(partn) + '_hop_' + str(hop_layer), 'models', 'Load Time (ms)')\n",
    "\n",
    "def output_train_investigate(data, data_name, dataset, image_data_path, intermediate_data_path, partition_nums, layers, \\\n",
    "                             dropout = 0.1, lr = 0.0001, weight_decay = 0.1, mini_epoch_num = 20, output_period = 40, valid_part_num = 2):            \n",
    "    for partn in partition_nums:\n",
    "        for GCN_layer in layers:\n",
    "            net_layer = len(GCN_layer) + 1\n",
    "            hop_layer = net_layer\n",
    "            # set the save path\n",
    "            print('Start running for partition num: ' + str(partn) + ' hop layer ' + str(hop_layer))\n",
    "            img_path = image_data_path + 'cluster_num_' + str(partn) + '/' + 'net_layer_' + str(net_layer) + '_hop_layer_' + str(hop_layer) + '/'\n",
    "            intermediate_data_folder = intermediate_data_path + 'cluster_num_' + str(partn) + '/' + 'net_layer_' + str(net_layer) + '_hop_layer_' + str(hop_layer) + '/'\n",
    "            \n",
    "            # set the batch for validation and train\n",
    "            mini_batch_folder = set_clustering_machine(data, intermediate_data_folder, test_ratio = 0.05, validation_ratio = 0.85, neigh_layer = hop_layer, train_frac = 1.0, \\\n",
    "                           valid_part_num = valid_part_num, train_part_num = partn, test_part_num = 1)\n",
    "\n",
    "            Train_peroid_f1, Train_peroid_accuracy = execute_investigate(mini_batch_folder, img_path, repeate_time = 7, input_layer = GCN_layer, epoch_num = 400, \\\n",
    "                                            dropout = dropout, lr = lr, weight_decay = weight_decay, mini_epoch_num = mini_epoch_num, output_period = output_period, \\\n",
    "                                            valid_part_num = valid_part_num, train_part_num = partn, test_part_num = 1)\n",
    "            \n",
    "            Train_peroid_f1 = store_data_multi_investigate(Train_peroid_f1, data_name, 'F1_score', img_path, 'invest_batch_num_' + str(partn) + '_hops_' + str(hop_layer))\n",
    "            draw_data_multi_tests(Train_peroid_f1, data_name, 'Train_process_batch_num_' + str(partn) + '_hop_' + str(hop_layer), 'epoch number', 'F1 score')\n",
    "\n",
    "            Train_peroid_accuracy = store_data_multi_investigate(Train_peroid_accuracy, data_name, 'Accuracy', img_path, 'invest_batch_num_' + str(partn) + '_hops_' + str(hop_layer))\n",
    "            draw_data_multi_tests(Train_peroid_accuracy, data_name, 'Train_process_batch_num_' + str(partn) + '_hop_' + str(hop_layer), 'epoch number', 'Accuracy')\n",
    "            \n",
    "            \n",
    "def output_tune_param(data, data_name, dataset, image_data_path, intermediate_data_path, partition_nums, layers, dropout = 0.1, lr = 0.0001, weight_decay = 0.1, mini_epoch_num = 20, valid_part_num = 2):\n",
    "    for partn in partition_nums:\n",
    "        for GCN_layer in layers:\n",
    "            net_layer = len(GCN_layer) + 1\n",
    "            hop_layer = net_layer\n",
    "            # Set the tune parameters and name\n",
    "            tune_name = 'batch_epoch_num'\n",
    "            tune_params = [400, 200, 100, 50, 20, 10, 5]\n",
    "#             tune_name = 'weight_decay'\n",
    "#             tune_params = [0.0001, 0.001, 0.01, 0.1]\n",
    "\n",
    "            img_path = image_data_path + 'cluster_num_' + str(partn) + '/' + 'net_layer_' + str(net_layer) + '_hop_layer_' + str(hop_layer) + '/' + 'tune_' + tune_name + '/'\n",
    "            intermediate_data_folder = intermediate_data_path + 'cluster_num_' + str(partn) + '/' + 'net_layer_' + str(net_layer) + '_hop_layer_' + str(hop_layer) + '/' + 'tune_' + tune_name + '/'\n",
    "            print('Start tuning for tuning param: ' + tune_name + ' partition num: ' + str(partn) + ' hop layer ' + str(hop_layer))\n",
    "            \n",
    "            # set the batch for validation and train\n",
    "            mini_batch_folder = set_clustering_machine(data, intermediate_data_folder, test_ratio = 0.05, validation_ratio = 0.85, neigh_layer = hop_layer, train_frac = 1.0, \\\n",
    "                           valid_part_num = valid_part_num, train_part_num = partn, test_part_num = 1)\n",
    "\n",
    "            validation_accuracy, validation_f1, time_total_train, time_data_load = execute_tuning(tune_params, mini_batch_folder, img_path, repeate_time = 7, \\\n",
    "                                                input_layer = GCN_layer, epoch_num = 400, dropout = dropout, lr = lr, weight_decay = weight_decay, mini_epoch_num = mini_epoch_num, \\\n",
    "                                                valid_part_num = valid_part_num, train_part_num = partn, test_part_num = 1)\n",
    "\n",
    "            validation_accuracy = store_data_multi_tuning(tune_params,validation_accuracy, data_name, img_path, 'accuracy_cluster_num_' + str(partn) + '_hops_' + str(hop_layer))\n",
    "            draw_data_multi_tests(validation_accuracy, data_name, 'vali_cluster_num_' + str(partn) + '_hop_' + str(hop_layer), 'epochs_per_batch', 'Accuracy')\n",
    "\n",
    "            validation_f1 = store_data_multi_tuning(tune_params, validation_f1, data_name, img_path, 'validation_cluster_num_' + str(partn) + '_hops_' + str(hop_layer))\n",
    "            draw_data_multi_tests(validation_f1, data_name, 'vali_cluster_num_' + str(partn) + '_hop_' + str(hop_layer), 'epochs_per_batch', 'F1 score')\n",
    "\n",
    "            time_train = store_data_multi_tuning(tune_params, time_total_train, data_name, img_path, 'train_time_cluster_num_' + str(partn) + '_hops_' + str(hop_layer))\n",
    "            draw_data_multi_tests(time_train, data_name, 'train_time_cluster_num_' + str(partn) + '_hop_' + str(hop_layer), 'epochs_per_batch', 'Train Time (ms)')\n",
    "\n",
    "            time_load = store_data_multi_tuning(tune_params, time_data_load, data_name, img_path, 'load_time_cluster_num_' + str(partn) + '_hops_' + str(hop_layer))\n",
    "            draw_data_multi_tests(time_load, data_name, 'load_time_cluster_num_' + str(partn) + '_hop_' + str(hop_layer), 'epochs_per_batch', 'Load Time (ms)')\n",
    "            \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_data_root = '/media/xiangli/storage1/projects/tmpdata/'\n",
    "test_folder_name = 'hpc_large_scale_1/train_10%_full_neigh_random_split_tr_valid_first/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cora dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "data_name = 'Cora'\n",
    "dataset = Planetoid(root = local_data_root + 'Planetoid/Cora', name=data_name)\n",
    "data = dataset[0]\n",
    "image_data_path = './results/' + data_name + '/' + test_folder_name\n",
    "intermediate_data_folder = './intermediate_data/' + data_name + '/' + test_folder_name\n",
    "\n",
    "partition_nums = [2]\n",
    "layers = [[32]]\n",
    "tune_lr = 0.0001\n",
    "check_mini_epoch = 20\n",
    "# partition_nums = [2, 4, 8]\n",
    "# layers = [[], [32], [32, 32], [32, 32, 32]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check convergence\n",
    "output_train_loss(data, data_name, dataset, image_data_path, intermediate_data_folder, partition_nums, layers, \\\n",
    "                  dropout = 0.1, lr = tune_lr, weight_decay = 0.1, mini_epoch_num = check_mini_epoch, valid_part_num = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output accuracy, F1, time (train, load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check F1-score\n",
    "output_F1_score(data, data_name, dataset, image_data_path, intermediate_data_folder, partition_nums, layers, \\\n",
    "                dropout = 0.1, lr = tune_lr, weight_decay = 0.1, mini_epoch_num = check_mini_epoch, valid_part_num = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In process training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start running for partition num: 2 hop layer 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# in-train process\n",
    "output_train_investigate(data, data_name, dataset, image_data_path, intermediate_data_folder, partition_nums, layers, \\\n",
    "                         dropout = 0.5, lr = 0.0001, weight_decay = 0.001, mini_epoch_num = 20, output_period = 40, valid_part_num = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tuning epoch number for each train-batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tune_param(data, data_name, dataset, image_data_path, intermediate_data_folder, partition_nums, layers, \\\n",
    "                  dropout = 0.5, lr = 0.0001, weight_decay = 0.001, mini_epoch_num = 20, valid_part_num = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# free GPU memory\n",
    "!(nvidia-smi | grep 'python' | awk '{ print $3 }' | xargs -n1 kill -9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_geometric]",
   "language": "python",
   "name": "conda-env-pytorch_geometric-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
