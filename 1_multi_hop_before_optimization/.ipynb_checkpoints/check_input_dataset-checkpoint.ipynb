{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from utils import filter_out_isolate, draw_cluster_info, draw_isolate_cluster_info, draw_trainer_info, print_data_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "def print_data_info(data):\n",
    "    \n",
    "    print('Info (attributes) of a single data instance')\n",
    "    print(data, '\\n number of nodes: ', data.num_nodes, '\\n number of edges: ', data.num_edges, \\\n",
    "      '\\n number of features per ndoe: ', data.num_node_features, '\\n number of edge features: ', data.num_edge_features, \\\n",
    "#       '\\n number of classifying labels of dataset: ', dataset.num_classes, \\\n",
    "      '\\n all the attributes of data: ', data.keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_data_root = '/media/xiangli/storage1/projects/tmpdata/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Belong to the Planetoid series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cora dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "data_name = 'Cora'\n",
    "dataset = Planetoid(root = local_data_root + 'Planetoid/Cora', name=data_name)\n",
    "data = dataset[0]\n",
    "print_data_info(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citeseer Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "data_name = 'CiteSeer'\n",
    "dataset = Planetoid(root = local_data_root + 'Planetoid/CiteSeer', name=data_name)\n",
    "data = dataset[0]\n",
    "print_data_info(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PubMed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "data_name = 'PubMed'\n",
    "dataset = Planetoid(root = local_data_root + 'Planetoid/PubMed', name=data_name)\n",
    "data = dataset[0]\n",
    "print_data_info(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stanford Education Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of data:  10\n",
      "Info (attributes) of a single data instance\n",
      "Data(circle=[325], circle_batch=[325], edge_index=[2, 5732], x=[348, 1406]) \n",
      " number of nodes:  348 \n",
      " number of edges:  5732 \n",
      " number of features per ndoe:  1406 \n",
      " number of edge features:  0 \n",
      " all the attributes of data:  ['x', 'edge_index', 'circle', 'circle_batch']\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import SNAPDataset\n",
    "# available_datasets = {\n",
    "#         'ego-facebook': ['facebook.tar.gz'],\n",
    "#         'ego-gplus': ['gplus.tar.gz'],   # data format failure\n",
    "#         'ego-twitter': ['twitter.tar.gz'],    # too large for processing\n",
    "#         'soc-epinions1': ['soc-Epinions1.txt.gz'],\n",
    "#         'soc-livejournal1': ['soc-LiveJournal1.txt.gz'],\n",
    "#         'soc-pokec': ['soc-pokec-relationships.txt.gz'],\n",
    "#         'soc-slashdot0811': ['soc-Slashdot0811.txt.gz'],\n",
    "#         'soc-slashdot0922': ['soc-Slashdot0902.txt.gz'],\n",
    "#         'wiki-vote': ['wiki-Vote.txt.gz'],\n",
    "#     }\n",
    "data_name = 'ego-facebook'\n",
    "dataset = SNAPDataset(root = local_data_root + data_name, name=data_name)\n",
    "print('number of data: ', len(dataset))\n",
    "data = dataset[0]\n",
    "print_data_info(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'ego-twitter'\n",
    "dataset = SNAPDataset(root = local_data_root + data_name, name=data_name)\n",
    "print('number of data: ', len(dataset))\n",
    "data = dataset[0]\n",
    "print_data_info(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://snap.stanford.edu/data/wiki-Vote.txt.gz\n",
      "/media/xiangli/storage1/projects/tmpdata/wiki-vote/wiki-vote/raw/wiki-Vote.txt.gz\n",
      "Extracting /media/xiangli/storage1/projects/tmpdata/wiki-vote/wiki-vote/raw/wiki-Vote.txt.gz\n",
      "Processing...\n",
      "Done!\n",
      "number of data:  1\n",
      "Info (attributes) of a single data instance\n",
      "Data(edge_index=[2, 103689]) \n",
      " number of nodes:  7115 \n",
      " number of edges:  103689 \n",
      " number of features per ndoe:  0 \n",
      " number of edge features:  0 \n",
      " all the attributes of data:  ['edge_index']\n"
     ]
    }
   ],
   "source": [
    "data_name = 'wiki-vote'\n",
    "dataset = SNAPDataset(root = local_data_root + data_name, name=data_name)\n",
    "print('number of data: ', len(dataset))\n",
    "data = dataset[0]\n",
    "print_data_info(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://snap.stanford.edu/data/soc-pokec-relationships.txt.gz\n",
      "/media/xiangli/storage1/projects/tmpdata/soc-pokec/soc-pokec/raw/soc-pokec-relationships.txt.gz\n",
      "Extracting /media/xiangli/storage1/projects/tmpdata/soc-pokec/soc-pokec/raw/soc-pokec-relationships.txt.gz\n",
      "Processing...\n",
      "Done!\n",
      "number of data:  1\n",
      "Info (attributes) of a single data instance\n",
      "Data(edge_index=[2, 30622560]) \n",
      " number of nodes:  1632804 \n",
      " number of edges:  30622560 \n",
      " number of features per ndoe:  0 \n",
      " number of edge features:  0 \n",
      " all the attributes of data:  ['edge_index']\n"
     ]
    }
   ],
   "source": [
    "data_name = 'soc-pokec'\n",
    "dataset = SNAPDataset(root = local_data_root + data_name, name=data_name)\n",
    "print('number of data: ', len(dataset))\n",
    "data = dataset[0]\n",
    "print_data_info(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://snap.stanford.edu/data/soc-LiveJournal1.txt.gz\n",
      "/media/xiangli/storage1/projects/tmpdata/soc-livejournal1/soc-livejournal1/raw/soc-LiveJournal1.txt.gz\n",
      "Extracting /media/xiangli/storage1/projects/tmpdata/soc-livejournal1/soc-livejournal1/raw/soc-LiveJournal1.txt.gz\n",
      "Processing...\n",
      "Done!\n",
      "number of data:  1\n",
      "Info (attributes) of a single data instance\n",
      "Data(edge_index=[2, 68993773]) \n",
      " number of nodes:  4847571 \n",
      " number of edges:  68993773 \n",
      " number of features per ndoe:  0 \n",
      " number of edge features:  0 \n",
      " all the attributes of data:  ['edge_index']\n"
     ]
    }
   ],
   "source": [
    "data_name = 'soc-livejournal1'\n",
    "dataset = SNAPDataset(root = local_data_root + data_name, name=data_name)\n",
    "print('number of data: ', len(dataset))\n",
    "data = dataset[0]\n",
    "print_data_info(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://snap.stanford.edu/data/soc-Slashdot0811.txt.gz\n",
      "/media/xiangli/storage1/projects/tmpdata/soc-slashdot0811/soc-slashdot0811/raw/soc-Slashdot0811.txt.gz\n",
      "Extracting /media/xiangli/storage1/projects/tmpdata/soc-slashdot0811/soc-slashdot0811/raw/soc-Slashdot0811.txt.gz\n",
      "Processing...\n",
      "Done!\n",
      "number of data:  1\n",
      "Info (attributes) of a single data instance\n",
      "Data(edge_index=[2, 905468]) \n",
      " number of nodes:  77360 \n",
      " number of edges:  905468 \n",
      " number of features per ndoe:  0 \n",
      " number of edge features:  0 \n",
      " all the attributes of data:  ['edge_index']\n"
     ]
    }
   ],
   "source": [
    "data_name = 'soc-slashdot0811'\n",
    "dataset = SNAPDataset(root = local_data_root + data_name, name=data_name)\n",
    "print('number of data: ', len(dataset))\n",
    "data = dataset[0]\n",
    "print_data_info(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import CitationFull\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TUD dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "data_name = 'facebook_ct1'\n",
    "dataset = TUDataset(root = local_data_root + data_name, name=data_name)\n",
    "print('number of data: ', len(dataset))\n",
    "data = dataset[0]\n",
    "print_data_info(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Belong to the CitationFull series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/abojchevski/graph2gauss/raw/master/data/cora_ml.npz\n",
      "Processing...\n",
      "Done!\n",
      "number of data:  1\n",
      "Info (attributes) of a single data instance\n",
      "Data(edge_index=[2, 16316], x=[2995, 2879], y=[2995]) \n",
      " number of nodes:  2995 \n",
      " number of edges:  16316 \n",
      " number of features per ndoe:  2879 \n",
      " number of edge features:  0 \n",
      " all the attributes of data:  ['x', 'edge_index', 'y']\n"
     ]
    }
   ],
   "source": [
    "# assert name in ['cora', 'cora_ml', 'citeseer', 'dblp', 'pubmed']\n",
    "from torch_geometric.datasets import CitationFull\n",
    "data_name = 'cora_ml'\n",
    "dataset = CitationFull(root = local_data_root + data_name,  name=data_name)\n",
    "print('number of data: ', len(dataset))\n",
    "data = dataset[0]\n",
    "print_data_info(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/abojchevski/graph2gauss/raw/master/data/citeseer.npz\n",
      "Processing...\n",
      "Done!\n",
      "number of data:  1\n",
      "Info (attributes) of a single data instance\n",
      "Data(edge_index=[2, 10674], x=[4230, 602], y=[4230]) \n",
      " number of nodes:  4230 \n",
      " number of edges:  10674 \n",
      " number of features per ndoe:  602 \n",
      " number of edge features:  0 \n",
      " all the attributes of data:  ['x', 'edge_index', 'y']\n"
     ]
    }
   ],
   "source": [
    "data_name = 'citeseer'\n",
    "dataset = CitationFull(root = local_data_root + data_name,  name=data_name)\n",
    "print('number of data: ', len(dataset))\n",
    "data = dataset[0]\n",
    "print_data_info(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/abojchevski/graph2gauss/raw/master/data/dblp.npz\n",
      "Processing...\n",
      "Done!\n",
      "number of data:  1\n",
      "Info (attributes) of a single data instance\n",
      "Data(edge_index=[2, 105734], x=[17716, 1639], y=[17716]) \n",
      " number of nodes:  17716 \n",
      " number of edges:  105734 \n",
      " number of features per ndoe:  1639 \n",
      " number of edge features:  0 \n",
      " all the attributes of data:  ['x', 'edge_index', 'y']\n"
     ]
    }
   ],
   "source": [
    "data_name = 'dblp'\n",
    "dataset = CitationFull(root = local_data_root + data_name,  name=data_name)\n",
    "print('number of data: ', len(dataset))\n",
    "data = dataset[0]\n",
    "print_data_info(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/abojchevski/graph2gauss/raw/master/data/pubmed.npz\n",
      "Processing...\n",
      "Done!\n",
      "number of data:  1\n",
      "Info (attributes) of a single data instance\n",
      "Data(edge_index=[2, 88648], x=[19717, 500], y=[19717]) \n",
      " number of nodes:  19717 \n",
      " number of edges:  88648 \n",
      " number of features per ndoe:  500 \n",
      " number of edge features:  0 \n",
      " all the attributes of data:  ['x', 'edge_index', 'y']\n"
     ]
    }
   ],
   "source": [
    "data_name = 'pubmed'\n",
    "dataset = CitationFull(root = local_data_root + data_name,  name=data_name)\n",
    "print('number of data: ', len(dataset))\n",
    "data = dataset[0]\n",
    "print_data_info(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CoraFull dataset (alias for CitationFull with name \"Cora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/abojchevski/graph2gauss/raw/master/data/cora.npz\n",
      "Processing...\n",
      "Done!\n",
      "number of data:  1\n",
      "Info (attributes) of a single data instance\n",
      "Data(edge_index=[2, 126842], x=[19793, 8710], y=[19793]) \n",
      " number of nodes:  19793 \n",
      " number of edges:  126842 \n",
      " number of features per ndoe:  8710 \n",
      " number of edge features:  0 \n",
      " all the attributes of data:  ['x', 'edge_index', 'y']\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import CoraFull\n",
    "data_name = 'CoraFull'\n",
    "dataset = CoraFull(root = local_data_root + 'CoralFull')\n",
    "print('number of data: ', len(dataset))\n",
    "data = dataset[0]\n",
    "print_data_info(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coauthor dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of data:  1\n",
      "Info (attributes) of a single data instance\n",
      "Data(edge_index=[2, 163788], x=[18333, 6805], y=[18333]) \n",
      " number of nodes:  18333 \n",
      " number of edges:  163788 \n",
      " number of features per ndoe:  6805 \n",
      " number of edge features:  0 \n",
      " all the attributes of data:  ['x', 'edge_index', 'y']\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Coauthor\n",
    "data_name = 'cs'\n",
    "dataset = Coauthor(root = local_data_root + 'Coauthor/' + data_name, name=data_name)\n",
    "print('number of data: ', len(dataset))\n",
    "data = dataset[0]\n",
    "print_data_info(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Amazon\n",
    "data_name = 'computers'    # can also be 'computers', 'photos'\n",
    "dataset = Amazon(root = local_data_root + 'Amazon/' + data_name, name=data_name)\n",
    "print('number of data: ', len(dataset))\n",
    "data = dataset[0]\n",
    "print_data_info(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'photo'    # can also be 'computers', 'photos'\n",
    "dataset = Amazon(root = local_data_root + 'Amazon/' + data_name, name=data_name)\n",
    "print('number of data: ', len(dataset))\n",
    "data = dataset[0]\n",
    "print_data_info(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PPI dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of data:  20\n",
      "Info (attributes) of a single data instance\n",
      "Data(edge_index=[2, 32318], x=[1767, 50], y=[1767, 121]) \n",
      " number of nodes:  1767 \n",
      " number of edges:  32318 \n",
      " number of features per ndoe:  50 \n",
      " number of edge features:  0 \n",
      " all the attributes of data:  ['x', 'edge_index', 'y']\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import PPI\n",
    "data_name = 'PPI'    # can also be 'computers'\n",
    "dataset = PPI(root = local_data_root + 'PPI/' + data_name)\n",
    "print('number of data: ', len(dataset))\n",
    "data = dataset[0]\n",
    "print_data_info(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of data:  2\n",
      "Info (attributes) of a single data instance\n",
      "Data(edge_index=[2, 100648], x=[3224, 50], y=[3224, 121]) \n",
      " number of nodes:  3224 \n",
      " number of edges:  100648 \n",
      " number of features per ndoe:  50 \n",
      " number of edge features:  0 \n",
      " all the attributes of data:  ['x', 'edge_index', 'y']\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import PPI\n",
    "data_name = 'PPI'    # can also be 'computers'\n",
    "dataset = PPI(root = local_data_root + 'PPI/' + data_name, split=\"test\")\n",
    "print('number of data: ', len(dataset))\n",
    "data = dataset[0]\n",
    "print_data_info(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of data:  2\n",
      "Info (attributes) of a single data instance\n",
      "Data(edge_index=[2, 97446], x=[3230, 50], y=[3230, 121]) \n",
      " number of nodes:  3230 \n",
      " number of edges:  97446 \n",
      " number of features per ndoe:  50 \n",
      " number of edge features:  0 \n",
      " all the attributes of data:  ['x', 'edge_index', 'y']\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import PPI\n",
    "data_name = 'PPI'    # can also be 'computers'\n",
    "dataset = PPI(root = local_data_root + 'PPI/' + data_name, split=\"val\")\n",
    "print('number of data: ', len(dataset))\n",
    "data = dataset[0]\n",
    "print_data_info(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reddit dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Reddit\n",
    "data_name = 'Reddit'    # can also be 'computers'\n",
    "dataset = Reddit(root = local_data_root + '/' + data_name)\n",
    "print('number of data: ', len(dataset))\n",
    "data = dataset[0]\n",
    "print_data_info(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QM7b dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import QM7b\n",
    "data_name = 'QM7b'    # can also be 'computers'\n",
    "dataset = QM7b(root = local_data_root + '/' + data_name)\n",
    "print('number of data: ', len(dataset))\n",
    "data = dataset[0]\n",
    "print_data_info(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QM9 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of data:  133246\n",
      "Info (attributes) of a single data instance\n",
      "Data(edge_attr=[8, 4], edge_index=[2, 8], pos=[5, 3], x=[5, 13], y=[1, 12]) \n",
      " number of nodes:  5 \n",
      " number of edges:  8 \n",
      " number of features per ndoe:  13 \n",
      " number of edge features:  4 \n",
      " all the attributes of data:  ['x', 'edge_index', 'edge_attr', 'y', 'pos']\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import QM9\n",
    "data_name = 'QM9'    # can also be 'computers'\n",
    "dataset = QM9(root = local_data_root + '/' + data_name)\n",
    "print('number of data: ', len(dataset))\n",
    "data = dataset[0]\n",
    "print_data_info(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of data:  1\n",
      "Info (attributes) of a single data instance\n",
      "Data(edge_index=[2, 58086], edge_norm=[58086], edge_type=[58086], test_idx=[36], test_y=[36], train_idx=[140], train_y=[140]) \n",
      " number of nodes:  8285 \n",
      " number of edges:  58086 \n",
      " number of features per ndoe:  0 \n",
      " number of edge features:  0 \n",
      " all the attributes of data:  ['edge_index', 'edge_type', 'edge_norm', 'train_idx', 'train_y', 'test_idx', 'test_y']\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Entities\n",
    "data_name = 'AIFB'    # can also be 'computers'\n",
    "dataset = Entities(root = local_data_root + 'Entities/' + data_name, name=data_name)\n",
    "print('number of data: ', len(dataset))\n",
    "data = dataset[0]\n",
    "print_data_info(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Large data scale :  Entities  AM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 25486294176 bytes. Error code 12 (Cannot allocate memory)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-bc60b553bc30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'AM'\u001b[0m    \u001b[0;31m# can also be 'computers'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEntities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal_data_root\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'Entities/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'number of data: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint_data_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_1_4_0_geometric/lib/python3.7/site-packages/torch_geometric/datasets/entities.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, name, transform, pre_transform)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'AIFB'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'AM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'MUTAG'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'BGS'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEntities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessed_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_1_4_0_geometric/lib/python3.7/site-packages/torch_geometric/data/in_memory_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter)\u001b[0m\n\u001b[1;32m     51\u001b[0m                  pre_filter=None):\n\u001b[1;32m     52\u001b[0m         super(InMemoryDataset, self).__init__(root, transform, pre_transform,\n\u001b[0;32m---> 53\u001b[0;31m                                               pre_filter)\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_1_4_0_geometric/lib/python3.7/site-packages/torch_geometric/data/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'process'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_1_4_0_geometric/lib/python3.7/site-packages/torch_geometric/data/dataset.py\u001b[0m in \u001b[0;36m_process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessed_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessed_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pre_transform.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_1_4_0_geometric/lib/python3.7/site-packages/torch_geometric/datasets/entities.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         oh = F.one_hot(edge_type,\n\u001b[0;32m--> 106\u001b[0;31m                        num_classes=2 * len(relations)).to(torch.float)\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0mdeg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscatter_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medge_type\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 25486294176 bytes. Error code 12 (Cannot allocate memory)\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Entities\n",
    "data_name = 'AM'    # can also be 'computers'\n",
    "dataset = Entities(root = local_data_root + 'Entities/' + data_name, name=data_name)\n",
    "print('number of data: ', len(dataset))\n",
    "data = dataset[0]\n",
    "print_data_info(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'MUTAG'    # can also be 'computers'\n",
    "dataset = Entities(root = local_data_root + 'Entities/' + data_name, name=data_name)\n",
    "print('number of data: ', len(dataset))\n",
    "data = dataset[0]\n",
    "print_data_info(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'BGS'    # can also be 'computers'\n",
    "dataset = Entities(root = local_data_root + 'Entities/' + data_name, name=data_name)\n",
    "print('number of data: ', len(dataset))\n",
    "data = dataset[0]\n",
    "print_data_info(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GEDDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import GEDDataset\n",
    "data_name = 'LINUX'    # can also be 'computers'\n",
    "dataset = GEDDataset(root = local_data_root + 'GEDDataset/' + data_name, name=data_name)\n",
    "print('number of data: ', len(dataset))\n",
    "data = dataset[0]\n",
    "print('Info (attributes) of a single data instance')\n",
    "print(data, '\\n number of nodes: ', data.num_nodes, '\\n number of edges: ', data.num_edges, \\\n",
    "  '\\n number of features per ndoe: ', data.num_node_features, '\\n number of edge features: ', data.num_edge_features, \\\n",
    "  '\\n all the attributes of data: ', data.keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNISTSuperpixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import MNISTSuperpixels\n",
    "data_name = 'MNISTSuperpixels'    # can also be 'computers'\n",
    "dataset = MNISTSuperpixels(root = local_data_root + '/' + data_name)\n",
    "print('number of data: ', len(dataset))\n",
    "data = dataset[0]\n",
    "print_data_info(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ShapeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import ShapeNet\n",
    "data_name = 'ShapeNet'    # can also be 'computers'\n",
    "dataset = ShapeNet(root = local_data_root + '/' + data_name)\n",
    "print('number of data: ', len(dataset))\n",
    "data = dataset[0]\n",
    "print_data_info(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCPNetDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import PCPNetDataset\n",
    "data_name = 'Noisy'    # can also be 'computers'\n",
    "dataset = PCPNetDataset(root = local_data_root + 'PCPNetDataset/' + data_name, category = 'Noisy')\n",
    "print('number of data: ', len(dataset))\n",
    "data = dataset[0]\n",
    "print('Info (attributes) of a single data instance')\n",
    "print(data, '\\n number of nodes: ', data.num_nodes, '\\n number of edges: ', data.num_edges, \\\n",
    "  '\\n number of features per ndoe: ', data.num_node_features, '\\n number of edge features: ', data.num_edge_features, \\\n",
    "  '\\n all the attributes of data: ', data.keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S3DIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the data set here contains 4096 nodes, with a total number of 20291 data\n",
    "\n",
    "This dataset can be used as the mini-batch directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import S3DIS\n",
    "data_name = 'S3DIS'    # can also be 'computers'\n",
    "dataset = S3DIS(root = local_data_root + '/' + data_name)\n",
    "print('number of data: ', len(dataset))\n",
    "data = dataset[0]\n",
    "print_data_info(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select = [(idx, data.num_nodes) for idx, data in enumerate(dataset) if data.num_nodes > 5000]\n",
    "print(select)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# free GPU memory\n",
    "!(nvidia-smi | grep 'python' | awk '{ print $3 }' | xargs -n1 kill -9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_1_4_0_geometric]",
   "language": "python",
   "name": "conda-env-pytorch_1_4_0_geometric-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
