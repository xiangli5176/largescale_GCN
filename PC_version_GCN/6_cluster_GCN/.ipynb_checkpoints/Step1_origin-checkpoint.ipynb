{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrate model inter-cluster with three clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from utils import filter_out_isolate, draw_cluster_info, draw_isolate_cluster_info, draw_trainer_info, print_data_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import torch\n",
    "from torch_geometric.utils import scatter_\n",
    "\n",
    "import math\n",
    "import random\n",
    "\n",
    "from torch.nn import Parameter\n",
    "from torch_scatter import scatter_add\n",
    "# from torch_geometric.nn import MessagePassing\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import add_remaining_self_loops\n",
    "\n",
    "### ====================== Establish a GCN based model ========================\n",
    "class ListModule(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Abstract list layer class.\n",
    "    \"\"\"\n",
    "    def __init__(self, *args):\n",
    "        \"\"\"\n",
    "        Module initializing.\n",
    "        \"\"\"\n",
    "        super(ListModule, self).__init__()\n",
    "        idx = 0\n",
    "        for module in args:\n",
    "            self.add_module(str(idx), module)\n",
    "            idx += 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Getting the indexed layer.\n",
    "        \"\"\"\n",
    "        if idx < 0 or idx >= len(self._modules):\n",
    "            raise IndexError('index {} is out of range'.format(idx))\n",
    "        it = iter(self._modules.values())\n",
    "        for i in range(idx):\n",
    "            next(it)\n",
    "        return next(it)\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "        Iterating on the layers.\n",
    "        \"\"\"\n",
    "        return iter(self._modules.values())\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Number of layers.\n",
    "        \"\"\"\n",
    "        return len(self._modules)\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, input_layers = [16, 16], dropout=0.3):\n",
    "        \"\"\"\n",
    "        input layers: list of integers\n",
    "        dropout: probability of droping out \n",
    "        \"\"\"\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.input_layers = input_layers\n",
    "        self.dropout = dropout\n",
    "        self.setup_layers()\n",
    "\n",
    "    def setup_layers(self):\n",
    "        \"\"\"\n",
    "        Creating the layes based on the args.\n",
    "        \"\"\"\n",
    "        self.layers = []\n",
    "        self.input_layers = [self.in_channels] + self.input_layers + [self.out_channels]\n",
    "        for i, _ in enumerate(self.input_layers[:-1]):\n",
    "            self.layers.append(GCNConv(self.input_layers[i],self.input_layers[i+1]))\n",
    "        self.layers = ListModule(*self.layers)\n",
    "\n",
    "    # change the dropout positions: \n",
    "    def forward(self, edge_index, features, edge_weights = None):\n",
    "        if len(self.layers) > 1:\n",
    "            for i in range(len(self.layers)-1):\n",
    "                features = F.relu(self.layers[i](features, edge_index, edge_weights))\n",
    "#                 if i>0:\n",
    "                features = F.dropout(features, p = self.dropout, training = self.training)\n",
    "                    \n",
    "            features = self.layers[len(self.layers)-1](features, edge_index, edge_weights)\n",
    "        else:\n",
    "            features = self.layers[0](features, edge_index, edge_weights)    # for a single layer case\n",
    "\n",
    "        predictions = F.log_softmax(features, dim=1)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partition GCN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partition method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import metis\n",
    "import random\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import chain\n",
    "\n",
    "class ClusteringMachine(object):\n",
    "    \"\"\"\n",
    "    Clustering the graph, feature set and label. Performed on the CPU side\n",
    "    \"\"\"\n",
    "    def __init__(self, edge_index, features, label, partition_num = 2):\n",
    "        \"\"\"\n",
    "        :param edge_index: COO format of the edge indices.\n",
    "        :param features: Feature matrix (ndarray).\n",
    "        :param label: label vector (ndarray).\n",
    "        \"\"\"\n",
    "        tmp = edge_index.t().numpy().tolist()\n",
    "        self.graph = nx.from_edgelist(tmp)\n",
    "        self.features = features\n",
    "        self.label = label\n",
    "        self.partition_num = partition_num\n",
    "        self._set_sizes()\n",
    "        self.edge_index = edge_index\n",
    "        # this will get the edge weights in a complete graph\n",
    "        self.get_edge_weight(self.edge_index, self.node_count)\n",
    "\n",
    "    def _set_sizes(self):\n",
    "        \"\"\"\n",
    "        Setting the feature and class count.\n",
    "        \"\"\"\n",
    "        self.node_count = self.features.shape[0]\n",
    "        self.feature_count = self.features.shape[1]    # features all always in the columns\n",
    "        self.label_count = len(np.unique(self.label.numpy()) )\n",
    "        \n",
    "        \n",
    "    def decompose(self, test_ratio, validation_ratio):\n",
    "        \"\"\"\n",
    "        Decomposing the graph, partitioning the features and label, creating Torch arrays.\n",
    "        \"\"\"\n",
    "        # to keep the edge weights of the original whole graph:\n",
    "        \n",
    "        self.metis_clustering()\n",
    "#         self.random_clustering()\n",
    "        self._set_inter_clusters()\n",
    "        self.general_global_isolate_partitioning(test_ratio, validation_ratio)\n",
    "        # for the wholeGCNTraniner Purpose\n",
    "        self.general_accumulate_partition()\n",
    "        \n",
    "    def _set_inter_clusters(self):\n",
    "        # independent of the clustering method:\n",
    "        self.intersect_cluster = []\n",
    "        for i in range(1, self.partition_num):\n",
    "            tmp = [(m, n) for m, n in zip(self.clusters, self.clusters[i:])]\n",
    "            self.intersect_cluster.extend(tmp)\n",
    "        # initialize as the totla edges (without duplicates) all over the whole graph\n",
    "        self.macro_inter_edges = set(self.graph.edges())   # a sequence of tuple to indicate edges\n",
    "\n",
    "    def random_clustering(self, target_nodes, partition_num):\n",
    "        \"\"\"\n",
    "            Random clustering the nodes.\n",
    "            Input: \n",
    "                1) target_nodes: list of node \n",
    "                2) partition_num: number of partition to be generated\n",
    "            Output: \n",
    "                1) membership of each node\n",
    "        \"\"\"\n",
    "        # randomly divide into two clusters\n",
    "        nodes_order = [node for node in target_nodes]\n",
    "        random.shuffle(nodes_order)\n",
    "        n = (len(nodes_order) + partition_num - 1) // partition_num\n",
    "        partition_list = [nodes_order[i * n:(i + 1) * n] for i in range(partition_num)]\n",
    "#         cluster_membership = {node : i for i, node_list in enumerate(partition_list) for node in node_list}\n",
    "        cluster_nodes_global = {i : node_list for i, node_list in enumerate(partition_list)}\n",
    "        \n",
    "        return cluster_nodes_global\n",
    "\n",
    "    def metis_clustering(self, target_graph, partition_num):\n",
    "        \"\"\"\n",
    "            Random clustering the nodes.\n",
    "            Input: \n",
    "                1) target_nodes: list of node \n",
    "                2) partition_num: number of partition to be generated\n",
    "            Output: \n",
    "                1) membership of each node\n",
    "        \"\"\"\n",
    "        (st, parts) = metis.part_graph(target_graph, partition_num)\n",
    "        clusters = list(set(parts))\n",
    "        cluster_nodes_global = defaultdict(list)\n",
    "        for node, cluster_id in enumerate(parts):\n",
    "            cluster_nodes_global[cluster_id].append(node)\n",
    "        return cluster_nodes_global\n",
    "\n",
    "    def general_global_isolate_partitioning(self, test_ratio, validation_ratio):\n",
    "        \"\"\"\n",
    "        Creating data partitions and train-test splits.\n",
    "        \"\"\"\n",
    "        self.type = 'general'\n",
    "        relative_test_ratio = (test_ratio) / (1 - validation_ratio)\n",
    "        self.sg_nodes_global = {}\n",
    "        self.sg_edges_global = {}\n",
    "        self.sg_subgraph = {}\n",
    "        \n",
    "        self.sg_model_nodes_global = {}\n",
    "        self.sg_validation_nodes_global = {}\n",
    "        self.sg_train_nodes_global = {}\n",
    "        self.sg_test_nodes_global = {}\n",
    "        \n",
    "        # keep the info of each cluster:\n",
    "        self.info_isolate_cluster_size = {}\n",
    "        self.info_model_cluster_size = {}\n",
    "        self.info_validation_cluster_size = {}\n",
    "        self.info_train_cluster_size = {}\n",
    "        self.info_test_cluster_size = {}\n",
    "        \n",
    "        for cluster in self.clusters:\n",
    "            \n",
    "            self.sg_subgraph[cluster] = self.graph.subgraph([node for node in sorted(self.graph.nodes()) if self.cluster_membership[node] == cluster])\n",
    "            \n",
    "            self.sg_nodes_global[cluster] = sorted(node for node in self.sg_subgraph[cluster].nodes())\n",
    "            \n",
    "            self.sg_edges_global[cluster] = {edge for edge in self.sg_subgraph[cluster].edges()}\n",
    "            # substract two possible directions of edges\n",
    "            self.macro_inter_edges -= set([(edge[0], edge[1]) for edge in self.sg_subgraph[cluster].edges()] +  \\\n",
    "                                       [(edge[1], edge[0]) for edge in self.sg_subgraph[cluster].edges()])\n",
    "            \n",
    "            self.sg_model_nodes_global[cluster], self.sg_validation_nodes_global[cluster] = train_test_split(self.sg_nodes_global[cluster], test_size = validation_ratio)\n",
    "            self.sg_model_nodes_global[cluster] = sorted(self.sg_model_nodes_global[cluster])\n",
    "            self.sg_validation_nodes_global[cluster] = sorted(self.sg_validation_nodes_global[cluster])\n",
    "            \n",
    "            self.sg_train_nodes_global[cluster], self.sg_test_nodes_global[cluster] = train_test_split(self.sg_model_nodes_global[cluster], test_size = relative_test_ratio)\n",
    "            self.sg_train_nodes_global[cluster] = sorted(self.sg_train_nodes_global[cluster])\n",
    "            self.sg_test_nodes_global[cluster] = sorted(self.sg_test_nodes_global[cluster])\n",
    "            \n",
    "            # record the information of each cluster:\n",
    "            self.info_isolate_cluster_size[cluster] = len(self.sg_nodes_global[cluster])\n",
    "            self.info_model_cluster_size[cluster] = len(self.sg_model_nodes_global[cluster])\n",
    "            self.info_validation_cluster_size[cluster] = len(self.sg_validation_nodes_global[cluster])\n",
    "            \n",
    "            self.info_train_cluster_size[cluster] = len(self.sg_train_nodes_global[cluster])\n",
    "            self.info_test_cluster_size[cluster] = len(self.sg_test_nodes_global[cluster])\n",
    "    \n",
    "    def general_isolate_clustering(self, k):\n",
    "        \"\"\"\n",
    "            Still find the train batch, but cannot exceed the scope of the isolated clustering\n",
    "        \"\"\"\n",
    "        self.sg_mini_train_edges_global = {}\n",
    "        self.sg_mini_train_nodes_global = {}\n",
    "        \n",
    "        self.sg_mini_train_nodes_local = {}\n",
    "        self.sg_mini_train_edges_local = {}\n",
    "        self.sg_mini_train_edge_weight_local = {}\n",
    "        self.sg_mini_train_features = {}\n",
    "        self.sg_mini_train_labels = {}\n",
    "        \n",
    "        self.neighbor = defaultdict(dict)   # keep layer nodes of each layer\n",
    "        self.train_accum_neighbor = defaultdict(set)\n",
    "        \n",
    "        self.info_train_batch_size = {}\n",
    "        \n",
    "        for cluster in self.clusters:\n",
    "            self.neighbor[cluster] = {0 : set(self.sg_train_nodes_global[cluster])}\n",
    "            for layer in range(k):\n",
    "                # first accumulate last layer\n",
    "                self.train_accum_neighbor[cluster] |= self.neighbor[cluster][layer]\n",
    "                tmp_level = set()\n",
    "                for node in self.neighbor[cluster][layer]:\n",
    "                    tmp_level |= set(self.sg_subgraph[cluster].neighbors(node))\n",
    "                # add the new layer of neighbors\n",
    "                self.neighbor[cluster][layer+1] = tmp_level - self.train_accum_neighbor[cluster]\n",
    "#                 print('layer ' + str(layer + 1) + ' : ', self.neighbor[cluster][layer+1])\n",
    "            # the most outside layer: kth layer will be added:\n",
    "            self.train_accum_neighbor[cluster] |= self.neighbor[cluster][k]\n",
    "            batch_subgraph = self.sg_subgraph[cluster].subgraph(self.train_accum_neighbor[cluster])\n",
    "            \n",
    "            \n",
    "            # first select all the overlapping nodes of the train nodes\n",
    "            self.sg_mini_train_edges_global[cluster] = {edge for edge in batch_subgraph.edges()}\n",
    "            self.sg_mini_train_nodes_global[cluster] = sorted(node for node in batch_subgraph.nodes())\n",
    "            \n",
    "            \n",
    "            mini_mapper = {node: i for i, node in enumerate(self.sg_mini_train_nodes_global[cluster])}\n",
    "            sg_node_index_local = sorted(mini_mapper.values())\n",
    "            \n",
    "            self.sg_mini_train_edges_local[cluster] = \\\n",
    "                           [ [ mini_mapper[edge[0]], mini_mapper[edge[1]] ] for edge in self.sg_mini_train_edges_global[cluster] ] + \\\n",
    "                           [ [ mini_mapper[edge[1]], mini_mapper[edge[0]] ] for edge in self.sg_mini_train_edges_global[cluster] ] + \\\n",
    "                           [ [i, i] for i in sg_node_index_local ]  \n",
    "            \n",
    "            self.sg_mini_train_edge_weight_local[cluster] = \\\n",
    "                            [ self.edge_weight_global_dict[(edge[0], edge[1])] for edge in self.sg_mini_train_edges_global[cluster] ] + \\\n",
    "                            [ self.edge_weight_global_dict[(edge[1], edge[0])] for edge in self.sg_mini_train_edges_global[cluster] ] + \\\n",
    "                            [ self.edge_weight_global_dict[(i, i)] for i in self.sg_mini_train_nodes_global[cluster] ]\n",
    "            \n",
    "#             print('train nodes global for the cluster # ' + str(cluster), self.sg_train_nodes_global[cluster])\n",
    "            self.sg_mini_train_nodes_local[cluster] = [ mini_mapper[global_idx] for global_idx in self.sg_train_nodes_global[cluster] ]\n",
    "            \n",
    "            self.sg_mini_train_features[cluster] = self.features[self.sg_mini_train_nodes_global[cluster],:]\n",
    "            self.sg_mini_train_labels[cluster] = self.label[self.sg_mini_train_nodes_global[cluster]]\n",
    "            \n",
    "            # record information \n",
    "            self.info_train_batch_size[cluster] = len(self.sg_mini_train_nodes_global[cluster])\n",
    "        \n",
    "        # at last, out of all the cluster loop do the data transfer\n",
    "        self.transfer_edges_and_nodes()\n",
    "        self.mini_transfer_edges_and_nodes()\n",
    "        \n",
    "    def get_train_neighbor(self, k):\n",
    "        \"\"\"\n",
    "            get a collection of nodes: including k layers of neighbors together with original isolate cluster nodes\n",
    "            k: number of layers of neighbors\n",
    "        \"\"\"\n",
    "        # this self.neighbor keeps a record: in each cluster, the nodes of different layer of neighbors\n",
    "        self.neighbor = defaultdict(dict)   # keep layer nodes of each layer\n",
    "        self.train_accum_neighbor = defaultdict(set)\n",
    "        for cluster in self.clusters:\n",
    "            self.neighbor[cluster] = {0 : set(self.sg_train_nodes_global[cluster])}\n",
    "            \n",
    "            for layer in range(k):\n",
    "                # first accumulate last layer\n",
    "                self.train_accum_neighbor[cluster] |= self.neighbor[cluster][layer]\n",
    "                tmp_level = set()\n",
    "                for node in self.neighbor[cluster][layer]:\n",
    "                    tmp_level |= set(self.graph.neighbors(node))\n",
    "                # add the new layer of neighbors\n",
    "                self.neighbor[cluster][layer+1] = tmp_level - self.train_accum_neighbor[cluster]\n",
    "#                 print('layer ' + str(layer + 1) + ' : ', self.neighbor[cluster][layer+1])\n",
    "            # the most outside layer: kth layer will be added:\n",
    "            self.train_accum_neighbor[cluster] |= self.neighbor[cluster][k]\n",
    "#             print('accumulating ' + str(k) + ' layers: ', self.train_accum_neighbor[cluster])\n",
    "            # after getting the train k layer neighbor nodes, generating the graph\n",
    "            batch_subgraph = self.graph.subgraph(self.train_accum_neighbor[cluster])\n",
    "            print('nodes for cluster ' + str(cluster) + ' are: ', sorted(node for node in batch_subgraph.nodes()))\n",
    "            \n",
    "            print('edges for cluster ' + str(cluster) + ' are: ', {edge for edge in batch_subgraph.edges()} ) \n",
    "        \n",
    "        \n",
    "    def transfer_edges_and_nodes(self):\n",
    "        \"\"\"\n",
    "        Transfering the data to PyTorch format.\n",
    "        \"\"\"\n",
    "        self.edge_weight_global = torch.FloatTensor(self.edge_weight_global)\n",
    "        self.edge_index_global_self_loops = self.edge_index_global_self_loops\n",
    "#         self.label = torch.LongTensor(self.label)\n",
    "        for cluster in self.clusters:\n",
    "            self.sg_train_nodes_global[cluster] = torch.LongTensor(self.sg_train_nodes_global[cluster])\n",
    "            self.sg_test_nodes_global[cluster] = torch.LongTensor(self.sg_test_nodes_global[cluster])\n",
    "            self.sg_validation_nodes_global[cluster] = torch.LongTensor(self.sg_validation_nodes_global[cluster])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partition Graph with trainiing and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Custom_GCN_layer import Net\n",
    "import time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class ClusterGCNTrainer_mini_Train(object):\n",
    "    \"\"\"\n",
    "    Training a ClusterGCN.\n",
    "    \"\"\"\n",
    "    def __init__(self, clustering_machine, in_channels, out_channels, input_layers = [32, 16], dropout=0.3):\n",
    "        \"\"\"\n",
    "        :param in_channels, out_channels: input and output feature dimension\n",
    "        :param clustering_machine:\n",
    "        \"\"\"  \n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.clustering_machine = clustering_machine\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.input_layers = input_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.create_model()\n",
    "\n",
    "    def create_model(self):\n",
    "        \"\"\"\n",
    "        Creating a StackedGCN and transferring to CPU/GPU.\n",
    "        \"\"\"\n",
    "#         print('used layers are: ', str(self.input_layers))\n",
    "        self.model = Net(self.in_channels, self.out_channels, input_layers = self.input_layers, dropout = self.dropout)\n",
    "        self.model = self.model.to(self.device)\n",
    "    \n",
    "    # call the forward function batch by batch\n",
    "    def do_forward_pass(self, cluster):\n",
    "        \"\"\"\n",
    "        Making a forward pass with data from a given partition.\n",
    "        :param cluster: Cluster index.\n",
    "        :return average_loss: Average loss on the cluster.\n",
    "        :return node_count: Number of nodes.\n",
    "        \"\"\"\n",
    "        \n",
    "        '''Target and features are one-one mapping'''\n",
    "        # calculate the probabilites from log_sofmax\n",
    "        predictions = self.model(self.tr_edges, self.tr_features, self.tr_edge_weights)\n",
    "        \n",
    "        ave_loss = torch.nn.functional.nll_loss(predictions[self.tr_train_nodes], self.tr_target[self.tr_train_nodes])\n",
    "        node_count = self.tr_train_nodes.shape[0]\n",
    "\n",
    "        # for each cluster keep track of the counts of the nodes\n",
    "        return ave_loss, node_count\n",
    "\n",
    "\n",
    "    def update_average_loss(self, batch_average_loss, node_count, isolate = True):\n",
    "        \"\"\"\n",
    "        Updating the average loss in the epoch.\n",
    "        :param batch_average_loss: Loss of the cluster. \n",
    "        :param node_count: Number of nodes in currently processed cluster.\n",
    "        :return average_loss: Average loss in the epoch.\n",
    "        \"\"\"\n",
    "        self.accumulated_training_loss = self.accumulated_training_loss + batch_average_loss.item() * node_count\n",
    "        if isolate:\n",
    "            self.node_count_seen = self.node_count_seen + node_count\n",
    "        average_loss = self.accumulated_training_loss / self.node_count_seen\n",
    "        return average_loss\n",
    "\n",
    "\n",
    "    # iterate through epoch and also the clusters\n",
    "    def train(self, epoch_num=10, learning_rate=0.01, weight_decay = 0.01, mini_epoch_num = 1):\n",
    "        \"\"\"\n",
    "        Training a model.\n",
    "        \"\"\"\n",
    "        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        self.model.train()\n",
    "        self.record_ave_training_loss = []\n",
    "        self.time_train_load_data = 0\n",
    "        \n",
    "        epoch_partition = epoch_num // mini_epoch_num\n",
    "        t0 = time.time()\n",
    "        epoch_num\n",
    "        for epoch in range(epoch_partition):\n",
    "#             For test purpose, we let the clusters to follow specific order\n",
    "            random.shuffle(self.clustering_machine.clusters)\n",
    "            self.node_count_seen = 0\n",
    "            self.accumulated_training_loss = 0\n",
    "            for cluster in self.clustering_machine.clusters:\n",
    "                # for each cluster, we load once and train it for multiple epochs:\n",
    "                t1 = time.time()\n",
    "                \n",
    "                self.tr_edges = self.clustering_machine.sg_mini_train_edges_local[cluster].to(self.device)\n",
    "                self.tr_features = self.clustering_machine.sg_mini_train_features[cluster].to(self.device)\n",
    "                self.tr_edge_weights = self.clustering_machine.sg_mini_train_edge_weight_local[cluster].to(self.device)\n",
    "                self.tr_train_nodes = self.clustering_machine.sg_mini_train_nodes_local[cluster].to(self.device)\n",
    "                self.tr_target = self.clustering_machine.sg_mini_train_labels[cluster].to(self.device)\n",
    "                \n",
    "                self.time_train_load_data += (time.time() - t1) * 1000\n",
    "                # train each batch for multiple epochs\n",
    "                for mini_epoch in range(mini_epoch_num):\n",
    "                    self.optimizer.zero_grad()\n",
    "                    batch_ave_loss, node_count = self.do_forward_pass(cluster)\n",
    "                    batch_ave_loss.backward()\n",
    "                    self.optimizer.step()\n",
    "                    ave_loss = self.update_average_loss(batch_ave_loss, node_count)\n",
    "            \n",
    "            self.record_ave_training_loss.append(ave_loss)\n",
    "        # convert to ms\n",
    "        self.time_train_total = ((time.time() - t0) * 1000)\n",
    "        \n",
    "#         epochs.set_description(\"Ave Train Loss per node: %g \" % round(ave_loss,6))\n",
    "#         print(\"Train ave loss of overlapping clusters per node : %g\" % round(ave_loss,6))\n",
    "\n",
    "    \n",
    "    def do_validation_prediction(self, cluster):\n",
    "        \"\"\"\n",
    "        Scoring a cluster.\n",
    "        :param cluster: Cluster index.\n",
    "        :return prediction: Prediction matrix with probabilities.\n",
    "        :return target: Target vector.\n",
    "        \"\"\"\n",
    "        validation_nodes = self.clustering_machine.sg_validation_nodes_global[cluster].to(self.device)\n",
    "        prediction = self.model(self.edges, self.features, self.edge_weights)\n",
    "        \n",
    "        return prediction[validation_nodes], self.label[validation_nodes]\n",
    "\n",
    "    def validate(self):\n",
    "        \"\"\"\n",
    "        Scoring the test and printing the F-1 score.\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        self.predictions = []\n",
    "        self.targets = []\n",
    "        \n",
    "        self.edges = self.clustering_machine.edge_index_global_self_loops.to(self.device)\n",
    "        self.features = self.clustering_machine.features.to(self.device)\n",
    "        self.edge_weights = self.clustering_machine.edge_weight_global.to(self.device)\n",
    "        self.label = self.clustering_machine.label.to(self.device)\n",
    "        \n",
    "        for cluster in self.clustering_machine.clusters:\n",
    "            prediction, target = self.do_validation_prediction(cluster)\n",
    "\n",
    "            self.predictions.append(prediction.cpu().detach().numpy())\n",
    "            self.targets.append(target.cpu().detach().numpy())\n",
    "        \n",
    "        # concatenate all the ndarrays inside this list\n",
    "        self.targets = np.concatenate(self.targets)\n",
    "        # along axis:    axis == 1\n",
    "        self.predictions = np.concatenate(self.predictions).argmax(1)  # return the indices of maximum probability \n",
    "#         print('shape of the targets and predictions are: ', self.targets.shape, self.predictions.shape)\n",
    "        \n",
    "        f1 = f1_score(self.targets, self.predictions, average=\"micro\")\n",
    "        accuracy = accuracy_score(self.targets, self.predictions)\n",
    "#         print(\"\\nTest F-1 score: {:.4f}\".format(score))\n",
    "        return (f1, accuracy)\n",
    "\n",
    "    def do_batch_validation_prediction(self, cluster):\n",
    "        \"\"\"\n",
    "        Scoring a cluster.\n",
    "        :param cluster: Cluster index.\n",
    "        :return prediction: Prediction matrix with probabilities.\n",
    "        :return target: Target vector.\n",
    "        \"\"\"\n",
    "        predictions = self.model(self.valid_edges, self.valid_features, self.valid_edge_weights)\n",
    "        return predictions[self.valid_validation_nodes], self.valid_target[self.valid_validation_nodes]\n",
    "\n",
    "    def batch_validate(self):\n",
    "        \"\"\"\n",
    "        Scoring the test and printing the F-1 score.\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        self.predictions = []\n",
    "        self.targets = []\n",
    "        \n",
    "        for cluster in self.clustering_machine.clusters:\n",
    "            self.valid_edges = self.clustering_machine.sg_mini_valid_edges_local[cluster].to(self.device)\n",
    "            self.valid_features = self.clustering_machine.sg_mini_valid_features[cluster].to(self.device)\n",
    "            self.valid_edge_weights = self.clustering_machine.sg_mini_valid_edge_weight_local[cluster].to(self.device)\n",
    "            self.valid_validation_nodes = self.clustering_machine.sg_mini_valid_nodes_local[cluster].to(self.device)\n",
    "            self.valid_target = self.clustering_machine.sg_mini_valid_labels[cluster].to(self.device)\n",
    "            \n",
    "            prediction, target = self.do_batch_validation_prediction(cluster)\n",
    "\n",
    "            self.predictions.append(prediction.cpu().detach().numpy())\n",
    "            self.targets.append(target.cpu().detach().numpy())\n",
    "        \n",
    "        # concatenate all the ndarrays inside this list\n",
    "        self.targets = np.concatenate(self.targets)\n",
    "        # along axis:    axis == 1\n",
    "        self.predictions = np.concatenate(self.predictions).argmax(1)  # return the indices of maximum probability \n",
    "#         print('shape of the targets and predictions are: ', self.targets.shape, self.predictions.shape)\n",
    "        \n",
    "        f1 = f1_score(self.targets, self.predictions, average=\"micro\")\n",
    "        accuracy = accuracy_score(self.targets, self.predictions)\n",
    "#         print(\"\\nTest F-1 score: {:.4f}\".format(score))\n",
    "        return (f1, accuracy)\n",
    "\n",
    "# for cross-validation purpose: \n",
    "    def do_prediction(self, cluster):\n",
    "        \"\"\"\n",
    "        Scoring a cluster.\n",
    "        :param cluster: Cluster index.\n",
    "        :return prediction: Prediction matrix with probabilities.\n",
    "        :return target: Target vector.\n",
    "        \"\"\"\n",
    "        test_nodes = self.clustering_machine.sg_test_nodes_global[cluster].to(self.device)\n",
    "        prediction = self.model(self.edges, self.features, self.edge_weights)\n",
    "        \n",
    "        return prediction[test_nodes], self.label[test_nodes]\n",
    "    \n",
    "    def test(self):\n",
    "        \"\"\"\n",
    "        Scoring the test and printing the F-1 score.\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        self.predictions = []\n",
    "        self.targets = []\n",
    "        \n",
    "        self.edges = self.clustering_machine.edge_index_global_self_loops.to(self.device)\n",
    "        self.features = self.clustering_machine.features.to(self.device)\n",
    "        self.edge_weights = self.clustering_machine.edge_weight_global.to(self.device)\n",
    "        self.label = self.clustering_machine.label.to(self.device)\n",
    "        \n",
    "        for cluster in self.clustering_machine.clusters:\n",
    "            prediction, target = self.do_prediction(cluster)\n",
    "\n",
    "            self.predictions.append(prediction.cpu().detach().numpy())\n",
    "            self.targets.append(target.cpu().detach().numpy())\n",
    "        \n",
    "        # concatenate all the ndarrays inside this list\n",
    "        self.targets = np.concatenate(self.targets)\n",
    "        # along axis:    axis == 1\n",
    "        self.predictions = np.concatenate(self.predictions).argmax(1)  # return the indices of maximum probability \n",
    "#         print('shape of the targets and predictions are: ', self.targets.shape, self.predictions.shape)\n",
    "        \n",
    "        f1 = f1_score(self.targets, self.predictions, average=\"micro\")\n",
    "        accuracy = accuracy_score(self.targets, self.predictions)\n",
    "#         print(\"\\nTest F-1 score: {:.4f}\".format(score))\n",
    "        return (f1, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whole input graph as base case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class wholeClusterGCNTrainer_sequence(object):\n",
    "    \"\"\"\n",
    "    Training a ClusterGCN.\n",
    "    \"\"\"\n",
    "    def __init__(self, clustering_machine, in_channels, out_channels, input_layers = [16, 16], dropout=0.3):\n",
    "        \"\"\"\n",
    "        :param in_channels, out_channels: input and output feature dimension\n",
    "        :param clustering_machine:\n",
    "        \"\"\"  \n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.clustering_machine = clustering_machine\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.input_layers = input_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.create_model()\n",
    "\n",
    "    def create_model(self):\n",
    "        \"\"\"\n",
    "        Creating a StackedGCN and transferring to CPU/GPU.\n",
    "        \"\"\"\n",
    "#         print('used layers are: ', str(self.input_layers))\n",
    "        self.model = Net(self.in_channels, self.out_channels, input_layers = self.input_layers, dropout = self.dropout)\n",
    "        self.model = self.model.to(self.device)\n",
    "    \n",
    "    # call the forward function batch by batch\n",
    "    def do_forward_pass(self, cluster):\n",
    "        \"\"\"\n",
    "        Making a forward pass with data from a given partition.\n",
    "        :param cluster: Cluster index.\n",
    "        :return average_loss: Average loss on the cluster.\n",
    "        :return node_count: Number of nodes.\n",
    "        \"\"\"\n",
    "        \n",
    "        train_nodes = self.clustering_machine.sg_train_nodes_global[cluster].to(self.device)\n",
    "        \n",
    "        '''Target and features are one-one mapping'''\n",
    "        # calculate the probabilites from log_sofmax\n",
    "        predictions = self.model(self.edges, self.features, self.edge_weights)\n",
    "        \n",
    "        ave_loss = torch.nn.functional.nll_loss(predictions[train_nodes], self.label[train_nodes])\n",
    "        node_count = train_nodes.shape[0]\n",
    "\n",
    "        # for each cluster keep track of the counts of the nodes\n",
    "        return ave_loss, node_count\n",
    "\n",
    "\n",
    "    def update_average_loss(self, batch_average_loss, node_count, isolate = True):\n",
    "        \"\"\"\n",
    "        Updating the average loss in the epoch.\n",
    "        :param batch_average_loss: Loss of the cluster. \n",
    "        :param node_count: Number of nodes in currently processed cluster.\n",
    "        :return average_loss: Average loss in the epoch.\n",
    "        \"\"\"\n",
    "        self.accumulated_training_loss = self.accumulated_training_loss + batch_average_loss.item()*node_count\n",
    "        if isolate:\n",
    "            self.node_count_seen = self.node_count_seen + node_count\n",
    "        average_loss = self.accumulated_training_loss / self.node_count_seen\n",
    "        return average_loss\n",
    "\n",
    "    def do_prediction(self, cluster):\n",
    "        \"\"\"\n",
    "        Scoring a cluster.\n",
    "        :param cluster: Cluster index.\n",
    "        :return prediction: Prediction matrix with probabilities.\n",
    "        :return target: Target vector.\n",
    "        \"\"\"\n",
    "        test_nodes = self.clustering_machine.sg_test_nodes_global[cluster].to(self.device)\n",
    "        target = self.clustering_machine.label.to(self.device)\n",
    "        prediction = self.model(self.edges, self.features, self.edge_weights)\n",
    "        \n",
    "        return prediction[test_nodes], target[test_nodes]\n",
    "\n",
    "    # iterate through epoch and also the clusters\n",
    "    def train(self, epoch_num=10, learning_rate=0.01, weight_decay = 0.01):\n",
    "        \"\"\"\n",
    "        Training a model.\n",
    "        \"\"\"\n",
    "        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        self.model.train()   # set self.training = True : will be used in the dropout\n",
    "        self.record_ave_training_loss = []\n",
    "        self.time_train_load_data = 0\n",
    "        \n",
    "        t0 = time.time()\n",
    "        # first transfer the whole graph data to the GPU device\n",
    "        \n",
    "        t1 = time.time()\n",
    "        self.edges = self.clustering_machine.edge_index_global_self_loops.to(self.device)\n",
    "        self.features = self.clustering_machine.features.to(self.device)\n",
    "        self.edge_weights = self.clustering_machine.edge_weight_global.to(self.device)\n",
    "        self.label = self.clustering_machine.label.to(self.device)\n",
    "        self.time_train_load_data += (time.time() - t1) * 1000\n",
    "        \n",
    "        for epoch in range(epoch_num):\n",
    "            random.shuffle(self.clustering_machine.clusters)\n",
    "            self.node_count_seen = 0\n",
    "            self.accumulated_training_loss = 0\n",
    "            for cluster in self.clustering_machine.clusters:\n",
    "                self.optimizer.zero_grad()\n",
    "                batch_ave_loss, node_count = self.do_forward_pass(cluster)\n",
    "                batch_ave_loss.backward()\n",
    "                self.optimizer.step()\n",
    "                ave_loss = self.update_average_loss(batch_ave_loss, node_count)\n",
    "            \n",
    "            self.record_ave_training_loss.append(ave_loss)\n",
    "        # convert to ms\n",
    "        self.time_train_total = ((time.time() - t0) * 1000)\n",
    "        \n",
    "#         epochs.set_description(\"Ave Train Loss per node: %g \" % round(ave_loss,6))\n",
    "#         print(\"Train ave loss of overlapping clusters per node : %g\" % round(ave_loss,6))\n",
    "\n",
    "    def test(self):\n",
    "        \"\"\"\n",
    "        Scoring the test and printing the F-1 score.\n",
    "        \"\"\"\n",
    "        self.model.eval()   # set self.training = false\n",
    "        self.predictions = []\n",
    "        self.targets = []\n",
    "        for cluster in self.clustering_machine.clusters:\n",
    "            prediction, target = self.do_prediction(cluster)\n",
    "\n",
    "            self.predictions.append(prediction.cpu().detach().numpy())\n",
    "            self.targets.append(target.cpu().detach().numpy())\n",
    "        \n",
    "        # concatenate all the ndarrays inside this list\n",
    "        self.targets = np.concatenate(self.targets)\n",
    "        # along axis:    axis == 1\n",
    "        self.predictions = np.concatenate(self.predictions).argmax(1)  # return the indices of maximum probability \n",
    "#         print('shape of the targets and predictions are: ', self.targets.shape, self.predictions.shape)\n",
    "        \n",
    "        f1_score = f1_score(self.targets, self.predictions, average=\"micro\")\n",
    "        accuracy = accuracy_score(self.targets, self.predictions)\n",
    "#         print(\"\\nTest F-1 score: {:.4f}\".format(score))\n",
    "        return (f1_score, accuracy)\n",
    "    \n",
    "    def do_validation_prediction(self, cluster):\n",
    "        \"\"\"\n",
    "        Scoring a cluster.\n",
    "        :param cluster: Cluster index.\n",
    "        :return prediction: Prediction matrix with probabilities.\n",
    "        :return target: Target vector.\n",
    "        \"\"\"\n",
    "        validation_nodes = self.clustering_machine.sg_validation_nodes_global[cluster].to(self.device)\n",
    "        target = self.clustering_machine.label.to(self.device)\n",
    "        \n",
    "        prediction = self.model(self.edges, self.features, self.edge_weights)\n",
    "        \n",
    "        return prediction[validation_nodes], target[validation_nodes]\n",
    "\n",
    "    def validate(self):\n",
    "        \"\"\"\n",
    "        Scoring the test and printing the F-1 score.\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        self.predictions = []\n",
    "        self.targets = []\n",
    "        for cluster in self.clustering_machine.clusters:\n",
    "            prediction, target = self.do_validation_prediction(cluster)\n",
    "\n",
    "            self.predictions.append(prediction.cpu().detach().numpy())\n",
    "            self.targets.append(target.cpu().detach().numpy())\n",
    "        \n",
    "        # concatenate all the ndarrays inside this list\n",
    "        self.targets = np.concatenate(self.targets)\n",
    "        # along axis:    axis == 1\n",
    "        self.predictions = np.concatenate(self.predictions).argmax(1)  # return the indices of maximum probability \n",
    "#         print('shape of the targets and predictions are: ', self.targets.shape, self.predictions.shape)\n",
    "        \n",
    "        f1 = f1_score(self.targets, self.predictions, average=\"micro\")\n",
    "        accuracy = accuracy_score(self.targets, self.predictions)\n",
    "#         print(\"\\nTest F-1 score: {:.4f}\".format(score))\n",
    "        return (f1, accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the mini clustering basic info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_clustering(clustering_machine, miniBatch = True):\n",
    "    whole_graph = clustering_machine.graph\n",
    "\n",
    "    isolate_clusters_global = [ clustering_machine.sg_nodes_global[cluster]\n",
    "                             for cluster in clustering_machine.clusters]\n",
    "    \n",
    "    modeling_clusters_global = [ clustering_machine.sg_model_nodes_global[cluster]\n",
    "                             for cluster in clustering_machine.clusters]\n",
    "\n",
    "    validation_clusters_global = [ clustering_machine.sg_validation_nodes_global[cluster]\n",
    "                             for cluster in clustering_machine.clusters]\n",
    "\n",
    "    training_clusters_global = clustering_machine.sg_train_nodes_global\n",
    "\n",
    "    testing_clusters_global =  clustering_machine.sg_test_nodes_global\n",
    "\n",
    "    sg_edges_clusters_global = [  clustering_machine.sg_edges_global[cluster]\n",
    "                             for cluster in clustering_machine.clusters]\n",
    "\n",
    "    print('node cluster memeber ship: ', clustering_machine.cluster_membership)\n",
    "    print('isolated clusters are: ', isolate_clusters_global)\n",
    "    \n",
    "\n",
    "    print('training nodes global ids are: \\n', training_clusters_global)\n",
    "    \n",
    "    print('testing global clusters are: ', testing_clusters_global)\n",
    "    print('modeling global clusters are: ', modeling_clusters_global)\n",
    "    print('validation global clusters are: ', validation_clusters_global)\n",
    "\n",
    "    subgraphs = [clustering_machine.graph.subgraph(isolate_clusters_global[cluster]) \\\n",
    "                                               for cluster in clustering_machine.clusters]\n",
    "    plt.subplot(331)\n",
    "    nx.draw(whole_graph, with_labels=True, font_weight='bold')\n",
    "    # 2) the two halves of the graph\n",
    "    plt.subplot(332)\n",
    "    nx.draw(subgraphs[0], with_labels=True, font_weight='bold')\n",
    "    plt.subplot(333)\n",
    "    nx.draw(subgraphs[1], with_labels=True, font_weight='bold')\n",
    "    \n",
    "    print('Info about the mini_batch only with training nodes: ')\n",
    "    sg_mini_train_edges_clusters_global = [  clustering_machine.sg_mini_train_edges_global[cluster] for cluster in clustering_machine.clusters]\n",
    "    sg_mini_train_nodes_clusters_global = clustering_machine.sg_mini_train_nodes_global\n",
    "    print('mini train edges of each cluster, global ids: ', sg_mini_train_edges_clusters_global)\n",
    "    print('mini train overlapping nodes global ids: ', sg_mini_train_nodes_clusters_global)\n",
    "\n",
    "    mini_train_subgraphs = [clustering_machine.graph.subgraph(clustering_machine.train_accum_neighbor[cluster]) \\\n",
    "                                           for cluster in clustering_machine.clusters]\n",
    "    plt.subplot(334)\n",
    "    nx.draw(mini_train_subgraphs[0], with_labels=True, font_weight='bold')\n",
    "    plt.subplot(335)\n",
    "    nx.draw(mini_train_subgraphs[1], with_labels=True, font_weight='bold')\n",
    "    \n",
    "    if miniBatch:\n",
    "        print('Info about the mini_batch only with validation nodes: ')\n",
    "        sg_mini_valid_edges_clusters_global = [  clustering_machine.sg_mini_valid_edges_global[cluster] for cluster in clustering_machine.clusters]\n",
    "        sg_mini_valid_nodes_clusters_global = clustering_machine.sg_mini_valid_nodes_global\n",
    "        print('mini train edges of each cluster, global ids: ', sg_mini_valid_edges_clusters_global)\n",
    "        print('mini train overlapping nodes global ids: ', sg_mini_valid_nodes_clusters_global)\n",
    "\n",
    "        mini_valid_subgraphs = [clustering_machine.graph.subgraph(clustering_machine.valid_accum_neighbor[cluster]) \\\n",
    "                                               for cluster in clustering_machine.clusters]\n",
    "        plt.subplot(337)\n",
    "        nx.draw(mini_valid_subgraphs[0], with_labels=True, font_weight='bold')\n",
    "        plt.subplot(338)\n",
    "        nx.draw(mini_valid_subgraphs[1], with_labels=True, font_weight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Trivial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 2.],\n",
      "        [0., 3.],\n",
      "        [0., 4.],\n",
      "        [0., 5.],\n",
      "        [0., 6.],\n",
      "        [0., 7.],\n",
      "        [0., 8.],\n",
      "        [0., 9.]]) torch.Size([10, 2])\n"
     ]
    }
   ],
   "source": [
    "'''Trivial data'''\n",
    "edge_index = torch.tensor([[0, 1, 1, 3, 1, 2, 4, 2, 4, 6, 6, 7, 7, 9, 2, 5, 9, 8], \n",
    "                           [1, 0, 3, 1, 2, 1, 2, 4, 6, 4, 7, 6, 9, 7, 5, 2, 8, 9]])\n",
    "# features = torch.rand(10, 3)\n",
    "features = torch.tensor([[0, 0], [0, 1], [0, 2], [0, 3], [0, 4],  \n",
    "                           [0, 5], [0, 6], [0, 7], [0, 8], [0, 9]], dtype = torch.float)\n",
    "# label = torch.tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "\n",
    "label = torch.tensor([0, 1, 1, 0, 1, 1, 1, 0, 0, 0])\n",
    "print(features, features.shape)\n",
    "\n",
    "check_clustering_machine = ClusteringMachine(edge_index, features, label, partition_num = 2)\n",
    "check_clustering_machine.decompose(0.2, 0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mini batch train nodes and valid throughout whole graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=orange>\n",
    "Note: the all_overlap and train_overlap are the same effects in the train process\n",
    "    \n",
    "These two differ in the validation part. Train_overlap will lose some overalpping in the validation nodes which affect F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node cluster memeber ship:  {0: 0, 1: 0, 2: 0, 3: 0, 4: 1, 5: 1, 6: 1, 7: 1, 8: 0, 9: 1}\n",
      "isolated clusters are:  [[0, 1, 2, 3, 8], [4, 5, 6, 7, 9]]\n",
      "training nodes global ids are: \n",
      " {0: tensor([2, 3]), 1: tensor([7, 9])}\n",
      "testing global clusters are:  {0: tensor([8]), 1: tensor([5])}\n",
      "modeling global clusters are:  [[2, 3, 8], [5, 7, 9]]\n",
      "validation global clusters are:  [tensor([0, 1]), tensor([4, 6])]\n",
      "Info about the mini_batch only with training nodes: \n",
      "mini train edges of each cluster, global ids:  [{(1, 2), (2, 5), (1, 3), (2, 4)}, {(8, 9), (6, 7), (9, 7)}]\n",
      "mini train overlapping nodes global ids:  {0: [1, 2, 3, 4, 5], 1: [6, 7, 8, 9]}\n",
      "Info about the mini_batch only with validation nodes: \n",
      "mini train edges of each cluster, global ids:  [{(0, 1), (1, 3), (1, 2)}, {(4, 6), (6, 7), (2, 4)}]\n",
      "mini train overlapping nodes global ids:  {0: [0, 1, 2, 3], 1: [2, 4, 6, 7]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiangli/anaconda3/envs/pytorch_geometric/lib/python3.7/site-packages/networkx/drawing/nx_pylab.py:579: MatplotlibDeprecationWarning: \n",
      "The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead.\n",
      "  if not cb.iterable(width):\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 7 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# mini-batch of the all_overlap\n",
    "clustering_machine = copy.deepcopy(check_clustering_machine)\n",
    "clustering_machine.mini_batch_train_clustering(1) # include number of layers\n",
    "check_clustering(clustering_machine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.25, 0.25)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcn_trainer_batch = ClusterGCNTrainer_mini_Train(clustering_machine, 2, 2, input_layers = [16], dropout=0.3)\n",
    "gcn_trainer_batch.train(1, 0.0001, 0.1)\n",
    "gcn_trainer_batch.validate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### minibatch train nodes and batch validatioin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.75, 0.75)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustering_machine = copy.deepcopy(check_clustering_machine)\n",
    "clustering_machine.mini_batch_train_clustering(1) # include number of layers\n",
    "gcn_trainer_batch = ClusterGCNTrainer_mini_Train(clustering_machine, 2, 2, input_layers = [16], dropout=0.3)\n",
    "gcn_trainer_batch.train(1, 0.0001, 0.1)\n",
    "gcn_trainer_batch.batch_validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Default whole graph (recombine train nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.75, 0.75)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# default brute force case: recombination whole graph\n",
    "clustering_machine = copy.deepcopy(check_clustering_machine)\n",
    "clustering_machine.mini_batch_train_clustering(0)      \n",
    "gcn_trainer_whole = wholeClusterGCNTrainer_sequence(clustering_machine, 2, 2, input_layers = [16], dropout=0.3)\n",
    "gcn_trainer_whole.train(1, 0.0001, 0.1)\n",
    "gcn_trainer_whole.validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### mini-batch train nodes only in the isolated cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node cluster memeber ship:  {0: 0, 1: 0, 2: 0, 3: 0, 4: 1, 5: 1, 6: 1, 7: 1, 8: 0, 9: 1}\n",
      "isolated clusters are:  [[0, 1, 2, 3, 8], [4, 5, 6, 7, 9]]\n",
      "training nodes global ids are: \n",
      " {0: tensor([2, 3]), 1: tensor([7, 9])}\n",
      "testing global clusters are:  {0: tensor([8]), 1: tensor([5])}\n",
      "modeling global clusters are:  [[2, 3, 8], [5, 7, 9]]\n",
      "validation global clusters are:  [tensor([0, 1]), tensor([4, 6])]\n",
      "Info about the mini_batch only with training nodes: \n",
      "mini train edges of each cluster, global ids:  [{(0, 1), (1, 3), (1, 2)}, {(6, 7), (4, 6), (9, 7)}]\n",
      "mini train overlapping nodes global ids:  {0: [0, 1, 2, 3], 1: [4, 6, 7, 9]}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# mini-batch of the isolate\n",
    "clustering_machine = copy.deepcopy(check_clustering_machine)\n",
    "clustering_machine.general_isolate_clustering(2) \n",
    "check_clustering(clustering_machine, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.25, 0.25)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check_clustering(clustering_machine, True)\n",
    "gcn_trainer_isolate = ClusterGCNTrainer_mini_Train(clustering_machine, 2, 2, input_layers = [16])\n",
    "gcn_trainer_isolate.train(1,  0.0001, 0.1)\n",
    "gcn_trainer_isolate.validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use library data to check the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_clustering_machine(data, partition_num = 10, test_ratio = 0.05, validation_ratio = 0.85):\n",
    "    connect_edge_index, connect_features, connect_label = filter_out_isolate(data.edge_index, data.x, data.y)\n",
    "    clustering_machine = ClusteringMachine(connect_edge_index, connect_features, connect_label, partition_num = partition_num)\n",
    "    clustering_machine.decompose(test_ratio, validation_ratio)\n",
    "    return clustering_machine\n",
    "\n",
    "''' Draw the information about the GCN calculating batch size '''\n",
    "def draw_cluster_info(clustering_machine, data_name, img_path, comments = '_cluster_node_distr'):\n",
    "    cluster_id = clustering_machine.clusters    # a list of cluster indices\n",
    "    cluster_datapoints = {'cluster_id': cluster_id,  \\\n",
    "                          'train_batch' : [clustering_machine.info_train_batch_size[idx] for idx in cluster_id], \\\n",
    "                          'cluster_size' : [clustering_machine.info_isolate_cluster_size[idx] for idx in cluster_id], \\\n",
    "                         }\n",
    "                         \n",
    "    df = pd.DataFrame(data=cluster_datapoints, dtype=np.int32)\n",
    "    # print(df)\n",
    "    df_reshape = df.melt('cluster_id', var_name = 'clusters', value_name = 'node_num')\n",
    "    \n",
    "    plt.clf()\n",
    "    plt.figure()\n",
    "    sns.set(style='whitegrid')\n",
    "    g = sns.catplot(x=\"cluster_id\", y=\"node_num\", hue='clusters', kind='bar', data=df_reshape)\n",
    "    g.despine(left=True)\n",
    "    g.fig.suptitle(data_name + comments)\n",
    "    g.set_xlabels(\"Cluster ID\")\n",
    "    g.set_ylabels(\"Number of nodes\")\n",
    "    \n",
    "    img_name = img_path + data_name + comments\n",
    "    os.makedirs(os.path.dirname(img_name), exist_ok=True)\n",
    "    g.savefig(img_name, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formal Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def No_partition_run(local_clustering_machine, data_name, dataset, image_path, input_layer = [16, 16], epochs=300, \\\n",
    "                     dropout = 0.3, lr = 0.01, weight_decay = 0.01):\n",
    "    \"\"\"\n",
    "    # the partition num: will determine the training, testing and validation data\n",
    "    return: test F-1 value, validation F-1 value\n",
    "    \"\"\"\n",
    "    clustering_machine = copy.deepcopy(local_clustering_machine)\n",
    "    # the accumulating neighbor nodes only contain train nodes, no hop neighbors\n",
    "    clustering_machine.mini_batch_train_clustering(0)\n",
    "    # 0) train the data as a whole with no parition\n",
    "    gcn_trainer = wholeClusterGCNTrainer_sequence(clustering_machine, dataset.num_node_features, dataset.num_classes, input_layers = input_layer, dropout = dropout)\n",
    "    gcn_trainer.train(epoch_num=epochs, learning_rate=lr, weight_decay=weight_decay)\n",
    "    \n",
    "#     test_F1, test_accuracy = gcn_trainer.test()\n",
    "    validation_F1, validation_accuracy = gcn_trainer.validate()\n",
    "    time_train_total = gcn_trainer.time_train_total\n",
    "    time_data_load = gcn_trainer.time_train_load_data\n",
    "    return validation_accuracy, validation_F1, time_train_total, time_data_load, gcn_trainer\n",
    "\n",
    "\n",
    "def Cluster_train_batch_run(local_clustering_machine, data_name, dataset, image_path, input_layer = [16, 16], epochs=300, neigh_layer = 1, \\\n",
    "                           dropout = 0.3, lr = 0.01, weight_decay = 0.01, mini_epoch_num = 5):\n",
    "    \"\"\"\n",
    "    # the partition num: will determine the training, testing and validation data\n",
    "    Tuning parameters:  dropout, lr (learning rate), weight_decay: l2 regularization\n",
    "    return: validation accuracy value, validation F-1 value, time_training (ms), time_data_load (ms)\n",
    "    \"\"\"\n",
    "    clustering_machine = copy.deepcopy(local_clustering_machine)\n",
    "    # defalt to contain 1 layer of neighbors of train nodes\n",
    "    clustering_machine.mini_batch_train_clustering(neigh_layer)\n",
    "    \n",
    "    gcn_trainer = ClusterGCNTrainer_mini_Train(clustering_machine, dataset.num_node_features, dataset.num_classes, input_layers = input_layer, dropout = dropout)\n",
    "    gcn_trainer.train(epoch_num=epochs, learning_rate=lr, weight_decay=weight_decay, mini_epoch_num = mini_epoch_num)\n",
    "    \n",
    "#     test_F1, test_accuracy = gcn_trainer.test()\n",
    "    validation_F1, validation_accuracy = gcn_trainer.validate()\n",
    "    time_train_total = gcn_trainer.time_train_total\n",
    "    time_data_load = gcn_trainer.time_train_load_data\n",
    "    return validation_accuracy, validation_F1, time_train_total, time_data_load, gcn_trainer\n",
    "\n",
    "\n",
    "def Isolate_clustering_run(local_clustering_machine, data_name, dataset, image_path, input_layer = [16, 16], epochs=300, neigh_layer = 1, \\\n",
    "                           dropout = 0.3, lr = 0.01, weight_decay = 0.01):\n",
    "    \"\"\"\n",
    "    # the partition num: will determine the training, testing and validation data\n",
    "    return: test F-1 value, validation F-1 value\n",
    "    \"\"\"\n",
    "    clustering_machine = copy.deepcopy(local_clustering_machine)\n",
    "    # defalt to contain 1 layer of neighbors of train nodes\n",
    "    clustering_machine.general_isolate_clustering(neigh_layer)\n",
    "    gcn_trainer = ClusterGCNTrainer_mini_Train(clustering_machine, dataset.num_node_features, dataset.num_classes, input_layers = input_layer, dropout = dropout)\n",
    "    gcn_trainer.train(epoch_num=epochs, learning_rate=lr, weight_decay=weight_decay)\n",
    "    \n",
    "#     test_F1, test_accuracy = gcn_trainer.test()\n",
    "    validation_F1, validation_accuracy = gcn_trainer.validate()\n",
    "    time_train_total = gcn_trainer.time_train_total\n",
    "    time_data_load = gcn_trainer.time_train_load_data\n",
    "    return validation_accuracy, validation_F1, time_train_total, time_data_load, gcn_trainer\n",
    "\n",
    "def Cluster_train_valid_batch_run(local_clustering_machine, data_name, dataset, image_path, input_layer = [16, 16], epochs=300, neigh_layer = 1, \\\n",
    "                           dropout = 0.3, lr = 0.01, weight_decay = 0.01, mini_epoch_num = 5):\n",
    "    \"\"\"\n",
    "    # the partition num: will determine the training, testing and validation data\n",
    "    Tuning parameters:  dropout, lr (learning rate), weight_decay: l2 regularization\n",
    "    return: validation accuracy value, validation F-1 value, time_training (ms), time_data_load (ms)\n",
    "    \"\"\"\n",
    "    clustering_machine = copy.deepcopy(local_clustering_machine)\n",
    "    # defalt to contain 1 layer of neighbors of train nodes\n",
    "    clustering_machine.mini_batch_train_clustering(neigh_layer)\n",
    "    \n",
    "    gcn_trainer = ClusterGCNTrainer_mini_Train(clustering_machine, dataset.num_node_features, dataset.num_classes, input_layers = input_layer, dropout = dropout)\n",
    "    gcn_trainer.train(epoch_num=epochs, learning_rate=lr, weight_decay=weight_decay, mini_epoch_num = mini_epoch_num)\n",
    "    \n",
    "#     test_F1, test_accuracy = gcn_trainer.test()\n",
    "    validation_F1, validation_accuracy = gcn_trainer.batch_validate()\n",
    "    time_train_total = gcn_trainer.time_train_total\n",
    "    time_data_load = gcn_trainer.time_train_load_data\n",
    "    return validation_accuracy, validation_F1, time_train_total, time_data_load, gcn_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_train_loss_converge(clustering_machine, data_name, dataset, image_path,  comments, input_layer = [32, 16], epoch_num = 300, layer_num = 1, dropout = 0.3, lr = 0.0001, weight_decay = 0.01, mini_epoch_num = 5):\n",
    "    a3, v3, time3, load3, Cluster_train_valid_batch_trainer = Cluster_train_valid_batch_run(clustering_machine, data_name, dataset, image_path, input_layer = input_layer, epochs=epoch_num, neigh_layer = layer_num, \\\n",
    "                                                                               dropout = dropout, lr = lr, weight_decay = weight_decay, mini_epoch_num = mini_epoch_num)\n",
    "    draw_Cluster_train_valid_batch = draw_trainer_info(data_name, Cluster_train_valid_batch_trainer, image_path, 'train_valid_batch_' + comments)\n",
    "    draw_Cluster_train_valid_batch.draw_ave_loss_per_node()\n",
    "    \n",
    "    a0, v0, time0, load0, Cluster_train_batch_trainer = Cluster_train_batch_run(clustering_machine, data_name, dataset, image_path, input_layer = input_layer, epochs=epoch_num, neigh_layer = layer_num, \\\n",
    "                                                                               dropout = dropout, lr = lr, weight_decay = weight_decay, mini_epoch_num = mini_epoch_num)\n",
    "    draw_Cluster_train_batch = draw_trainer_info(data_name, Cluster_train_batch_trainer, image_path, 'train_batch_' + comments)\n",
    "    draw_Cluster_train_batch.draw_ave_loss_per_node()\n",
    "    \n",
    "    a1, v1, time1, load1, Isolate_clustering_trainer = Isolate_clustering_run(clustering_machine, data_name, dataset, image_path, input_layer = input_layer, epochs=epoch_num, neigh_layer = layer_num, \\\n",
    "                                                                             dropout = dropout, lr = lr, weight_decay = weight_decay)\n",
    "    draw_Isolate_clustering = draw_trainer_info(data_name, Isolate_clustering_trainer, image_path, 'Isolate_' + comments)\n",
    "    draw_Isolate_clustering.draw_ave_loss_per_node()\n",
    "    \n",
    "    # whole graph version, should not work for the large scale graph\n",
    "    a2, v2, time2, load2, No_partition_trainer = No_partition_run(clustering_machine, data_name, dataset, image_path, input_layer = input_layer, epochs=epoch_num, \\\n",
    "                                                                 dropout = dropout, lr = lr, weight_decay = weight_decay)\n",
    "    draw_No_partition = draw_trainer_info(data_name, No_partition_trainer, image_path, 'whole_' + comments)\n",
    "    draw_No_partition.draw_ave_loss_per_node()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Execute the testing program '''\n",
    "def execute_one(clustering_machine, image_path, repeate_time = 5, input_layer = [32, 16], epoch_num = 300, layer_num = 1, \\\n",
    "                dropout = 0.3, lr = 0.0001, weight_decay = 0.01, mini_epoch_num = 5):\n",
    "    \"\"\"\n",
    "        return all test-F1 and validation-F1 for all four models\n",
    "    \"\"\"\n",
    "#     test_f1 = {}\n",
    "    validation_accuracy = {}\n",
    "    validation_f1 = {}\n",
    "    time_total_train = {}\n",
    "    time_data_load = {}\n",
    "    \n",
    "    # Each graph model corresponds to one function below\n",
    "    graph_model = ['train_batch', 'isolate', 'whole_graph', 'batch_valid']\n",
    "    for i in range(repeate_time):\n",
    "        model_res = []\n",
    "        model_res.append(Cluster_train_batch_run(clustering_machine, data_name, dataset, image_path, input_layer = input_layer, epochs=epoch_num, neigh_layer = layer_num, \\\n",
    "                                                         dropout = dropout, lr = lr, weight_decay = weight_decay, mini_epoch_num = mini_epoch_num)[:4] )\n",
    "        model_res.append(Isolate_clustering_run(clustering_machine, data_name, dataset, image_path, input_layer = input_layer, epochs=epoch_num, neigh_layer = layer_num, \\\n",
    "                                                        dropout = dropout, lr = lr, weight_decay = weight_decay)[:4])\n",
    "        model_res.append(No_partition_run(clustering_machine, data_name, dataset, image_path, input_layer = input_layer, epochs=epoch_num, \n",
    "                                                  dropout = dropout, lr = lr, weight_decay = weight_decay)[:4])\n",
    "        \n",
    "        model_res.append(Cluster_train_valid_batch_run(clustering_machine, data_name, dataset, image_path, input_layer = input_layer, epochs=epoch_num, neigh_layer = layer_num, \\\n",
    "                                                         dropout = dropout, lr = lr, weight_decay = weight_decay, mini_epoch_num = mini_epoch_num)[:4])\n",
    "        \n",
    "        validation_accuracy[i], validation_f1[i], time_total_train[i], time_data_load[i] = zip(*model_res)\n",
    "    return graph_model, validation_accuracy, validation_f1, time_total_train, time_data_load\n",
    "\n",
    "def store_data_multi_tests(f1_data, data_name, graph_model, img_path, comments):\n",
    "    run_id = sorted(f1_data.keys())\n",
    "    run_data = {'run_id': run_id}\n",
    "    \n",
    "    \n",
    "    run_data.update({model_name : [f1_data[key][idx] for key in run_id] for idx, model_name in enumerate(graph_model)})\n",
    "    \n",
    "#     run_data = {'run_id': run_id,  \\\n",
    "#                 'train_batch' : [f1_data[key][0] for key in run_id], \\\n",
    "#                 'isolate' : [f1_data[key][1] for key in run_id], \\\n",
    "#                 'whole_graph' : [f1_data[key][2] for key in run_id], \\\n",
    "#                 'batch_valid' : [f1_data[key][3] for key in run_id], \\\n",
    "#                }\n",
    "    \n",
    "    pickle_filename = img_path + data_name + '_' + comments + '.pkl'\n",
    "    os.makedirs(os.path.dirname(pickle_filename), exist_ok=True)\n",
    "    df = pd.DataFrame(data=run_data, dtype=np.int32)\n",
    "    df.to_pickle(pickle_filename)\n",
    "    return pickle_filename\n",
    "\n",
    "def draw_data_multi_tests(pickle_filename, data_name, comments, xlabel, ylabel):\n",
    "    df = pd.read_pickle(pickle_filename)\n",
    "    df_reshape = df.melt('run_id', var_name = 'model', value_name = ylabel)\n",
    "\n",
    "    plt.clf()\n",
    "    plt.figure()\n",
    "    sns.set(style='whitegrid')\n",
    "    g = sns.catplot(x=\"model\", y=ylabel, kind='box', data=df_reshape)\n",
    "    g.despine(left=True)\n",
    "    g.fig.suptitle(data_name + ' ' + ylabel + ' ' + comments)\n",
    "    g.set_xlabels(xlabel)\n",
    "    g.set_ylabels(ylabel)\n",
    "\n",
    "    img_name = pickle_filename[:-4] + '_img'\n",
    "    os.makedirs(os.path.dirname(img_name), exist_ok=True)\n",
    "    plt.savefig(img_name, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_tuning(tune_params, clustering_machine, image_path, repeate_time = 7, input_layer = [32, 32], epoch_num = 400, layer_num = 1, \\\n",
    "                  dropout = 0.1, lr = 0.0001, weight_decay = 0.1):\n",
    "    \"\"\"\n",
    "        Tune all the hyperparameters\n",
    "        1) learning rate\n",
    "        2) dropout\n",
    "        3) layer unit number\n",
    "        4) weight decay\n",
    "    \"\"\"\n",
    "    validation_accuracy = {}\n",
    "    validation_f1 = {}\n",
    "    time_total_train = {}\n",
    "    time_data_load = {}\n",
    "    \n",
    "    res = [{tune_val : Cluster_train_valid_batch_run(clustering_machine, data_name, dataset, image_path, \\\n",
    "            input_layer = input_layer, epochs=epoch_num, neigh_layer = layer_num, \\\n",
    "            dropout = dropout, lr = lr, weight_decay = weight_decay, mini_epoch_num = tune_val)[:4] for tune_val in tune_params} for i in range(repeate_time)]\n",
    "    \n",
    "    for i, ref in enumerate(res):\n",
    "        validation_accuracy[i] = {tune_val : res_lst[0] for tune_val, res_lst in ref.items()}\n",
    "        validation_f1[i] = {tune_val : res_lst[1] for tune_val, res_lst in ref.items()}\n",
    "        time_total_train[i] = {tune_val : res_lst[2] for tune_val, res_lst in ref.items()}\n",
    "        time_data_load[i] = {tune_val : res_lst[3] for tune_val, res_lst in ref.items()}\n",
    "        \n",
    "    return validation_accuracy, validation_f1, time_total_train, time_data_load\n",
    "\n",
    "def store_data_multi_tuning(tune_params, target, data_name, img_path, comments):\n",
    "    \"\"\"\n",
    "        tune_params: is the tuning parameter list\n",
    "        target: is the result, here should be F1-score, accuraycy, load time, train time\n",
    "    \"\"\"\n",
    "    run_ids = sorted(target.keys())   # key is the run_id\n",
    "    run_data = {'run_id': run_ids}\n",
    "    # the key can be converted to string or not: i.e. str(tune_val)\n",
    "    # here we keep it as integer such that we want it to follow order\n",
    "    tmp = {tune_val : [target[run_id][tune_val] for run_id in run_ids] for tune_val in tune_params}  # the value is list\n",
    "    run_data.update(tmp)\n",
    "    \n",
    "    pickle_filename = img_path + data_name + '_' + comments + '.pkl'\n",
    "    os.makedirs(os.path.dirname(pickle_filename), exist_ok=True)\n",
    "    df = pd.DataFrame(data=run_data, dtype=np.int32)\n",
    "    df.to_pickle(pickle_filename)\n",
    "    return pickle_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use data from pytorch geometric datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_data_root = '/media/xiangli/storage1/projects/tmpdata/'\n",
    "test_folder_name = 'trivial_batch_valid/train_10%_full_neigh_metis/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cora dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "data_name = 'Cora'\n",
    "dataset = Planetoid(root = local_data_root + 'Planetoid/Cora', name=data_name)\n",
    "data = dataset[0]\n",
    "image_data_path = './results/' + data_name + '/' + test_folder_name\n",
    "\n",
    "partition_nums = [4]\n",
    "layers = [[32]]\n",
    "\n",
    "# partition_nums = [2, 4, 8]\n",
    "# layers = [[], [32], [32, 32], [32, 32, 32]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start checking train loss for partition num: 4 hop layer: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 464.35x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check convergence\n",
    "\n",
    "for partn in partition_nums:\n",
    "    for GCN_layer in layers:\n",
    "        net_layer = len(GCN_layer) + 1\n",
    "        hop_layer = net_layer\n",
    "        clustering_machine = set_clustering_machine(data, partition_num = partn, test_ratio = 0.05, validation_ratio = 0.85)\n",
    "        print('Start checking train loss for partition num: ' + str(partn) + ' hop layer: ' + str(hop_layer))\n",
    "        img_path = image_data_path + 'cluster_num_' + str(partn) + '/' + 'net_layer_' + str(net_layer) + '_hop_layer_' + str(hop_layer) + '/'\n",
    "        check_train_loss_converge(clustering_machine, data_name, dataset, img_path, 'part_num_' + str(partn), input_layer = GCN_layer, epoch_num = 400, layer_num = hop_layer, \\\n",
    "                                 dropout = 0.1, lr = 0.0001, weight_decay = 0.1, mini_epoch_num = 1)\n",
    "        clustering_machine.mini_batch_train_clustering(hop_layer)\n",
    "        draw_cluster_info(clustering_machine, data_name, img_path, comments = '_cluster_node_distr_' + str(hop_layer) + '_hops')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output accuracy, F1, time (train, load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start running for partition num: 4 hop layer 2\n"
     ]
    }
   ],
   "source": [
    "for partn in partition_nums:\n",
    "    for GCN_layer in layers:\n",
    "        net_layer = len(GCN_layer) + 1\n",
    "        hop_layer = net_layer\n",
    "        clustering_machine = set_clustering_machine(data, partition_num = partn, test_ratio = 0.05, validation_ratio = 0.85)\n",
    "        print('Start running for partition num: ' + str(partn) + ' hop layer ' + str(hop_layer))\n",
    "        img_path = image_data_path + 'cluster_num_' + str(partn) + '/' + 'net_layer_' + str(net_layer) + '_hop_layer_' + str(hop_layer) + '/'\n",
    "\n",
    "        graph_model, validation_accuracy, validation_f1, time_total_train, time_data_load = execute_one(clustering_machine, img_path, repeate_time = 7, input_layer = GCN_layer, epoch_num = 400, layer_num = hop_layer, \\\n",
    "                                                                                          dropout = 0.1, lr = 0.0001, weight_decay = 0.1, mini_epoch_num = 20)\n",
    "        \n",
    "        validation_accuracy = store_data_multi_tests(validation_accuracy, data_name, graph_model, img_path, 'test_cluster_num_' + str(partn) + '_hops_' + str(hop_layer))\n",
    "        draw_data_multi_tests(validation_accuracy, data_name, 'vali_cluster_num_' + str(partn) + '_hop_' + str(hop_layer), 'models', 'Accuracy')\n",
    "        \n",
    "        validation_f1 = store_data_multi_tests(validation_f1, data_name, graph_model, img_path, 'validation_cluster_num_' + str(partn) + '_hops_' + str(hop_layer))\n",
    "        draw_data_multi_tests(validation_f1, data_name, 'vali_cluster_num_' + str(partn) + '_hop_' + str(hop_layer), 'models', 'F1 score')\n",
    "        \n",
    "        time_train = store_data_multi_tests(time_total_train, data_name, graph_model, img_path, 'train_time_cluster_num_' + str(partn) + '_hops_' + str(hop_layer))\n",
    "        draw_data_multi_tests(time_train, data_name, 'train_time_cluster_num_' + str(partn) + '_hop_' + str(hop_layer), 'models', 'Train Time (ms)')\n",
    "        \n",
    "        time_load = store_data_multi_tests(time_data_load, data_name, graph_model, img_path, 'load_time_cluster_num_' + str(partn) + '_hops_' + str(hop_layer))\n",
    "        draw_data_multi_tests(time_load, data_name, 'load_time_cluster_num_' + str(partn) + '_hop_' + str(hop_layer), 'models', 'Load Time (ms)')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tuning epoch number for each train-batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start tuning for tuning param: batch_epoch_num partition num: 4 hop layer 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tune target parameters\n",
    "# partition_nums = [4]\n",
    "# layers = [[32, 32]]\n",
    "\n",
    "for partn in partition_nums:\n",
    "    for GCN_layer in layers:\n",
    "        net_layer = len(GCN_layer) + 1\n",
    "        hop_layer = net_layer\n",
    "        clustering_machine = set_clustering_machine(data, partition_num = partn, test_ratio = 0.05, validation_ratio = 0.85)\n",
    "        \n",
    "        # Set the tune parameters and name\n",
    "        tune_name = 'batch_epoch_num'\n",
    "        tune_params = [400, 200, 100, 50, 20, 10, 5, 1]\n",
    "        \n",
    "        img_path = image_data_path + 'cluster_num_' + str(partn) + '/' + 'net_layer_' + str(net_layer) + '_hop_layer_' + str(hop_layer) + '/' + 'tune_' + tune_name + '/'\n",
    "        print('Start tuning for tuning param: ' + tune_name + ' partition num: ' + str(partn) + ' hop layer ' + str(hop_layer))\n",
    "        \n",
    "        \n",
    "        validation_accuracy, validation_f1, time_total_train, time_data_load = execute_tuning(tune_params, clustering_machine, img_path, repeate_time = 7, \\\n",
    "                                                                                              input_layer = GCN_layer, epoch_num = 400, layer_num = hop_layer, \\\n",
    "                                                                                              dropout = 0.1, lr = 0.0001, weight_decay = 0.1)\n",
    "        \n",
    "        validation_accuracy = store_data_multi_tuning(tune_params,validation_accuracy, data_name, img_path, 'accuracy_cluster_num_' + str(partn) + '_hops_' + str(hop_layer))\n",
    "        draw_data_multi_tests(validation_accuracy, data_name, 'vali_cluster_num_' + str(partn) + '_hop_' + str(hop_layer), 'epochs_per_batch', 'Accuracy')\n",
    "        \n",
    "        validation_f1 = store_data_multi_tuning(tune_params, validation_f1, data_name, img_path, 'validation_cluster_num_' + str(partn) + '_hops_' + str(hop_layer))\n",
    "        draw_data_multi_tests(validation_f1, data_name, 'vali_cluster_num_' + str(partn) + '_hop_' + str(hop_layer), 'epochs_per_batch', 'F1 score')\n",
    "        \n",
    "        time_train = store_data_multi_tuning(tune_params, time_total_train, data_name, img_path, 'train_time_cluster_num_' + str(partn) + '_hops_' + str(hop_layer))\n",
    "        draw_data_multi_tests(time_train, data_name, 'train_time_cluster_num_' + str(partn) + '_hop_' + str(hop_layer), 'epochs_per_batch', 'Train Time (ms)')\n",
    "        \n",
    "        time_load = store_data_multi_tuning(tune_params, time_data_load, data_name, img_path, 'load_time_cluster_num_' + str(partn) + '_hops_' + str(hop_layer))\n",
    "        draw_data_multi_tests(time_load, data_name, 'load_time_cluster_num_' + str(partn) + '_hop_' + str(hop_layer), 'epochs_per_batch', 'Load Time (ms)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CiteSeer Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "data_name = 'CiteSeer'\n",
    "dataset = Planetoid(root = local_data_root + 'Planetoid/CiteSeer', name=data_name)\n",
    "data = dataset[0]\n",
    "image_data_path = './results/' + data_name + '/' + test_folder_name\n",
    "\n",
    "partition_nums = [2, 4, 8]\n",
    "layers = [[], [16], [16, 16], [16, 16, 16]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning the epoch number per batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tune target parameters\n",
    "# partition_nums = [4]\n",
    "# layers = [[32, 32]]\n",
    "\n",
    "for partn in partition_nums:\n",
    "    for GCN_layer in layers:\n",
    "        net_layer = len(GCN_layer) + 1\n",
    "        hop_layer = net_layer\n",
    "        clustering_machine = set_clustering_machine(data, partition_num = partn, test_ratio = 0.05, validation_ratio = 0.85)\n",
    "        \n",
    "        # Set the tune parameters and name\n",
    "        tune_name = 'batch_epoch_num'\n",
    "        tune_params = [400, 200, 100, 50, 20, 10, 5, 1]\n",
    "        \n",
    "        img_path = image_data_path + 'cluster_num_' + str(partn) + '/' + 'net_layer_' + str(net_layer) + '_hop_layer_' + str(hop_layer) + '/' + 'tune_' + tune_name + '/'\n",
    "        print('Start tuning for tuning param: ' + tune_name + ' partition num: ' + str(partn) + ' hop layer ' + str(hop_layer))\n",
    "        \n",
    "        \n",
    "        validation_accuracy, validation_f1, time_total_train, time_data_load = execute_tuning(tune_params, clustering_machine, img_path, repeate_time = 7, \\\n",
    "                                                                                              input_layer = GCN_layer, epoch_num = 400, layer_num = hop_layer, \\\n",
    "                                                                                              dropout = 0.1, lr = 0.0001, weight_decay = 0.1)\n",
    "        \n",
    "        validation_accuracy = store_data_multi_tuning(tune_params,validation_accuracy, data_name, img_path, 'accuracy_cluster_num_' + str(partn) + '_hops_' + str(hop_layer))\n",
    "        draw_data_multi_tests(validation_accuracy, data_name, 'vali_cluster_num_' + str(partn) + '_hop_' + str(hop_layer), 'epochs_per_batch', 'Accuracy')\n",
    "        \n",
    "        validation_f1 = store_data_multi_tuning(tune_params, validation_f1, data_name, img_path, 'validation_cluster_num_' + str(partn) + '_hops_' + str(hop_layer))\n",
    "        draw_data_multi_tests(validation_f1, data_name, 'vali_cluster_num_' + str(partn) + '_hop_' + str(hop_layer), 'epochs_per_batch', 'F1 score')\n",
    "        \n",
    "        time_train = store_data_multi_tuning(tune_params, time_total_train, data_name, img_path, 'train_time_cluster_num_' + str(partn) + '_hops_' + str(hop_layer))\n",
    "        draw_data_multi_tests(time_train, data_name, 'train_time_cluster_num_' + str(partn) + '_hop_' + str(hop_layer), 'epochs_per_batch', 'Train Time (ms)')\n",
    "        \n",
    "        time_load = store_data_multi_tuning(tune_params, time_data_load, data_name, img_path, 'load_time_cluster_num_' + str(partn) + '_hops_' + str(hop_layer))\n",
    "        draw_data_multi_tests(time_load, data_name, 'load_time_cluster_num_' + str(partn) + '_hop_' + str(hop_layer), 'epochs_per_batch', 'Load Time (ms)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking train loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check convergence\n",
    "\n",
    "for partn in partition_nums:\n",
    "    for GCN_layer in layers:\n",
    "        net_layer = len(GCN_layer) + 1\n",
    "        hop_layer = net_layer\n",
    "        clustering_machine = set_clustering_machine(data, partition_num = partn, test_ratio = 0.05, validation_ratio = 0.85)\n",
    "        print('Start checking train loss for partition num: ' + str(partn) + ' hop layer: ' + str(hop_layer))\n",
    "        img_path = image_data_path + 'cluster_num_' + str(partn) + '/' + 'net_layer_' + str(net_layer) + '_hop_layer_' + str(hop_layer) + '/'\n",
    "        check_train_loss_converge(clustering_machine, data_name, dataset, img_path, 'part_num_' + str(partn), input_layer = GCN_layer, epoch_num = 400, layer_num = hop_layer, \\\n",
    "                                 dropout = 0.5, lr = 0.0001, weight_decay = 0.1, mini_epoch_num = 20)\n",
    "        clustering_machine.mini_batch_train_clustering(hop_layer)\n",
    "        draw_cluster_info(clustering_machine, data_name, img_path, comments = '_cluster_node_distr_' + str(hop_layer) + '_hops')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for partn in partition_nums:\n",
    "    for GCN_layer in layers:\n",
    "        net_layer = len(GCN_layer) + 1\n",
    "        hop_layer = net_layer\n",
    "        clustering_machine = set_clustering_machine(data, partition_num = partn, test_ratio = 0.05, validation_ratio = 0.85)\n",
    "        print('Start running for partition num: ' + str(partn) + ' hop layer ' + str(hop_layer))\n",
    "        img_path = image_data_path + 'cluster_num_' + str(partn) + '/' + 'net_layer_' + str(net_layer) + '_hop_layer_' + str(hop_layer) + '/'\n",
    "\n",
    "        validation_accuracy, validation_f1, time_total_train, time_data_load = execute_one(clustering_machine, img_path, repeate_time = 7, input_layer = GCN_layer, epoch_num = 400, layer_num = hop_layer, \\\n",
    "                                                                                          dropout = 0.5, lr = 0.0001, weight_decay = 0.1, mini_epoch_num = 20)\n",
    "        \n",
    "        validation_accuracy = store_data_multi_tests(validation_accuracy, data_name, img_path, 'test_cluster_num_' + str(partn) + '_hops_' + str(hop_layer))\n",
    "        draw_data_multi_tests(validation_accuracy, data_name, 'vali_cluster_num_' + str(partn) + '_hop_' + str(hop_layer), 'Accuracy')\n",
    "        validation_f1 = store_data_multi_tests(validation_f1, data_name, img_path, 'validation_cluster_num_' + str(partn) + '_hops_' + str(hop_layer))\n",
    "        draw_data_multi_tests(validation_f1, data_name, 'vali_cluster_num_' + str(partn) + '_hop_' + str(hop_layer), 'F1 score')\n",
    "        \n",
    "        time_train = store_data_multi_tests(time_total_train, data_name, img_path, 'train_time_cluster_num_' + str(partn) + '_hops_' + str(hop_layer))\n",
    "        draw_data_multi_tests(time_train, data_name, 'train_time_cluster_num_' + str(partn) + '_hop_' + str(hop_layer), 'Train Time (ms)')\n",
    "        time_load = store_data_multi_tests(time_data_load, data_name, img_path, 'load_time_cluster_num_' + str(partn) + '_hops_' + str(hop_layer))\n",
    "        draw_data_multi_tests(time_load, data_name, 'load_time_cluster_num_' + str(partn) + '_hop_' + str(hop_layer), 'Load Time (ms)')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PubMed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "data_name = 'PubMed'\n",
    "dataset = Planetoid(root = local_data_root + 'Planetoid/PubMed', name=data_name)\n",
    "data = dataset[0]\n",
    "image_data_path = './results/' + data_name + '/' + test_folder_name\n",
    "\n",
    "partition_nums = [2, 4, 8]\n",
    "layers = [[], [64], [64, 64], [64, 64, 64]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune epoch number per batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tune target parameters\n",
    "# partition_nums = [4]\n",
    "# layers = [[32, 32]]\n",
    "\n",
    "for partn in partition_nums:\n",
    "    for GCN_layer in layers:\n",
    "        net_layer = len(GCN_layer) + 1\n",
    "        hop_layer = net_layer\n",
    "        clustering_machine = set_clustering_machine(data, partition_num = partn, test_ratio = 0.05, validation_ratio = 0.85)\n",
    "        \n",
    "        # Set the tune parameters and name\n",
    "        tune_name = 'batch_epoch_num'\n",
    "        tune_params = [400, 200, 100, 50, 20, 10, 5, 1]\n",
    "        \n",
    "        img_path = image_data_path + 'cluster_num_' + str(partn) + '/' + 'net_layer_' + str(net_layer) + '_hop_layer_' + str(hop_layer) + '/' + 'tune_' + tune_name + '/'\n",
    "        print('Start tuning for tuning param: ' + tune_name + ' partition num: ' + str(partn) + ' hop layer ' + str(hop_layer))\n",
    "        \n",
    "        \n",
    "        validation_accuracy, validation_f1, time_total_train, time_data_load = execute_tuning(tune_params, clustering_machine, img_path, repeate_time = 7, \\\n",
    "                                                                                              input_layer = GCN_layer, epoch_num = 400, layer_num = hop_layer, \\\n",
    "                                                                                              dropout = 0.1, lr = 0.0001, weight_decay = 0.1)\n",
    "        \n",
    "        validation_accuracy = store_data_multi_tuning(tune_params,validation_accuracy, data_name, img_path, 'accuracy_cluster_num_' + str(partn) + '_hops_' + str(hop_layer))\n",
    "        draw_data_multi_tests(validation_accuracy, data_name, 'vali_cluster_num_' + str(partn) + '_hop_' + str(hop_layer), 'epochs_per_batch', 'Accuracy')\n",
    "        \n",
    "        validation_f1 = store_data_multi_tuning(tune_params, validation_f1, data_name, img_path, 'validation_cluster_num_' + str(partn) + '_hops_' + str(hop_layer))\n",
    "        draw_data_multi_tests(validation_f1, data_name, 'vali_cluster_num_' + str(partn) + '_hop_' + str(hop_layer), 'epochs_per_batch', 'F1 score')\n",
    "        \n",
    "        time_train = store_data_multi_tuning(tune_params, time_total_train, data_name, img_path, 'train_time_cluster_num_' + str(partn) + '_hops_' + str(hop_layer))\n",
    "        draw_data_multi_tests(time_train, data_name, 'train_time_cluster_num_' + str(partn) + '_hop_' + str(hop_layer), 'epochs_per_batch', 'Train Time (ms)')\n",
    "        \n",
    "        time_load = store_data_multi_tuning(tune_params, time_data_load, data_name, img_path, 'load_time_cluster_num_' + str(partn) + '_hops_' + str(hop_layer))\n",
    "        draw_data_multi_tests(time_load, data_name, 'load_time_cluster_num_' + str(partn) + '_hop_' + str(hop_layer), 'epochs_per_batch', 'Load Time (ms)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the train error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check convergence\n",
    "\n",
    "for partn in partition_nums:\n",
    "    for GCN_layer in layers:\n",
    "        net_layer = len(GCN_layer) + 1\n",
    "        hop_layer = net_layer\n",
    "        clustering_machine = set_clustering_machine(data, partition_num = partn, test_ratio = 0.05, validation_ratio = 0.85)\n",
    "        print('Start checking train loss for partition num: ' + str(partn) + ' hop layer: ' + str(hop_layer))\n",
    "        img_path = image_data_path + 'cluster_num_' + str(partn) + '/' + 'net_layer_' + str(net_layer) + '_hop_layer_' + str(hop_layer) + '/'\n",
    "        check_train_loss_converge(clustering_machine, data_name, dataset, img_path, 'part_num_' + str(partn), input_layer = GCN_layer, epoch_num = 400, layer_num = hop_layer, \\\n",
    "                                 dropout = 0.3, lr = 0.0001, weight_decay = 0.001, mini_epoch_num = 20)\n",
    "        clustering_machine.mini_batch_train_clustering(hop_layer)\n",
    "        draw_cluster_info(clustering_machine, data_name, img_path, comments = '_cluster_node_distr_' + str(hop_layer) + '_hops')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for partn in partition_nums:\n",
    "    for GCN_layer in layers:\n",
    "        net_layer = len(GCN_layer) + 1\n",
    "        hop_layer = net_layer\n",
    "        clustering_machine = set_clustering_machine(data, partition_num = partn, test_ratio = 0.05, validation_ratio = 0.85)\n",
    "        print('Start running for partition num: ' + str(partn) + ' hop layer ' + str(hop_layer))\n",
    "        img_path = image_data_path + 'cluster_num_' + str(partn) + '/' + 'net_layer_' + str(net_layer) + '_hop_layer_' + str(hop_layer) + '/'\n",
    "\n",
    "        validation_accuracy, validation_f1, time_total_train, time_data_load = execute_one(clustering_machine, img_path, repeate_time = 7, input_layer = GCN_layer, epoch_num = 400, layer_num = hop_layer, \\\n",
    "                                                                                          dropout = 0.3, lr = 0.0001, weight_decay = 0.001, mini_epoch_num = 20)\n",
    "        \n",
    "        validation_accuracy = store_data_multi_tests(validation_accuracy, data_name, img_path, 'test_cluster_num_' + str(partn) + '_hops_' + str(hop_layer))\n",
    "        draw_data_multi_tests(validation_accuracy, data_name, 'vali_cluster_num_' + str(partn) + '_hop_' + str(hop_layer), 'Accuracy')\n",
    "        validation_f1 = store_data_multi_tests(validation_f1, data_name, img_path, 'validation_cluster_num_' + str(partn) + '_hops_' + str(hop_layer))\n",
    "        draw_data_multi_tests(validation_f1, data_name, 'vali_cluster_num_' + str(partn) + '_hop_' + str(hop_layer), 'F1 score')\n",
    "        \n",
    "        time_train = store_data_multi_tests(time_total_train, data_name, img_path, 'train_time_cluster_num_' + str(partn) + '_hops_' + str(hop_layer))\n",
    "        draw_data_multi_tests(time_train, data_name, 'train_time_cluster_num_' + str(partn) + '_hop_' + str(hop_layer), 'Train Time (ms)')\n",
    "        time_load = store_data_multi_tests(time_data_load, data_name, img_path, 'load_time_cluster_num_' + str(partn) + '_hops_' + str(hop_layer))\n",
    "        draw_data_multi_tests(time_load, data_name, 'load_time_cluster_num_' + str(partn) + '_hop_' + str(hop_layer), 'Load Time (ms)')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# free GPU memory\n",
    "# !(nvidia-smi | grep 'python' | awk '{ print $3 }' | xargs -n1 kill -9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_geometric]",
   "language": "python",
   "name": "conda-env-pytorch_geometric-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
