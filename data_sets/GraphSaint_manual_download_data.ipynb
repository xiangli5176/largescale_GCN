{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset used in the GraphSaint paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from utils import filter_out_isolate, draw_cluster_info, draw_isolate_cluster_info, draw_trainer_info, print_data_info\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "def print_data_info(data):\n",
    "    \n",
    "    print('Info (attributes) of a single data instance')\n",
    "    print(data, '\\n number of nodes: ', data.num_nodes, '\\n number of edges: ', data.num_edges, \\\n",
    "      '\\n number of features per ndoe: ', data.num_node_features, '\\n number of edge features: ', data.num_edge_features, \\\n",
    "      '\\n number of classifying labels of dataset: ', dataset.num_classes, \\\n",
    "      '\\n all the attributes of data: ', data.keys)\n",
    "    \n",
    "local_data_root = '/home/xiangli/projects/tmpdata/GCN/GraphSaint/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flickr Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
    "from torch_geometric.data import InMemoryDataset, Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Flickr(InMemoryDataset):\n",
    "    r\"\"\"The Flickr dataset from the `\"GraphSAINT: Graph Sampling Based\n",
    "    Inductive Learning Method\" <https://arxiv.org/abs/1907.04931>`_ paper,\n",
    "    containing descriptions and common properties of images.\n",
    "\n",
    "    Args:\n",
    "        root (string): Root directory where the dataset should be saved.\n",
    "        transform (callable, optional): A function/transform that takes in an\n",
    "            :obj:`torch_geometric.data.Data` object and returns a transformed\n",
    "            version. The data object will be transformed before every access.\n",
    "            (default: :obj:`None`)\n",
    "        pre_transform (callable, optional): A function/transform that takes in\n",
    "            an :obj:`torch_geometric.data.Data` object and returns a\n",
    "            transformed version. The data object will be transformed before\n",
    "            being saved to disk. (default: :obj:`None`)\n",
    "    \"\"\"\n",
    "\n",
    "    adj_full_id = '1crmsTbd1-2sEXsGwa2IKnIB7Zd3TmUsy'\n",
    "    feats_id = '1join-XdvX3anJU_MLVtick7MgeAQiWIZ'\n",
    "    class_map_id = '1uxIkbtg5drHTsKt-PAsZZ4_yJmgFmle9'\n",
    "    role_id = '1htXCtuktuCW8TR8KiKfrFDAxUgekQoV7'\n",
    "\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super(Flickr, self).__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['adj_full.npz', 'feats.npy', 'class_map.json', 'role.json']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return 'data.pt'\n",
    "\n",
    "    def download(self):\n",
    "        path = osp.join(self.raw_dir, 'adj_full.npz')\n",
    "        gdd.download_file_from_google_drive(self.adj_full_id, path)\n",
    "\n",
    "        path = osp.join(self.raw_dir, 'feats.npy')\n",
    "        gdd.download_file_from_google_drive(self.feats_id, path)\n",
    "\n",
    "        path = osp.join(self.raw_dir, 'class_map.json')\n",
    "        gdd.download_file_from_google_drive(self.class_map_id, path)\n",
    "\n",
    "        path = osp.join(self.raw_dir, 'role.json')\n",
    "        gdd.download_file_from_google_drive(self.role_id, path)\n",
    "\n",
    "    def process(self):\n",
    "        f = np.load(osp.join(self.raw_dir, 'adj_full.npz'))\n",
    "        adj = sp.csr_matrix((f['data'], f['indices'], f['indptr']), f['shape'])\n",
    "        adj = adj.tocoo()\n",
    "        row = torch.from_numpy(adj.row).to(torch.long)\n",
    "        col = torch.from_numpy(adj.col).to(torch.long)\n",
    "        edge_index = torch.stack([row, col], dim=0)\n",
    "\n",
    "        x = np.load(osp.join(self.raw_dir, 'feats.npy'))\n",
    "        x = torch.from_numpy(x).to(torch.float)\n",
    "\n",
    "        ys = [-1] * x.size(0)\n",
    "        with open(osp.join(self.raw_dir, 'class_map.json')) as f:\n",
    "            class_map = json.load(f)\n",
    "            for key, item in class_map.items():\n",
    "                ys[int(key)] = item\n",
    "        y = torch.tensor(ys)\n",
    "\n",
    "        with open(osp.join(self.raw_dir, 'role.json')) as f:\n",
    "            role = json.load(f)\n",
    "\n",
    "        train_mask = torch.zeros(x.size(0), dtype=torch.bool)\n",
    "        train_mask[torch.tensor(role['tr'])] = True\n",
    "\n",
    "        val_mask = torch.zeros(x.size(0), dtype=torch.bool)\n",
    "        val_mask[torch.tensor(role['va'])] = True\n",
    "\n",
    "        test_mask = torch.zeros(x.size(0), dtype=torch.bool)\n",
    "        test_mask[torch.tensor(role['te'])] = True\n",
    "\n",
    "        data = Data(x=x, edge_index=edge_index, y=y, train_mask=train_mask,\n",
    "                    val_mask=val_mask, test_mask=test_mask)\n",
    "\n",
    "        data = data if self.pre_transform is None else self.pre_transform(data)\n",
    "\n",
    "        torch.save(self.collate([data]), self.processed_paths[0])\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}()'.format(self.__class__.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of data 1\n",
      "Info (attributes) of a single data instance\n",
      "Data(edge_index=[2, 899756], test_mask=[89250], train_mask=[89250], val_mask=[89250], x=[89250, 500], y=[89250]) \n",
      " number of nodes:  89250 \n",
      " number of edges:  899756 \n",
      " number of features per ndoe:  500 \n",
      " number of edge features:  0 \n",
      " number of classifying labels of dataset:  7 \n",
      " all the attributes of data:  ['x', 'edge_index', 'y', 'train_mask', 'val_mask', 'test_mask']\n"
     ]
    }
   ],
   "source": [
    "data_name = 'Flickr'\n",
    "dataset = Flickr(root = local_data_root + 'Flickr')\n",
    "print('number of data', len(dataset))\n",
    "data = dataset[0]\n",
    "print_data_info(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yelp Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Yelp(InMemoryDataset):\n",
    "    r\"\"\"The Yelp dataset from the `\"GraphSAINT: Graph Sampling Based\n",
    "    Inductive Learning Method\" <https://arxiv.org/abs/1907.04931>`_ paper,\n",
    "    containing customer reviewers and their friendship.\n",
    "\n",
    "    Args:\n",
    "        root (string): Root directory where the dataset should be saved.\n",
    "        transform (callable, optional): A function/transform that takes in an\n",
    "            :obj:`torch_geometric.data.Data` object and returns a transformed\n",
    "            version. The data object will be transformed before every access.\n",
    "            (default: :obj:`None`)\n",
    "        pre_transform (callable, optional): A function/transform that takes in\n",
    "            an :obj:`torch_geometric.data.Data` object and returns a\n",
    "            transformed version. The data object will be transformed before\n",
    "            being saved to disk. (default: :obj:`None`)\n",
    "    \"\"\"\n",
    "\n",
    "    adj_full_id = '1Juwx8HtDwSzmVIJ31ooVa1WljI4U5JnA'\n",
    "    feats_id = '1Zy6BZH_zLEjKlEFSduKE5tV9qqA_8VtM'\n",
    "    class_map_id = '1VUcBGr0T0-klqerjAjxRmAqFuld_SMWU'\n",
    "    role_id = '1NI5pa5Chpd-52eSmLW60OnB3WS5ikxq_'\n",
    "\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super(Yelp, self).__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['adj_full.npz', 'feats.npy', 'class_map.json', 'role.json']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return 'data.pt'\n",
    "\n",
    "    def download(self):\n",
    "        path = osp.join(self.raw_dir, 'adj_full.npz')\n",
    "        gdd.download_file_from_google_drive(self.adj_full_id, path)\n",
    "\n",
    "        path = osp.join(self.raw_dir, 'feats.npy')\n",
    "        gdd.download_file_from_google_drive(self.feats_id, path)\n",
    "\n",
    "        path = osp.join(self.raw_dir, 'class_map.json')\n",
    "        gdd.download_file_from_google_drive(self.class_map_id, path)\n",
    "\n",
    "        path = osp.join(self.raw_dir, 'role.json')\n",
    "        gdd.download_file_from_google_drive(self.role_id, path)\n",
    "\n",
    "    def process(self):\n",
    "        f = np.load(osp.join(self.raw_dir, 'adj_full.npz'))\n",
    "        adj = sp.csr_matrix((f['data'], f['indices'], f['indptr']), f['shape'])\n",
    "        adj = adj.tocoo()\n",
    "        row = torch.from_numpy(adj.row).to(torch.long)\n",
    "        col = torch.from_numpy(adj.col).to(torch.long)\n",
    "        edge_index = torch.stack([row, col], dim=0)\n",
    "\n",
    "        x = np.load(osp.join(self.raw_dir, 'feats.npy'))\n",
    "        x = torch.from_numpy(x).to(torch.float)\n",
    "\n",
    "        ys = [-1] * x.size(0)\n",
    "        with open(osp.join(self.raw_dir, 'class_map.json')) as f:\n",
    "            class_map = json.load(f)\n",
    "            for key, item in class_map.items():\n",
    "                ys[int(key)] = item\n",
    "        y = torch.tensor(ys)\n",
    "\n",
    "        with open(osp.join(self.raw_dir, 'role.json')) as f:\n",
    "            role = json.load(f)\n",
    "\n",
    "        train_mask = torch.zeros(x.size(0), dtype=torch.bool)\n",
    "        train_mask[torch.tensor(role['tr'])] = True\n",
    "\n",
    "        val_mask = torch.zeros(x.size(0), dtype=torch.bool)\n",
    "        val_mask[torch.tensor(role['va'])] = True\n",
    "\n",
    "        test_mask = torch.zeros(x.size(0), dtype=torch.bool)\n",
    "        test_mask[torch.tensor(role['te'])] = True\n",
    "\n",
    "        data = Data(x=x, edge_index=edge_index, y=y, train_mask=train_mask,\n",
    "                    val_mask=val_mask, test_mask=test_mask)\n",
    "\n",
    "        data = data if self.pre_transform is None else self.pre_transform(data)\n",
    "\n",
    "        torch.save(self.collate([data]), self.processed_paths[0])\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}()'.format(self.__class__.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of data 1\n",
      "Info (attributes) of a single data instance\n",
      "Data(edge_index=[2, 13954819], test_mask=[716847], train_mask=[716847], val_mask=[716847], x=[716847, 300], y=[716847, 100]) \n",
      " number of nodes:  716847 \n",
      " number of edges:  13954819 \n",
      " number of features per ndoe:  300 \n",
      " number of edge features:  0 \n",
      " number of classifying labels of dataset:  100 \n",
      " all the attributes of data:  ['x', 'edge_index', 'y', 'train_mask', 'val_mask', 'test_mask']\n"
     ]
    }
   ],
   "source": [
    "data_name = 'Yelp'\n",
    "dataset = Yelp(root = local_data_root + data_name)\n",
    "print('number of data', len(dataset))\n",
    "data = dataset[0]\n",
    "print_data_info(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PPI(large dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPI_large(InMemoryDataset):\n",
    "    r\"\"\"The PPI(large) dataset from the `\"GraphSAINT: Graph Sampling Based\n",
    "    Inductive Learning Method\" <https://arxiv.org/abs/1907.04931>`_ paper,\n",
    "    containing customer reviewers and their friendship.\n",
    "\n",
    "    Args:\n",
    "        root (string): Root directory where the dataset should be saved.\n",
    "        transform (callable, optional): A function/transform that takes in an\n",
    "            :obj:`torch_geometric.data.Data` object and returns a transformed\n",
    "            version. The data object will be transformed before every access.\n",
    "            (default: :obj:`None`)\n",
    "        pre_transform (callable, optional): A function/transform that takes in\n",
    "            an :obj:`torch_geometric.data.Data` object and returns a\n",
    "            transformed version. The data object will be transformed before\n",
    "            being saved to disk. (default: :obj:`None`)\n",
    "    \"\"\"\n",
    "    \n",
    "    adj_full_id = '1Sx3w_JK5J-lrzD2sf2ZW-CqCfnDYGRaY'\n",
    "    feats_id = '15kPXApOLkXhngxMcWJDDs0fUB227h8BN'\n",
    "    class_map_id = '1yBiSjpcF7tuL8UDCH0_Dcwgn01R2cKda'\n",
    "    role_id = '11sr8WLA4H-JYiWRnB7xo9W9yXu2-8HQG'\n",
    "\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super(PPI_large, self).__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['adj_full.npz', 'feats.npy', 'class_map.json', 'role.json']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return 'data.pt'\n",
    "\n",
    "    def download(self):\n",
    "        path = osp.join(self.raw_dir, 'adj_full.npz')\n",
    "        gdd.download_file_from_google_drive(self.adj_full_id, path)\n",
    "\n",
    "        path = osp.join(self.raw_dir, 'feats.npy')\n",
    "        gdd.download_file_from_google_drive(self.feats_id, path)\n",
    "\n",
    "        path = osp.join(self.raw_dir, 'class_map.json')\n",
    "        gdd.download_file_from_google_drive(self.class_map_id, path)\n",
    "\n",
    "        path = osp.join(self.raw_dir, 'role.json')\n",
    "        gdd.download_file_from_google_drive(self.role_id, path)\n",
    "\n",
    "    def process(self):\n",
    "        f = np.load(osp.join(self.raw_dir, 'adj_full.npz'))\n",
    "        adj = sp.csr_matrix((f['data'], f['indices'], f['indptr']), f['shape'])\n",
    "        adj = adj.tocoo()\n",
    "        row = torch.from_numpy(adj.row).to(torch.long)\n",
    "        col = torch.from_numpy(adj.col).to(torch.long)\n",
    "        edge_index = torch.stack([row, col], dim=0)\n",
    "\n",
    "        x = np.load(osp.join(self.raw_dir, 'feats.npy'))\n",
    "        x = torch.from_numpy(x).to(torch.float)\n",
    "\n",
    "        ys = [-1] * x.size(0)\n",
    "        with open(osp.join(self.raw_dir, 'class_map.json')) as f:\n",
    "            class_map = json.load(f)\n",
    "            for key, item in class_map.items():\n",
    "                ys[int(key)] = item\n",
    "        y = torch.tensor(ys)\n",
    "\n",
    "        with open(osp.join(self.raw_dir, 'role.json')) as f:\n",
    "            role = json.load(f)\n",
    "\n",
    "        train_mask = torch.zeros(x.size(0), dtype=torch.bool)\n",
    "        train_mask[torch.tensor(role['tr'])] = True\n",
    "\n",
    "        val_mask = torch.zeros(x.size(0), dtype=torch.bool)\n",
    "        val_mask[torch.tensor(role['va'])] = True\n",
    "\n",
    "        test_mask = torch.zeros(x.size(0), dtype=torch.bool)\n",
    "        test_mask[torch.tensor(role['te'])] = True\n",
    "\n",
    "        data = Data(x=x, edge_index=edge_index, y=y, train_mask=train_mask,\n",
    "                    val_mask=val_mask, test_mask=test_mask)\n",
    "\n",
    "        data = data if self.pre_transform is None else self.pre_transform(data)\n",
    "\n",
    "        torch.save(self.collate([data]), self.processed_paths[0])\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}()'.format(self.__class__.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 1Sx3w_JK5J-lrzD2sf2ZW-CqCfnDYGRaY into /home/xiangli/projects/tmpdata/GCN/PPI_large/raw/adj_full.npz... Done.\n",
      "Downloading 15kPXApOLkXhngxMcWJDDs0fUB227h8BN into /home/xiangli/projects/tmpdata/GCN/PPI_large/raw/feats.npy... Done.\n",
      "Downloading 1yBiSjpcF7tuL8UDCH0_Dcwgn01R2cKda into /home/xiangli/projects/tmpdata/GCN/PPI_large/raw/class_map.json... Done.\n",
      "Downloading 11sr8WLA4H-JYiWRnB7xo9W9yXu2-8HQG into /home/xiangli/projects/tmpdata/GCN/PPI_large/raw/role.json... Done.\n",
      "Processing...\n",
      "Done!\n",
      "number of data 1\n",
      "Info (attributes) of a single data instance\n",
      "Data(edge_index=[2, 1612348], test_mask=[56944], train_mask=[56944], val_mask=[56944], x=[56944, 50], y=[56944, 121]) \n",
      " number of nodes:  56944 \n",
      " number of edges:  1612348 \n",
      " number of features per ndoe:  50 \n",
      " number of edge features:  0 \n",
      " number of classifying labels of dataset:  121 \n",
      " all the attributes of data:  ['x', 'edge_index', 'y', 'train_mask', 'val_mask', 'test_mask']\n"
     ]
    }
   ],
   "source": [
    "data_name = 'PPI_large'\n",
    "dataset = PPI_large(root = local_data_root + data_name)\n",
    "print('number of data', len(dataset))\n",
    "data = dataset[0]\n",
    "print_data_info(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Amazon(InMemoryDataset):\n",
    "    r\"\"\"The Amazon dataset from the `\"GraphSAINT: Graph Sampling Based\n",
    "    Inductive Learning Method\" <https://arxiv.org/abs/1907.04931>`_ paper,\n",
    "    containing customer reviewers and their friendship.\n",
    "\n",
    "    Args:\n",
    "        root (string): Root directory where the dataset should be saved.\n",
    "        transform (callable, optional): A function/transform that takes in an\n",
    "            :obj:`torch_geometric.data.Data` object and returns a transformed\n",
    "            version. The data object will be transformed before every access.\n",
    "            (default: :obj:`None`)\n",
    "        pre_transform (callable, optional): A function/transform that takes in\n",
    "            an :obj:`torch_geometric.data.Data` object and returns a\n",
    "            transformed version. The data object will be transformed before\n",
    "            being saved to disk. (default: :obj:`None`)\n",
    "    \"\"\"\n",
    "    \n",
    "    adj_full_id = '17qhNA8H1IpbkkR-T2BmPQm8QNW5do-aa'\n",
    "    feats_id = '10SW8lCvAj-kb6ckkfTOC5y0l8XXdtMxj'\n",
    "    class_map_id = '1LIl4kimLfftj4-7NmValuWyCQE8AaE7P'\n",
    "    role_id = '1npK9xlmbnjNkV80hK2Q68wTEVOFjnt4K'\n",
    "\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super(Amazon, self).__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['adj_full.npz', 'feats.npy', 'class_map.json', 'role.json']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return 'data.pt'\n",
    "\n",
    "    def download(self):\n",
    "        path = osp.join(self.raw_dir, 'adj_full.npz')\n",
    "        gdd.download_file_from_google_drive(self.adj_full_id, path)\n",
    "\n",
    "        path = osp.join(self.raw_dir, 'feats.npy')\n",
    "        gdd.download_file_from_google_drive(self.feats_id, path)\n",
    "\n",
    "        path = osp.join(self.raw_dir, 'class_map.json')\n",
    "        gdd.download_file_from_google_drive(self.class_map_id, path)\n",
    "\n",
    "        path = osp.join(self.raw_dir, 'role.json')\n",
    "        gdd.download_file_from_google_drive(self.role_id, path)\n",
    "\n",
    "    def process(self):\n",
    "        f = np.load(osp.join(self.raw_dir, 'adj_full.npz'))\n",
    "        adj = sp.csr_matrix((f['data'], f['indices'], f['indptr']), f['shape'])\n",
    "        adj = adj.tocoo()\n",
    "        row = torch.from_numpy(adj.row).to(torch.long)\n",
    "        col = torch.from_numpy(adj.col).to(torch.long)\n",
    "        edge_index = torch.stack([row, col], dim=0)\n",
    "\n",
    "        x = np.load(osp.join(self.raw_dir, 'feats.npy'))\n",
    "        x = torch.from_numpy(x).to(torch.float)\n",
    "\n",
    "        ys = [-1] * x.size(0)\n",
    "        with open(osp.join(self.raw_dir, 'class_map.json')) as f:\n",
    "            class_map = json.load(f)\n",
    "            for key, item in class_map.items():\n",
    "                ys[int(key)] = item\n",
    "        y = torch.tensor(ys)\n",
    "\n",
    "        with open(osp.join(self.raw_dir, 'role.json')) as f:\n",
    "            role = json.load(f)\n",
    "\n",
    "        train_mask = torch.zeros(x.size(0), dtype=torch.bool)\n",
    "        train_mask[torch.tensor(role['tr'])] = True\n",
    "\n",
    "        val_mask = torch.zeros(x.size(0), dtype=torch.bool)\n",
    "        val_mask[torch.tensor(role['va'])] = True\n",
    "\n",
    "        test_mask = torch.zeros(x.size(0), dtype=torch.bool)\n",
    "        test_mask[torch.tensor(role['te'])] = True\n",
    "\n",
    "        data = Data(x=x, edge_index=edge_index, y=y, train_mask=train_mask,\n",
    "                    val_mask=val_mask, test_mask=test_mask)\n",
    "\n",
    "        data = data if self.pre_transform is None else self.pre_transform(data)\n",
    "\n",
    "        torch.save(self.collate([data]), self.processed_paths[0])\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}()'.format(self.__class__.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 17qhNA8H1IpbkkR-T2BmPQm8QNW5do-aa into /home/xiangli/projects/tmpdata/GCN/Amazon/raw/adj_full.npz... Done.\n",
      "Downloading 10SW8lCvAj-kb6ckkfTOC5y0l8XXdtMxj into /home/xiangli/projects/tmpdata/GCN/Amazon/raw/feats.npy... Done.\n",
      "Downloading 1LIl4kimLfftj4-7NmValuWyCQE8AaE7P into /home/xiangli/projects/tmpdata/GCN/Amazon/raw/class_map.json... Done.\n",
      "Downloading 1npK9xlmbnjNkV80hK2Q68wTEVOFjnt4K into /home/xiangli/projects/tmpdata/GCN/Amazon/raw/role.json... Done.\n",
      "Processing...\n",
      "Done!\n",
      "number of data 1\n",
      "Info (attributes) of a single data instance\n",
      "Data(edge_index=[2, 264339468], test_mask=[1569960], train_mask=[1569960], val_mask=[1569960], x=[1569960, 200], y=[1569960, 107]) \n",
      " number of nodes:  1569960 \n",
      " number of edges:  264339468 \n",
      " number of features per ndoe:  200 \n",
      " number of edge features:  0 \n",
      " number of classifying labels of dataset:  107 \n",
      " all the attributes of data:  ['x', 'edge_index', 'y', 'train_mask', 'val_mask', 'test_mask']\n"
     ]
    }
   ],
   "source": [
    "data_name = 'Amazon'\n",
    "dataset = Amazon(root = local_data_root + data_name)\n",
    "print('number of data', len(dataset))\n",
    "data = dataset[0]\n",
    "print_data_info(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPI_small(InMemoryDataset):\n",
    "    r\"\"\"The PPI(large) dataset from the `\"GraphSAINT: Graph Sampling Based\n",
    "    Inductive Learning Method\" <https://arxiv.org/abs/1907.04931>`_ paper,\n",
    "    containing customer reviewers and their friendship.\n",
    "\n",
    "    Args:\n",
    "        root (string): Root directory where the dataset should be saved.\n",
    "        transform (callable, optional): A function/transform that takes in an\n",
    "            :obj:`torch_geometric.data.Data` object and returns a transformed\n",
    "            version. The data object will be transformed before every access.\n",
    "            (default: :obj:`None`)\n",
    "        pre_transform (callable, optional): A function/transform that takes in\n",
    "            an :obj:`torch_geometric.data.Data` object and returns a\n",
    "            transformed version. The data object will be transformed before\n",
    "            being saved to disk. (default: :obj:`None`)\n",
    "    \"\"\"\n",
    "    \n",
    "    adj_full_id = '1DkkGTzlR4PXLN8TAspGxbqx2fs50K8yg'\n",
    "    feats_id = '1-2Y06R0Ps0Jl2C9GpgmWfmarCXU6B0e0'\n",
    "    class_map_id = '1RFxSE5ZqwFc9LTZQZqjI0wQ3Kf4vN84x'\n",
    "    role_id = '1zipPm-NDR4nEb14JMki9PNrWGziMndlx'\n",
    "\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super(PPI_small, self).__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['adj_full.npz', 'feats.npy', 'class_map.json', 'role.json']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return 'data.pt'\n",
    "\n",
    "    def download(self):\n",
    "        path = osp.join(self.raw_dir, 'adj_full.npz')\n",
    "        gdd.download_file_from_google_drive(self.adj_full_id, path)\n",
    "\n",
    "        path = osp.join(self.raw_dir, 'feats.npy')\n",
    "        gdd.download_file_from_google_drive(self.feats_id, path)\n",
    "\n",
    "        path = osp.join(self.raw_dir, 'class_map.json')\n",
    "        gdd.download_file_from_google_drive(self.class_map_id, path)\n",
    "\n",
    "        path = osp.join(self.raw_dir, 'role.json')\n",
    "        gdd.download_file_from_google_drive(self.role_id, path)\n",
    "\n",
    "    def process(self):\n",
    "        f = np.load(osp.join(self.raw_dir, 'adj_full.npz'))\n",
    "        adj = sp.csr_matrix((f['data'], f['indices'], f['indptr']), f['shape'])\n",
    "        adj = adj.tocoo()\n",
    "        row = torch.from_numpy(adj.row).to(torch.long)\n",
    "        col = torch.from_numpy(adj.col).to(torch.long)\n",
    "        edge_index = torch.stack([row, col], dim=0)\n",
    "\n",
    "        x = np.load(osp.join(self.raw_dir, 'feats.npy'))\n",
    "        x = torch.from_numpy(x).to(torch.float)\n",
    "\n",
    "        ys = [-1] * x.size(0)\n",
    "        with open(osp.join(self.raw_dir, 'class_map.json')) as f:\n",
    "            class_map = json.load(f)\n",
    "            for key, item in class_map.items():\n",
    "                ys[int(key)] = item\n",
    "        y = torch.tensor(ys)\n",
    "\n",
    "        with open(osp.join(self.raw_dir, 'role.json')) as f:\n",
    "            role = json.load(f)\n",
    "\n",
    "        train_mask = torch.zeros(x.size(0), dtype=torch.bool)\n",
    "        train_mask[torch.tensor(role['tr'])] = True\n",
    "\n",
    "        val_mask = torch.zeros(x.size(0), dtype=torch.bool)\n",
    "        val_mask[torch.tensor(role['va'])] = True\n",
    "\n",
    "        test_mask = torch.zeros(x.size(0), dtype=torch.bool)\n",
    "        test_mask[torch.tensor(role['te'])] = True\n",
    "\n",
    "        data = Data(x=x, edge_index=edge_index, y=y, train_mask=train_mask,\n",
    "                    val_mask=val_mask, test_mask=test_mask)\n",
    "\n",
    "        data = data if self.pre_transform is None else self.pre_transform(data)\n",
    "\n",
    "        torch.save(self.collate([data]), self.processed_paths[0])\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}()'.format(self.__class__.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 1DkkGTzlR4PXLN8TAspGxbqx2fs50K8yg into /home/xiangli/projects/tmpdata/GCN/PPI_small/raw/adj_full.npz... Done.\n",
      "Downloading 1-2Y06R0Ps0Jl2C9GpgmWfmarCXU6B0e0 into /home/xiangli/projects/tmpdata/GCN/PPI_small/raw/feats.npy... Done.\n",
      "Downloading 1RFxSE5ZqwFc9LTZQZqjI0wQ3Kf4vN84x into /home/xiangli/projects/tmpdata/GCN/PPI_small/raw/class_map.json... Done.\n",
      "Downloading 1zipPm-NDR4nEb14JMki9PNrWGziMndlx into /home/xiangli/projects/tmpdata/GCN/PPI_small/raw/role.json... Done.\n",
      "Processing...\n",
      "Done!\n",
      "number of data 1\n",
      "Info (attributes) of a single data instance\n",
      "Data(edge_index=[2, 450540], test_mask=[14755], train_mask=[14755], val_mask=[14755], x=[14755, 50], y=[14755, 121]) \n",
      " number of nodes:  14755 \n",
      " number of edges:  450540 \n",
      " number of features per ndoe:  50 \n",
      " number of edge features:  0 \n",
      " number of classifying labels of dataset:  121 \n",
      " all the attributes of data:  ['x', 'edge_index', 'y', 'train_mask', 'val_mask', 'test_mask']\n"
     ]
    }
   ],
   "source": [
    "data_name = 'PPI_small'\n",
    "dataset = PPI_small(root = local_data_root + data_name)\n",
    "print('number of data', len(dataset))\n",
    "data = dataset[0]\n",
    "print_data_info(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reddit dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reddit(InMemoryDataset):\n",
    "    r\"\"\"The PPI(large) dataset from the `\"GraphSAINT: Graph Sampling Based\n",
    "    Inductive Learning Method\" <https://arxiv.org/abs/1907.04931>`_ paper,\n",
    "    containing customer reviewers and their friendship.\n",
    "\n",
    "    Args:\n",
    "        root (string): Root directory where the dataset should be saved.\n",
    "        transform (callable, optional): A function/transform that takes in an\n",
    "            :obj:`torch_geometric.data.Data` object and returns a transformed\n",
    "            version. The data object will be transformed before every access.\n",
    "            (default: :obj:`None`)\n",
    "        pre_transform (callable, optional): A function/transform that takes in\n",
    "            an :obj:`torch_geometric.data.Data` object and returns a\n",
    "            transformed version. The data object will be transformed before\n",
    "            being saved to disk. (default: :obj:`None`)\n",
    "    \"\"\"\n",
    "\n",
    "    adj_full_id = '1sncK996BM5lpuDf75lDFqCiDZyErc1c2'\n",
    "    feats_id = '1ZsHaJ0ussP1W722krmEIp_8pwKAoi5b3'\n",
    "    class_map_id = '1JF3Pjv9OboMNYs2aXRQGbJbc4t_nDd5u'\n",
    "    role_id = '1nJIKd77lcAGU4j-kVNx_AIGEkveIKz3A'\n",
    "\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super(Reddit, self).__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['adj_full.npz', 'feats.npy', 'class_map.json', 'role.json']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return 'data.pt'\n",
    "\n",
    "    def download(self):\n",
    "        path = osp.join(self.raw_dir, 'adj_full.npz')\n",
    "        gdd.download_file_from_google_drive(self.adj_full_id, path)\n",
    "\n",
    "        path = osp.join(self.raw_dir, 'feats.npy')\n",
    "        gdd.download_file_from_google_drive(self.feats_id, path)\n",
    "\n",
    "        path = osp.join(self.raw_dir, 'class_map.json')\n",
    "        gdd.download_file_from_google_drive(self.class_map_id, path)\n",
    "\n",
    "        path = osp.join(self.raw_dir, 'role.json')\n",
    "        gdd.download_file_from_google_drive(self.role_id, path)\n",
    "\n",
    "    def process(self):\n",
    "        f = np.load(osp.join(self.raw_dir, 'adj_full.npz'))\n",
    "        adj = sp.csr_matrix((f['data'], f['indices'], f['indptr']), f['shape'])\n",
    "        adj = adj.tocoo()\n",
    "        row = torch.from_numpy(adj.row).to(torch.long)\n",
    "        col = torch.from_numpy(adj.col).to(torch.long)\n",
    "        edge_index = torch.stack([row, col], dim=0)\n",
    "\n",
    "        x = np.load(osp.join(self.raw_dir, 'feats.npy'))\n",
    "        x = torch.from_numpy(x).to(torch.float)\n",
    "\n",
    "        ys = [-1] * x.size(0)\n",
    "        with open(osp.join(self.raw_dir, 'class_map.json')) as f:\n",
    "            class_map = json.load(f)\n",
    "            for key, item in class_map.items():\n",
    "                ys[int(key)] = item\n",
    "        y = torch.tensor(ys)\n",
    "\n",
    "        with open(osp.join(self.raw_dir, 'role.json')) as f:\n",
    "            role = json.load(f)\n",
    "\n",
    "        train_mask = torch.zeros(x.size(0), dtype=torch.bool)\n",
    "        train_mask[torch.tensor(role['tr'])] = True\n",
    "\n",
    "        val_mask = torch.zeros(x.size(0), dtype=torch.bool)\n",
    "        val_mask[torch.tensor(role['va'])] = True\n",
    "\n",
    "        test_mask = torch.zeros(x.size(0), dtype=torch.bool)\n",
    "        test_mask[torch.tensor(role['te'])] = True\n",
    "\n",
    "        data = Data(x=x, edge_index=edge_index, y=y, train_mask=train_mask,\n",
    "                    val_mask=val_mask, test_mask=test_mask)\n",
    "\n",
    "        data = data if self.pre_transform is None else self.pre_transform(data)\n",
    "\n",
    "        torch.save(self.collate([data]), self.processed_paths[0])\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}()'.format(self.__class__.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 1sncK996BM5lpuDf75lDFqCiDZyErc1c2 into /home/xiangli/projects/tmpdata/GCN/Reddit/raw/adj_full.npz... Done.\n",
      "Downloading 1ZsHaJ0ussP1W722krmEIp_8pwKAoi5b3 into /home/xiangli/projects/tmpdata/GCN/Reddit/raw/feats.npy... Done.\n",
      "Downloading 1JF3Pjv9OboMNYs2aXRQGbJbc4t_nDd5u into /home/xiangli/projects/tmpdata/GCN/Reddit/raw/class_map.json... Done.\n",
      "Downloading 1nJIKd77lcAGU4j-kVNx_AIGEkveIKz3A into /home/xiangli/projects/tmpdata/GCN/Reddit/raw/role.json... Done.\n",
      "Processing...\n",
      "Done!\n",
      "number of data 1\n",
      "Info (attributes) of a single data instance\n",
      "Data(edge_index=[2, 23213838], test_mask=[232965], train_mask=[232965], val_mask=[232965], x=[232965, 602], y=[232965]) \n",
      " number of nodes:  232965 \n",
      " number of edges:  23213838 \n",
      " number of features per ndoe:  602 \n",
      " number of edge features:  0 \n",
      " number of classifying labels of dataset:  41 \n",
      " all the attributes of data:  ['x', 'edge_index', 'y', 'train_mask', 'val_mask', 'test_mask']\n"
     ]
    }
   ],
   "source": [
    "data_name = 'Reddit'\n",
    "dataset = Reddit(root = local_data_root + data_name)\n",
    "print('number of data', len(dataset))\n",
    "data = dataset[0]\n",
    "print_data_info(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_1_4_geometric]",
   "language": "python",
   "name": "conda-env-pytorch_1_4_geometric-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
