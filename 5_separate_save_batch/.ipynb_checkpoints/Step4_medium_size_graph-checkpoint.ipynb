{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrate model inter-cluster with three clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pickle\n",
    "import shutil\n",
    "\n",
    "from utils import filter_out_isolate, draw_cluster_info, draw_isolate_cluster_info, draw_trainer_info, print_data_info, check_folder_exist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import torch\n",
    "from torch_geometric.utils import scatter_\n",
    "\n",
    "special_args = [\n",
    "    'edge_index', 'edge_index_i', 'edge_index_j', 'size', 'size_i', 'size_j'\n",
    "]\n",
    "__size_error_msg__ = ('All tensors which should get mapped to the same source '\n",
    "                      'or target nodes must be of same size in dimension 0.')\n",
    "\n",
    "is_python2 = sys.version_info[0] < 3\n",
    "getargspec = inspect.getargspec if is_python2 else inspect.getfullargspec\n",
    "\n",
    "\n",
    "class MessagePassing(torch.nn.Module):\n",
    "    r\"\"\"Base class for creating message passing layers\n",
    "\n",
    "    .. math::\n",
    "        \\mathbf{x}_i^{\\prime} = \\gamma_{\\mathbf{\\Theta}} \\left( \\mathbf{x}_i,\n",
    "        \\square_{j \\in \\mathcal{N}(i)} \\, \\phi_{\\mathbf{\\Theta}}\n",
    "        \\left(\\mathbf{x}_i, \\mathbf{x}_j,\\mathbf{e}_{i,j}\\right) \\right),\n",
    "\n",
    "    where :math:`\\square` denotes a differentiable, permutation invariant\n",
    "    function, *e.g.*, sum, mean or max, and :math:`\\gamma_{\\mathbf{\\Theta}}`\n",
    "    and :math:`\\phi_{\\mathbf{\\Theta}}` denote differentiable functions such as\n",
    "    MLPs.\n",
    "    See `here <https://pytorch-geometric.readthedocs.io/en/latest/notes/\n",
    "    create_gnn.html>`__ for the accompanying tutorial.\n",
    "\n",
    "    Args:\n",
    "        aggr (string, optional): The aggregation scheme to use\n",
    "            (:obj:`\"add\"`, :obj:`\"mean\"` or :obj:`\"max\"`).\n",
    "            (default: :obj:`\"add\"`)\n",
    "        flow (string, optional): The flow direction of message passing\n",
    "            (:obj:`\"source_to_target\"` or :obj:`\"target_to_source\"`).\n",
    "            (default: :obj:`\"source_to_target\"`)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, aggr='add', flow='source_to_target'):\n",
    "        super(MessagePassing, self).__init__()\n",
    "\n",
    "        self.aggr = aggr\n",
    "        assert self.aggr in ['add', 'mean', 'max']\n",
    "\n",
    "        self.flow = flow\n",
    "        # give a warning if the option is not valid\n",
    "        assert self.flow in ['source_to_target', 'target_to_source']\n",
    "\n",
    "        self.__message_args__ = getargspec(self.message)[0][1:]\n",
    "        # we will have [x_j, norm ] put into self.__message_args__\n",
    "        \n",
    "        self.__special_args__ = [(i, arg)\n",
    "                                 for i, arg in enumerate(self.__message_args__)\n",
    "                                 if arg in special_args]\n",
    "        \n",
    "        self.__message_args__ = [arg for arg in self.__message_args__ if arg not in special_args]\n",
    "        \n",
    "        self.__update_args__ = getargspec(self.update)[0][2:]\n",
    "        # empty, since there is nothing beyond: agg_out\n",
    "\n",
    "#     function call: res = self.propagate(edge_index, x=x, norm=norm)\n",
    "    def propagate(self, edge_index, size=None, **kwargs):\n",
    "        r\"\"\"The initial call to start propagating messages.\n",
    "\n",
    "        Args:\n",
    "            edge_index (Tensor): The indices of a general (sparse) assignment\n",
    "                matrix with shape :obj:`[N, M]` (can be directed or\n",
    "                undirected).\n",
    "            size (list or tuple, optional): The size :obj:`[N, M]` of the\n",
    "                assignment matrix. If set to :obj:`None`, the size is tried to\n",
    "                get automatically inferred. (default: :obj:`None`)\n",
    "            **kwargs: Any additional data which is needed to construct messages\n",
    "                and to update node embeddings.\n",
    "        \"\"\"\n",
    "        dim = 0\n",
    "        size = [None, None] if size is None else list(size)\n",
    "        assert len(size) == 2\n",
    "\n",
    "        i, j = (0, 1) if self.flow == 'target_to_source' else (1, 0)\n",
    "        # here (i, j) == (1, 0)\n",
    "        ij = {\"_i\": i, \"_j\": j}\n",
    "\n",
    "        message_args = []\n",
    "        \n",
    "        for arg in self.__message_args__:\n",
    "#             arg[-2] == '_j'\n",
    "            if arg[-2:] in ij.keys():\n",
    "#                 tmp == x, is inside the dwargs\n",
    "                tmp = kwargs.get(arg[:-2], None)   # get the value of the parameter\n",
    "                if tmp is None:  # pragma: no cover\n",
    "                    message_args.append(tmp)\n",
    "                else:\n",
    "                    idx = ij[arg[-2:]]    # idx == 0\n",
    "                    if isinstance(tmp, tuple) or isinstance(tmp, list):\n",
    "                        assert len(tmp) == 2\n",
    "                        if tmp[1 - idx] is not None:\n",
    "                            if size[1 - idx] is None:\n",
    "                                size[1 - idx] = tmp[1 - idx].size(dim)\n",
    "                            if size[1 - idx] != tmp[1 - idx].size(dim):\n",
    "                                raise ValueError(__size_error_msg__)\n",
    "                        tmp = tmp[idx]\n",
    "                    \n",
    "                    if tmp is None:\n",
    "                        message_args.append(tmp)\n",
    "                    else:\n",
    "                        if size[idx] is None:\n",
    "                            size[idx] = tmp.size(dim)\n",
    "                        if size[idx] != tmp.size(dim):\n",
    "                            raise ValueError(__size_error_msg__)\n",
    "                        # dim == 0, we duplicate part of the embeddings x by using the edge_index[idx]\n",
    "#                         print('Inside the propagate, edge_index[idx]: \\n', edge_index[idx].shape, '\\n', edge_index[idx])\n",
    "                        tmp = torch.index_select(tmp, dim, edge_index[idx])\n",
    "                        message_args.append(tmp)   # here we append x from the kwargs\n",
    "            else:\n",
    "                message_args.append(kwargs.get(arg, None))   # here we append norm\n",
    "        \n",
    "#         message_args are: x_j, norm \n",
    "#         size:  [8, None] \n",
    "#         kwargs:  dict_keys(['x', 'norm']) \n",
    "#         special keys:  []\n",
    "        \n",
    "        size[0] = size[1] if size[0] is None else size[0]\n",
    "        size[1] = size[0] if size[1] is None else size[1]\n",
    "\n",
    "        kwargs['edge_index'] = edge_index\n",
    "        kwargs['size'] = size\n",
    "        \n",
    "        # for now self.__special_args__ is empty\n",
    "        for (idx, arg) in self.__special_args__:\n",
    "            if arg[-2:] in ij.keys():\n",
    "                # here we will change the content of x (features)\n",
    "                # features will be corresponds to edge_index\n",
    "                message_args.insert(idx, kwargs[arg[:-2]][ij[arg[-2:]]])\n",
    "            else:\n",
    "                message_args.insert(idx, kwargs[arg])\n",
    "\n",
    "        update_args = [kwargs[arg] for arg in self.__update_args__]\n",
    "#         message_args are: x_j, norm \n",
    "        out = self.message(*message_args)\n",
    "        # here i = 1, edge_index is the target endpoint of an edge, size[i] is the size of target endpoints\n",
    "        out = scatter_(self.aggr, out, edge_index[i], dim_size=size[i])\n",
    "        out = self.update(out, *update_args)\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j):  # pragma: no cover\n",
    "        r\"\"\"Constructs messages in analogy to :math:`\\phi_{\\mathbf{\\Theta}}`\n",
    "        for each edge in :math:`(i,j) \\in \\mathcal{E}`.\n",
    "        Can take any argument which was initially passed to :meth:`propagate`.\n",
    "        In addition, features can be lifted to the source node :math:`i` and\n",
    "        target node :math:`j` by appending :obj:`_i` or :obj:`_j` to the\n",
    "        variable name, *.e.g.* :obj:`x_i` and :obj:`x_j`.\"\"\"\n",
    "\n",
    "        return x_j\n",
    "\n",
    "    def update(self, aggr_out):  # pragma: no cover\n",
    "        r\"\"\"Updates node embeddings in analogy to\n",
    "        :math:`\\gamma_{\\mathbf{\\Theta}}` for each node\n",
    "        :math:`i \\in \\mathcal{V}`.\n",
    "        Takes in the output of aggregation as first argument and any argument\n",
    "        which was initially passed to :meth:`propagate`.\"\"\"\n",
    "\n",
    "        return aggr_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "from torch.nn import Parameter\n",
    "from torch_scatter import scatter_add\n",
    "# from torch_geometric.nn import MessagePassing\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import add_remaining_self_loops\n",
    "\n",
    "### ================== Definition of custom GCN\n",
    "\n",
    "def glorot(tensor):\n",
    "    if tensor is not None:\n",
    "        stdv = math.sqrt(6.0 / (tensor.size(-2) + tensor.size(-1)))\n",
    "        tensor.data.uniform_(-stdv, stdv)\n",
    "#         tensor.data.fill_(1.0)   # trivial example\n",
    "        \n",
    "def zeros(tensor):\n",
    "    if tensor is not None:\n",
    "        tensor.data.fill_(0)\n",
    "\n",
    "class custom_GCNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels, improved=False, cached=False,\n",
    "                 bias=True, **kwargs):\n",
    "        super().__init__(aggr='add', **kwargs)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.improved = improved\n",
    "        self.cached = cached\n",
    "\n",
    "        self.weight = Parameter(torch.Tensor(in_channels, out_channels))\n",
    "\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.Tensor(out_channels))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        glorot(self.weight)\n",
    "        zeros(self.bias)\n",
    "        self.cached_result = None\n",
    "        self.cached_num_edges = None\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def norm(edge_index, num_nodes, edge_weight=None, improved=False, dtype=None):\n",
    "        \n",
    "        if edge_weight is None:\n",
    "            edge_weight = torch.ones((edge_index.size(1), ), dtype=dtype, device=edge_index.device)\n",
    "        \n",
    "        fill_value = 1 if not improved else 2\n",
    "        \n",
    "        edge_index, edge_weight = add_remaining_self_loops(\n",
    "            edge_index, edge_weight, fill_value, num_nodes)\n",
    "        \n",
    "        row, col = edge_index   \n",
    "        # row includes the starting points of the edges  (first row of edge_index)\n",
    "        # col includes the ending points of the edges   (second row of edge_index)\n",
    "\n",
    "        deg = scatter_add(edge_weight, row, dim=0, dim_size=num_nodes)\n",
    "        # row records the source nodes, which is the index we are trying to add\n",
    "        # deg will record the out-degree of each node of x_i in all edges (x_i, x_j) including self_loops\n",
    "        \n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "        normalized_edge_weight = deg_inv_sqrt[row] * edge_weight * deg_inv_sqrt[col]\n",
    "        \n",
    "#         print('whole GCN training normalized_edge_weight: \\n', normalized_edge_weight)\n",
    "        return edge_index, normalized_edge_weight\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight = None):\n",
    "        \"\"\"\"\"\"\n",
    "#         print('current weight is: ')\n",
    "#         print(self.weight)\n",
    "#         print('current bias is: ')\n",
    "#         print(self.bias)\n",
    "        \n",
    "        x = torch.matmul(x, self.weight)   # update x (embeddings)\n",
    "        \n",
    "#         print('inside custom_GCN, edge_index: ', edge_index.shape, '\\n', edge_index)\n",
    "        res = self.propagate(edge_index, x = x, norm = edge_weight)\n",
    "        return res\n",
    "\n",
    "    # self is the first parameter of the message func\n",
    "    def message(self, x_j, norm):\n",
    "        # in source code of the MessagePassing:\n",
    "#         self.__message_args__ = getargspec(self.message)[0][1:]  : will be initialized as [x_j, norm]\n",
    "        \n",
    "        # view is to reshape the tensor, here make it only a single column\n",
    "        # use the normalized weights multiplied by the feature of the target nodes\n",
    "        '''\n",
    "        For each of extended edge_index:(x_i, x_j), assume there is N such edges\n",
    "        x_j of shape (N, k) , assume there is k features, value along each row are the same\n",
    "        norm of shape (1, m), assume there is m edges (including self loops), 1-D tensor\n",
    "        '''\n",
    "#         print('inside the message custom_GCN: norm \\n', norm.shape, '\\n', norm)\n",
    "#         print('inside the message custom_GCN: x_j \\n', x_j.shape, '\\n', x_j)\n",
    "        res = norm.view(-1, 1) * x_j  # use the element wise multiplication\n",
    "        return res\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        # update the embeddings of each node\n",
    "        if self.bias is not None:\n",
    "            aggr_out = aggr_out + self.bias\n",
    "        return aggr_out\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}({}, {})'.format(self.__class__.__name__, self.in_channels,\n",
    "                                   self.out_channels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ====================== Establish a GCN based model ========================\n",
    "class ListModule(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Abstract list layer class.\n",
    "    \"\"\"\n",
    "    def __init__(self, *args):\n",
    "        \"\"\"\n",
    "        Module initializing.\n",
    "        \"\"\"\n",
    "        super(ListModule, self).__init__()\n",
    "        idx = 0\n",
    "        for module in args:\n",
    "            self.add_module(str(idx), module)\n",
    "            idx += 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Getting the indexed layer.\n",
    "        \"\"\"\n",
    "        if idx < 0 or idx >= len(self._modules):\n",
    "            raise IndexError('index {} is out of range'.format(idx))\n",
    "        it = iter(self._modules.values())\n",
    "        for i in range(idx):\n",
    "            next(it)\n",
    "        return next(it)\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "        Iterating on the layers.\n",
    "        \"\"\"\n",
    "        return iter(self._modules.values())\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Number of layers.\n",
    "        \"\"\"\n",
    "        return len(self._modules)\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, input_layers = [16, 16], dropout=0.3):\n",
    "        \"\"\"\n",
    "        input layers: list of integers\n",
    "        dropout: probability of droping out \n",
    "        \"\"\"\n",
    "        super(Net, self).__init__()\n",
    "        # one trivial example\n",
    "#         self.conv1 = custom_GCNConv(in_channels, out_channels)\n",
    "#         self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.input_layers = input_layers\n",
    "        self.dropout = dropout\n",
    "        self.setup_layers()\n",
    "\n",
    "    def setup_layers(self):\n",
    "        \"\"\"\n",
    "        Creating the layes based on the args.\n",
    "        \"\"\"\n",
    "        self.layers = []\n",
    "        self.input_layers = [self.in_channels] + self.input_layers + [self.out_channels]\n",
    "        for i, _ in enumerate(self.input_layers[:-1]):\n",
    "            self.layers.append(custom_GCNConv(self.input_layers[i],self.input_layers[i+1]))\n",
    "        self.layers = ListModule(*self.layers)\n",
    "\n",
    "    # change the dropout positions: \n",
    "    def forward(self, edge_index, features, edge_weights = None):\n",
    "        if len(self.layers) > 1:\n",
    "            for i in range(len(self.layers)-1):\n",
    "                features = F.relu(self.layers[i](features, edge_index, edge_weights))\n",
    "#                 if i>0:\n",
    "                features = F.dropout(features, p = self.dropout, training = self.training)\n",
    "                    \n",
    "            features = self.layers[len(self.layers)-1](features, edge_index, edge_weights)\n",
    "        else:\n",
    "            features = self.layers[0](features, edge_index, edge_weights)    # for a single layer case\n",
    "\n",
    "        predictions = F.log_softmax(features, dim=1)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partition GCN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partition method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import metis\n",
    "import random\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import chain\n",
    "\n",
    "class ClusteringMachine(object):\n",
    "    \"\"\"\n",
    "    Clustering the graph, feature set and label. Performed on the CPU side\n",
    "    \"\"\"\n",
    "    def __init__(self, edge_index, features, label):\n",
    "        \"\"\"\n",
    "        :param edge_index: COO format of the edge indices.\n",
    "        :param features: Feature matrix (ndarray).\n",
    "        :param label: label vector (ndarray).\n",
    "        \"\"\"\n",
    "        tmp = edge_index.t().numpy().tolist()\n",
    "        self.graph = nx.from_edgelist(tmp)\n",
    "        self.features = features\n",
    "        self.label = label\n",
    "        self._set_sizes()\n",
    "        self.edge_index = edge_index\n",
    "        # this will get the edge weights in a complete graph\n",
    "        self.get_edge_weight(self.edge_index, self.node_count)\n",
    "\n",
    "    def _set_sizes(self):\n",
    "        \"\"\"\n",
    "        Setting the feature and class count.\n",
    "        \"\"\"\n",
    "        self.node_count = self.features.shape[0]\n",
    "        self.feature_count = self.features.shape[1]    # features all always in the columns\n",
    "        self.label_count = len(np.unique(self.label.numpy()) )\n",
    "        \n",
    "    def get_edge_weight(self, edge_index, num_nodes, edge_weight=None, improved=False, dtype=None):\n",
    "        \n",
    "        if edge_weight is None:\n",
    "            edge_weight = torch.ones((edge_index.size(1), ), dtype=dtype, device=edge_index.device)\n",
    "        \n",
    "        fill_value = 1 if not improved else 2\n",
    "        # there are num_nodes self-loop edges added after the edge_index\n",
    "        edge_index, edge_weight = add_remaining_self_loops(edge_index, edge_weight, fill_value, num_nodes)\n",
    "        \n",
    "        row, col = edge_index   \n",
    "        # row includes the starting points of the edges  (first row of edge_index)\n",
    "        # col includes the ending points of the edges   (second row of edge_index)\n",
    "\n",
    "        deg = scatter_add(edge_weight, row, dim=0, dim_size=num_nodes)\n",
    "        # row records the source nodes, which is the index we are trying to add\n",
    "        # deg will record the out-degree of each node of x_i in all edges (x_i, x_j) including self_loops\n",
    "        \n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "        normalized_edge_weight = deg_inv_sqrt[row] * edge_weight * deg_inv_sqrt[col]\n",
    "        self.edge_index_global_self_loops = edge_index\n",
    "        # transfer from tensor to the numpy to construct the dict for the edge_weights\n",
    "        edge_index = edge_index.t().numpy()\n",
    "        normalized_edge_weight = normalized_edge_weight.numpy()\n",
    "        num_edge, _ = edge_index.shape\n",
    "        # this info can also be stored as matrix considering the memory, depends whether the matrix is sparse or not\n",
    "        self.edge_weight_global_dict = {(edge_index[i][0], edge_index[i][1]) : normalized_edge_weight[i] for i in range(num_edge)}\n",
    "        \n",
    "#         print('after adding self-loops, edge_index is', edge_index)\n",
    "        self.edge_weight_global = [ self.edge_weight_global_dict[(edge[0], edge[1])] for edge in edge_index ]\n",
    "#         print('a list of the global weights : \\n', self.edge_weight_global )\n",
    "    \n",
    "    # 1) first use different clustering method, then split each cluster into train, test and validation nodes, split edges\n",
    "    def split_cluster_nodes_edges(self, test_ratio, validation_ratio, partition_num = 2):\n",
    "        \"\"\"\n",
    "        Decomposing the graph, partitioning the features and label, creating Torch arrays.\n",
    "        \"\"\"\n",
    "        # to keep the edge weights of the original whole graph:\n",
    "        self.train_clusters, self.sg_nodes_global = self.metis_clustering(self.graph, partition_num)\n",
    "#         self.train_clusters, self.sg_nodes_global = self.random_clustering(list(self.graph.nodes()), partition_num)\n",
    "        self.valid_clusters = self.train_clusters\n",
    "        \n",
    "        relative_test_ratio = (test_ratio) / (1 - validation_ratio)\n",
    "        self.sg_subgraph = {}\n",
    "        \n",
    "        self.sg_model_nodes_global = {}\n",
    "        self.sg_validation_nodes_global = {}\n",
    "        self.sg_train_nodes_global = {}\n",
    "        self.sg_test_nodes_global = {}\n",
    "        \n",
    "        # keep the info of each cluster:\n",
    "        self.info_isolate_cluster_size = {}\n",
    "        self.info_model_cluster_size = {}\n",
    "        self.info_validation_cluster_size = {}\n",
    "        self.info_train_cluster_size = {}\n",
    "        self.info_test_cluster_size = {}\n",
    "        \n",
    "        for cluster in self.train_clusters:\n",
    "            self.sg_model_nodes_global[cluster], self.sg_validation_nodes_global[cluster] = train_test_split(self.sg_nodes_global[cluster], test_size = validation_ratio)\n",
    "            self.sg_train_nodes_global[cluster], self.sg_test_nodes_global[cluster] = train_test_split(self.sg_model_nodes_global[cluster], test_size = relative_test_ratio)\n",
    "            \n",
    "            # record the information of each cluster:\n",
    "            self.info_isolate_cluster_size[cluster] = len(self.sg_nodes_global[cluster])\n",
    "            self.info_model_cluster_size[cluster] = len(self.sg_model_nodes_global[cluster])\n",
    "            self.info_validation_cluster_size[cluster] = len(self.sg_validation_nodes_global[cluster])\n",
    "            \n",
    "            self.info_train_cluster_size[cluster] = len(self.sg_train_nodes_global[cluster])\n",
    "            self.info_test_cluster_size[cluster] = len(self.sg_test_nodes_global[cluster])\n",
    "    \n",
    "    \n",
    "    # 2) first assign train, test, validation nodes, split edges; this is based on the assumption that the clustering is no longer that important\n",
    "    def split_whole_nodes_edges_then_cluster(self, test_ratio, validation_ratio):\n",
    "        \"\"\"\n",
    "            First create train-test splits, then split train and validation into different batch seeds\n",
    "            Input:  \n",
    "                1) ratio of test, validation\n",
    "                2) partition number of train nodes, test nodes, validation nodes\n",
    "            Output:\n",
    "                1) sg_validation_nodes_global, sg_train_nodes_global, sg_test_nodes_global\n",
    "        \"\"\"\n",
    "        relative_test_ratio = (test_ratio) / (1 - validation_ratio)\n",
    "        \n",
    "        # first divide the nodes for the whole graph, result will always be a list of lists \n",
    "        model_nodes_global, self.valid_nodes_global = train_test_split(list(self.graph.nodes()), test_size = validation_ratio)\n",
    "        self.train_nodes_global, self.test_nodes_global = train_test_split(model_nodes_global, test_size = relative_test_ratio)\n",
    "        \n",
    "    # just allocate each node to arandom cluster, store the membership inside each dict\n",
    "    def random_clustering(self, target_nodes, partition_num):\n",
    "        \"\"\"\n",
    "            Random clustering the nodes.\n",
    "            Input: \n",
    "                1) target_nodes: list of node \n",
    "                2) number of partition to be generated\n",
    "            Output: \n",
    "                1) cluster idx\n",
    "                2) membership of each node\n",
    "                3) list of generated clusters, each cluster includes a bunch of global node idx\n",
    "        \"\"\"\n",
    "        # randomly divide into two clusters\n",
    "        nodes_order = [node for node in target_nodes]\n",
    "        random.shuffle(nodes_order)\n",
    "        n = (len(nodes_order) + partition_num - 1) // partition_num\n",
    "        partition_list = [nodes_order[i * n:(i + 1) * n] for i in range(partition_num)]\n",
    "#         cluster_membership = {node : i for i, node_list in enumerate(partition_list) for node in node_list}\n",
    "        cluster_nodes_global = {i : node_list for i, node_list in enumerate(partition_list)}\n",
    "        \n",
    "        return cluster_nodes_global\n",
    "\n",
    "    def metis_clustering(self, target_graph, partition_num):\n",
    "        \"\"\"\n",
    "        Clustering the graph with Metis. For details see:\n",
    "        Input: \n",
    "            1) target graph\n",
    "            2) number of parts\n",
    "        Output:\n",
    "            1) index of all the clusters\n",
    "            2) membership of each node\n",
    "        \"\"\"\n",
    "        (st, parts) = metis.part_graph(target_graph, partition_num)\n",
    "        clusters = list(set(parts))\n",
    "        cluster_nodes_global = defaultdict(list)\n",
    "        for node, cluster_id in enumerate(parts):\n",
    "            cluster_nodes_global[cluster_id].append(node)\n",
    "        return clusters, cluster_nodes_global\n",
    "\n",
    "\n",
    "    def general_isolate_clustering(self, k):\n",
    "        \"\"\"\n",
    "            Still find the train batch, but cannot exceed the scope of the isolated clustering\n",
    "        \"\"\"\n",
    "        self.sg_mini_train_edges_global = {}\n",
    "        self.sg_mini_train_nodes_global = {}\n",
    "        \n",
    "        self.sg_mini_train_nodes_local = {}\n",
    "        self.sg_mini_train_edges_local = {}\n",
    "        self.sg_mini_train_edge_weight_local = {}\n",
    "        self.sg_mini_train_features = {}\n",
    "        self.sg_mini_train_labels = {}\n",
    "        \n",
    "        self.neighbor = defaultdict(dict)   # keep layer nodes of each layer\n",
    "        self.train_accum_neighbor = defaultdict(set)\n",
    "        \n",
    "        self.info_train_batch_size = {}\n",
    "        self.sg_subgraph = {}\n",
    "        \n",
    "        for cluster in self.train_clusters:\n",
    "            self.sg_subgraph[cluster] = self.graph.subgraph(self.sg_nodes_global[cluster]) # for later use of generating local neighbor\n",
    "            self.neighbor[cluster] = {0 : set(self.sg_train_nodes_global[cluster])}\n",
    "            for layer in range(k):\n",
    "                # first accumulate last layer\n",
    "                self.train_accum_neighbor[cluster] |= self.neighbor[cluster][layer]\n",
    "                tmp_level = set()\n",
    "                for node in self.neighbor[cluster][layer]:\n",
    "                    tmp_level |= set(self.sg_subgraph[cluster].neighbors(node))    # can only get the neighbor of the clustered: sg_subgraph[cluster], never beyond it\n",
    "                # add the new layer of neighbors\n",
    "                self.neighbor[cluster][layer+1] = tmp_level - self.train_accum_neighbor[cluster]\n",
    "#                 print('layer ' + str(layer + 1) + ' : ', self.neighbor[cluster][layer+1])\n",
    "            # the most outside layer: kth layer will be added:\n",
    "            self.train_accum_neighbor[cluster] |= self.neighbor[cluster][k]\n",
    "            batch_subgraph = self.sg_subgraph[cluster].subgraph(self.train_accum_neighbor[cluster])\n",
    "            \n",
    "            \n",
    "            # first select all the overlapping nodes of the train nodes\n",
    "            self.sg_mini_train_edges_global[cluster] = {edge for edge in batch_subgraph.edges()}\n",
    "            self.sg_mini_train_nodes_global[cluster] = sorted(node for node in batch_subgraph.nodes())\n",
    "            \n",
    "            \n",
    "            mini_mapper = {node: i for i, node in enumerate(self.sg_mini_train_nodes_global[cluster])}\n",
    "            sg_node_index_local = sorted(mini_mapper.values())\n",
    "            \n",
    "            self.sg_mini_train_edges_local[cluster] = \\\n",
    "                           [ [ mini_mapper[edge[0]], mini_mapper[edge[1]] ] for edge in self.sg_mini_train_edges_global[cluster] ] + \\\n",
    "                           [ [ mini_mapper[edge[1]], mini_mapper[edge[0]] ] for edge in self.sg_mini_train_edges_global[cluster] ] + \\\n",
    "                           [ [i, i] for i in sg_node_index_local ]  \n",
    "            \n",
    "            self.sg_mini_train_edge_weight_local[cluster] = \\\n",
    "                            [ self.edge_weight_global_dict[(edge[0], edge[1])] for edge in self.sg_mini_train_edges_global[cluster] ] + \\\n",
    "                            [ self.edge_weight_global_dict[(edge[1], edge[0])] for edge in self.sg_mini_train_edges_global[cluster] ] + \\\n",
    "                            [ self.edge_weight_global_dict[(i, i)] for i in self.sg_mini_train_nodes_global[cluster] ]\n",
    "            \n",
    "#             print('train nodes global for the cluster # ' + str(cluster), self.sg_train_nodes_global[cluster])\n",
    "            self.sg_mini_train_nodes_local[cluster] = [ mini_mapper[global_idx] for global_idx in self.sg_train_nodes_global[cluster] ]\n",
    "            \n",
    "            self.sg_mini_train_features[cluster] = self.features[self.sg_mini_train_nodes_global[cluster],:]\n",
    "            self.sg_mini_train_labels[cluster] = self.label[self.sg_mini_train_nodes_global[cluster]]\n",
    "            \n",
    "            # record information \n",
    "            self.info_train_batch_size[cluster] = len(self.sg_mini_train_nodes_global[cluster])\n",
    "        \n",
    "        # at last, out of all the cluster loop do the data transfer\n",
    "        self.transfer_edges_and_nodes()\n",
    "        \n",
    "        for cluster in self.sg_mini_train_edges_local.keys():\n",
    "            self.sg_mini_train_edges_local[cluster] = torch.LongTensor(self.sg_mini_train_edges_local[cluster]).t()\n",
    "            self.sg_mini_train_edge_weight_local[cluster] = torch.FloatTensor(self.sg_mini_train_edge_weight_local[cluster])\n",
    "            self.sg_mini_train_nodes_local[cluster] = torch.LongTensor(self.sg_mini_train_nodes_local[cluster])\n",
    "            self.sg_mini_train_features[cluster] = torch.FloatTensor(self.sg_mini_train_features[cluster])\n",
    "            self.sg_mini_train_labels[cluster] = torch.LongTensor(self.sg_mini_train_labels[cluster])\n",
    "        \n",
    "    # select the training nodes as the mini-batch for each cluster\n",
    "    def mini_batch_sample(self, target_seed, k, frac = 1):\n",
    "        \"\"\"\n",
    "            This function is to generate the neighbors of the seed (either train nodes or validation nodes)\n",
    "            params: cluster index, number of layer k, fraction of sampling from each neighbor layer\n",
    "            input: \n",
    "                1) target_seed: this is the 0 layer inside self.neighbor\n",
    "            output:\n",
    "                1) neighbor: nodes global idx inside each layer of the batch\n",
    "                2) accum_neighbor: accumulating neighbors , i.e. the final batch nodes\n",
    "        \"\"\"\n",
    "        accum_neighbor = defaultdict(set)\n",
    "        for cluster in target_seed.keys():\n",
    "            neighbor = set(target_seed[cluster])  # first layer of the neighbor nodes of each cluster\n",
    "            for layer in range(k):\n",
    "                # first accumulate last layer\n",
    "                accum_neighbor[cluster] |= neighbor\n",
    "                tmp_level = set()\n",
    "                for node in neighbor:\n",
    "                    tmp_level |= set(self.graph.neighbors(node))  # the key here we are using self.graph, extract neighbor from the whole graph\n",
    "                # add the new layer of neighbors\n",
    "                tmp_level -= accum_neighbor[cluster]\n",
    "                # each layer will only contains partial nodes from the previous layer\n",
    "                neighbor = set(random.sample(tmp_level, int(len(tmp_level) * frac) ) ) if 0 < frac < 1 else tmp_level\n",
    "    #                 print('layer ' + str(layer + 1) + ' : ', self.neighbor[cluster][layer+1])\n",
    "            # the most outside layer: kth layer will be added:\n",
    "            accum_neighbor[cluster] |= neighbor\n",
    "        return accum_neighbor\n",
    "        \n",
    "    def mini_batch_generate(self, batch_file_folder, target_seed, k, fraction = 1.0, data_type = 'train'):\n",
    "        \"\"\"\n",
    "            create the mini-batch focused on the train nodes only, include a total of k layers of neighbors of the original training nodes\n",
    "            k: number of layers of neighbors for each training node\n",
    "            fraction: fraction of neighbor nodes in each layer to be considered\n",
    "            Input:\n",
    "                1) target_seed: global ids of the nodes for seed to generate the batch\n",
    "                    usually one of (train_global, test_global_, validation_global)\n",
    "            Output: all tensors which are gonna be used in the train, forward procedure\n",
    "                local:\n",
    "                    1) sg_mini_edges_local\n",
    "                    2) self.sg_mini_train_edge_weight_local\n",
    "                    3) self.sg_mini_train_nodes_local\n",
    "                    4) self.sg_mini_train_features\n",
    "                    5) self.sg_mini_train_labels\n",
    "            \n",
    "        \"\"\"\n",
    "        # these are currently believed to be the main memory cost, storing all overlapping batch information\n",
    "        # instead we store all the information inside one list to be stored in a pickle file as out-of-core mini-batch\n",
    "        \n",
    "        info_batch_size = {}\n",
    "                \n",
    "        accum_neighbor = self.mini_batch_sample(target_seed, k, frac = fraction)\n",
    "        \n",
    "        for cluster in target_seed.keys():\n",
    "            batch_subgraph = self.graph.subgraph(accum_neighbor[cluster])\n",
    "            \n",
    "             # first select all the overlapping nodes of the train nodes\n",
    "            mini_nodes_global = sorted(node for node in batch_subgraph.nodes())\n",
    "            \n",
    "            # store the global edges\n",
    "            mini_edges_global = {edge for edge in batch_subgraph.edges()}\n",
    "            \n",
    "            \n",
    "            mini_mapper = {node: i for i, node in enumerate(mini_nodes_global)}\n",
    "            \n",
    "            # store local index of batch nodes\n",
    "            mini_nodes_local = [ mini_mapper[global_idx] for global_idx in target_seed[cluster] ]\n",
    "            \n",
    "            # store local index of batch edges\n",
    "            mini_edges_local = \\\n",
    "                           [ [ mini_mapper[edge[0]], mini_mapper[edge[1]] ] for edge in mini_edges_global ] + \\\n",
    "                           [ [ mini_mapper[edge[1]], mini_mapper[edge[0]] ] for edge in mini_edges_global ] + \\\n",
    "                           [ [i, i] for i in sorted(mini_mapper.values()) ]  \n",
    "            \n",
    "            \n",
    "            # store local edge weights\n",
    "            mini_edge_weight_local = \\\n",
    "                            [ self.edge_weight_global_dict[(edge[0], edge[1])] for edge in mini_edges_global ] + \\\n",
    "                            [ self.edge_weight_global_dict[(edge[1], edge[0])] for edge in mini_edges_global ] + \\\n",
    "                            [ self.edge_weight_global_dict[(i, i)] for i in mini_nodes_global ]\n",
    "            \n",
    "            \n",
    "            # store local features and lables\n",
    "            mini_features = self.features[mini_nodes_global,:]\n",
    "            mini_labels = self.label[mini_nodes_global]\n",
    "            \n",
    "            # record information \n",
    "            info_batch_size[cluster] = len(mini_nodes_global)\n",
    "            \n",
    "            mini_nodes_local = torch.LongTensor(mini_nodes_local)\n",
    "            mini_edges_local = torch.LongTensor(mini_edges_local).t()\n",
    "            mini_edge_weight_local = torch.FloatTensor(mini_edge_weight_local)\n",
    "            mini_features = torch.FloatTensor(mini_features)\n",
    "            mini_labels = torch.LongTensor(mini_labels)\n",
    "            \n",
    "            minibatch_data = [mini_nodes_local, mini_edges_local, mini_edge_weight_local, mini_features, mini_labels]\n",
    "            \n",
    "            batch_file_type_folder = batch_file_folder + data_type + '/'\n",
    "            batch_file_name = batch_file_type_folder + 'batch_' + str(cluster)\n",
    "            \n",
    "            os.makedirs(os.path.dirname(batch_file_name), exist_ok=True)\n",
    "            with open(batch_file_name, \"wb\") as fp:\n",
    "                pickle.dump(minibatch_data, fp)\n",
    "                \n",
    "        return info_batch_size\n",
    "        \n",
    "\n",
    "    def mini_batch_train_clustering(self, batch_file_folder, k, fraction = 1.0, train_batch_num = 2):\n",
    "        # special extreme case, each train node in one batch seed\n",
    "#         self.sg_train_nodes_global = self.random_clustering(train_nodes_global, len(train_nodes_global))\n",
    "        sg_train_nodes_global = self.random_clustering(self.train_nodes_global, train_batch_num)\n",
    "        \n",
    "        self.info_train_batch_size = self.mini_batch_generate(batch_file_folder, sg_train_nodes_global, k, fraction = 1.0, data_type = 'train')\n",
    "        self.info_train_cluster_size = {key : len(val) for key, val in sg_train_nodes_global.items()}\n",
    "        \n",
    "    def mini_batch_validation_clustering(self, batch_file_folder, k, fraction = 1.0, valid_batch_num = 2):\n",
    "        \n",
    "        sg_validation_nodes_global = self.random_clustering(self.valid_nodes_global, valid_batch_num)\n",
    "        self.info_validation_batch_size = self.mini_batch_generate(batch_file_folder, sg_validation_nodes_global, k, fraction = 1.0, data_type = 'validation')\n",
    "        \n",
    "        self.info_validation_cluster_size = {key : len(val) for key, val in sg_validation_nodes_global.items()}\n",
    "    \n",
    "    def mini_batch_test_clustering(self, batch_file_folder, k, fraction = 1.0, test_batch_num = 2):\n",
    "        \n",
    "        sg_test_nodes_global = self.random_clustering(self.test_nodes_global, test_batch_num)\n",
    "        self.info_test_batch_size = self.mini_batch_generate(sg_test_nodes_global, k, fraction = 1.0)\n",
    "        self.info_test_cluster_size = {key : len(val) for key, val in sg_test_nodes_global.items()}\n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partition Graph with trainiing and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Custom_GCN_layer import Net\n",
    "import time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class ClusterGCNTrainer_mini_Train(object):\n",
    "    \"\"\"\n",
    "    Training a ClusterGCN.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_folder, in_channels, out_channels, input_layers = [32, 16], dropout=0.3):\n",
    "        \"\"\"\n",
    "        :param in_channels, out_channels: input and output feature dimension\n",
    "        :param clustering_machine:\n",
    "        \"\"\"  \n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.data_folder = data_folder\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.input_layers = input_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.create_model()\n",
    "\n",
    "    def create_model(self):\n",
    "        \"\"\"\n",
    "        Creating a StackedGCN and transferring to CPU/GPU.\n",
    "        \"\"\"\n",
    "#         print('used layers are: ', str(self.input_layers))\n",
    "        self.model = Net(self.in_channels, self.out_channels, input_layers = self.input_layers, dropout = self.dropout)\n",
    "        self.model = self.model.to(self.device)\n",
    "    \n",
    "    # call the forward function batch by batch\n",
    "    def do_forward_pass(self, tr_train_nodes, tr_edges, tr_edge_weights, tr_features, tr_target):\n",
    "        \"\"\"\n",
    "        Making a forward pass with data from a given partition.\n",
    "        :param cluster: Cluster index.\n",
    "        :return average_loss: Average loss on the cluster.\n",
    "        :return node_count: Number of nodes.\n",
    "        \"\"\"\n",
    "        \n",
    "        '''Target and features are one-one mapping'''\n",
    "        # calculate the probabilites from log_sofmax\n",
    "        predictions = self.model(tr_edges, tr_features, tr_edge_weights)\n",
    "        \n",
    "        ave_loss = torch.nn.functional.nll_loss(predictions[tr_train_nodes], tr_target[tr_train_nodes])\n",
    "        node_count = tr_train_nodes.shape[0]\n",
    "\n",
    "        # for each cluster keep track of the counts of the nodes\n",
    "        return ave_loss, node_count\n",
    "\n",
    "\n",
    "    def update_average_loss(self, batch_average_loss, node_count, isolate = True):\n",
    "        \"\"\"\n",
    "        Updating the average loss in the epoch.\n",
    "        :param batch_average_loss: Loss of the cluster. \n",
    "        :param node_count: Number of nodes in currently processed cluster.\n",
    "        :return average_loss: Average loss in the epoch.\n",
    "        \"\"\"\n",
    "        self.accumulated_training_loss = self.accumulated_training_loss + batch_average_loss.item() * node_count\n",
    "        if isolate:\n",
    "            self.node_count_seen = self.node_count_seen + node_count\n",
    "        average_loss = self.accumulated_training_loss / self.node_count_seen\n",
    "        return average_loss\n",
    "\n",
    "    # iterate through epoch and also the clusters\n",
    "    def train_investigate_F1(self, epoch_num=10, learning_rate=0.01, weight_decay = 0.01, mini_epoch_num = 1, output_period = 10, train_batch_num = 2, valid_batch_num = 2):\n",
    "        \"\"\"\n",
    "            *** Periodically output the F1 score during training. After certain number of epochs ***\n",
    "            epoch_num:  number of total training epoch number\n",
    "            learning rate: learning rate during training\n",
    "            weight_decay:  decay coefficients for the regularization\n",
    "            mini_epoch_num:  number of epochs of repeating training after loading data on the GPU\n",
    "            output_period:  number of epochs after which output the F1 and accuray to investigate the model refining process\n",
    "        \"\"\"\n",
    "        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        self.model.train()   #   set into train mode, only effective for certain modules such as dropout and batchNorm\n",
    "        self.record_ave_training_loss = []\n",
    "        self.time_train_load_data = 0\n",
    "        \n",
    "        epoch_partition = epoch_num // mini_epoch_num\n",
    "        investigate_f1 = {}\n",
    "        investigate_accuracy = {}\n",
    "        \n",
    "        t0 = time.time()\n",
    "        train_clusters = list(range(train_batch_num))\n",
    "        for epoch_part in range(epoch_partition):\n",
    "#             For test purpose, we let the clusters to follow specific order\n",
    "            random.shuffle(train_clusters)\n",
    "            self.node_count_seen = 0\n",
    "            self.accumulated_training_loss = 0\n",
    "            for cluster in train_clusters:\n",
    "                # for each batch, we load once and train it for multiple epochs:\n",
    "                # read in the train data from the pickle files\n",
    "                batch_file_name = self.data_folder + 'train/batch_' + str(cluster)\n",
    "                with open(batch_file_name, \"rb\") as fp:\n",
    "                    minibatch_data_train = pickle.load(fp)\n",
    "                \n",
    "                tr_train_nodes, tr_edges, tr_edge_weights, tr_features, tr_target = minibatch_data_train\n",
    "                \n",
    "                t1 = time.time()\n",
    "                tr_train_nodes = tr_train_nodes.to(self.device)\n",
    "                tr_edges = tr_edges.to(self.device)\n",
    "                tr_edge_weights = tr_edge_weights.to(self.device)\n",
    "                tr_features = tr_features.to(self.device)\n",
    "                tr_target = tr_target.to(self.device)\n",
    "                \n",
    "                self.time_train_load_data += (time.time() - t1) * 1000\n",
    "                # train each batch for multiple epochs\n",
    "                for mini_epoch in range(mini_epoch_num):\n",
    "                    # record the current overall epoch index:\n",
    "                    real_epoch_num = 1 + mini_epoch + mini_epoch_num * epoch_part # real_epoch_num starts from 0, therefore we add 1\n",
    "                    \n",
    "                    self.optimizer.zero_grad()\n",
    "                    batch_ave_loss, node_count = self.do_forward_pass(tr_train_nodes, tr_edges, tr_edge_weights, tr_features, tr_target)\n",
    "                    batch_ave_loss.backward()\n",
    "                    self.optimizer.step()\n",
    "                    ave_loss = self.update_average_loss(batch_ave_loss, node_count)\n",
    "                    \n",
    "                    # at this point finish a single train duration: update the parameter and calcualte the loss function\n",
    "                    # periodically output the F1-score in the middle of the training process\n",
    "                    if real_epoch_num % output_period == 0:\n",
    "                        investigate_f1[real_epoch_num], investigate_accuracy[real_epoch_num] = self.batch_validate(valid_batch_num = valid_batch_num)\n",
    "                        self.model.train()    # reset to the train mode\n",
    "            \n",
    "            self.record_ave_training_loss.append(ave_loss)\n",
    "        # convert to ms\n",
    "        self.time_train_total = ((time.time() - t0) * 1000)\n",
    "        return investigate_f1, investigate_accuracy\n",
    "\n",
    "    # iterate through epoch and also the clusters\n",
    "    def train(self, epoch_num=10, learning_rate=0.01, weight_decay = 0.01, mini_epoch_num = 1, train_batch_num = 2):\n",
    "        \"\"\"\n",
    "            *** Training a model. ***\n",
    "            epoch_num:  number of total training epoch number\n",
    "            learning rate: learning rate during training\n",
    "            weight_decay:  decay coefficients for the regularization\n",
    "            mini_epoch_num:  number of epochs of repeating training after loading data on the GPU\n",
    "        \"\"\"\n",
    "        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        self.model.train()\n",
    "        self.record_ave_training_loss = []\n",
    "        self.time_train_load_data = 0\n",
    "        \n",
    "        epoch_partition = epoch_num // mini_epoch_num\n",
    "        t0 = time.time()\n",
    "        train_clusters = list(range(train_batch_num))\n",
    "        for epoch in range(epoch_partition):\n",
    "#             For test purpose, we let the clusters to follow specific order\n",
    "            random.shuffle(train_clusters)\n",
    "            self.node_count_seen = 0\n",
    "            self.accumulated_training_loss = 0\n",
    "            \n",
    "            for cluster in train_clusters:\n",
    "                # read in the train data from the pickle files\n",
    "                batch_file_name = self.data_folder + 'train/batch_' + str(cluster)\n",
    "                with open(batch_file_name, \"rb\") as fp:\n",
    "                    minibatch_data_train = pickle.load(fp)\n",
    "                \n",
    "                tr_train_nodes, tr_edges, tr_edge_weights, tr_features, tr_target = minibatch_data_train\n",
    "                \n",
    "                # for each cluster, we load once and train it for multiple epochs:\n",
    "                t1 = time.time()\n",
    "                tr_train_nodes = tr_train_nodes.to(self.device)\n",
    "                tr_edges = tr_edges.to(self.device)\n",
    "                tr_edge_weights = tr_edge_weights.to(self.device)\n",
    "                tr_features = tr_features.to(self.device)\n",
    "                tr_target = tr_target.to(self.device)\n",
    "                \n",
    "                \n",
    "                self.time_train_load_data += (time.time() - t1) * 1000\n",
    "                # train each batch for multiple epochs\n",
    "                for mini_epoch in range(mini_epoch_num):\n",
    "                    self.optimizer.zero_grad()\n",
    "                    batch_ave_loss, node_count = self.do_forward_pass(tr_train_nodes, tr_edges, tr_edge_weights, tr_features, tr_target)\n",
    "                    batch_ave_loss.backward()\n",
    "                    self.optimizer.step()\n",
    "                    ave_loss = self.update_average_loss(batch_ave_loss, node_count)\n",
    "            \n",
    "            self.record_ave_training_loss.append(ave_loss)\n",
    "        # convert to ms\n",
    "        self.time_train_total = ((time.time() - t0) * 1000)\n",
    "    \n",
    "\n",
    "    def do_batch_validation_prediction(self, valid_validation_nodes, valid_edges, valid_edge_weights, valid_features, valid_target):\n",
    "        \"\"\"\n",
    "        Scoring a cluster.\n",
    "        :param cluster: Cluster index.\n",
    "        :return prediction: Prediction matrix with probabilities.\n",
    "        :return target: Target vector.\n",
    "        \"\"\"\n",
    "        predictions = self.model(valid_edges, valid_features, valid_edge_weights)\n",
    "        return predictions[valid_validation_nodes], valid_target[valid_validation_nodes]\n",
    "\n",
    "    def batch_validate(self, valid_batch_num = 2):\n",
    "        \"\"\"\n",
    "        Scoring the test and printing the F-1 score.\n",
    "        \"\"\"\n",
    "        self.model.eval()   # set into test mode, only effective for certain modules such as dropout and batchNorm\n",
    "        \n",
    "        predictions = []\n",
    "        targets = []\n",
    "        valid_clusters = list(range(valid_batch_num))\n",
    "        for cluster in valid_clusters:\n",
    "            # read in the train data from the pickle files\n",
    "            batch_file_name = self.data_folder + 'validation/batch_' + str(cluster)\n",
    "            with open(batch_file_name, \"rb\") as fp:\n",
    "                minibatch_data_validation = pickle.load(fp)\n",
    "\n",
    "            valid_validation_nodes, valid_edges, valid_edge_weights, valid_features, valid_target = minibatch_data_validation\n",
    "            \n",
    "            valid_validation_nodes = valid_validation_nodes.to(self.device)\n",
    "            valid_edges = valid_edges.to(self.device)\n",
    "            valid_edge_weights = valid_edge_weights.to(self.device)\n",
    "            valid_features = valid_features.to(self.device)\n",
    "            valid_target = valid_target.to(self.device)\n",
    "            \n",
    "            \n",
    "            prediction, target = self.do_batch_validation_prediction(valid_validation_nodes, valid_edges, valid_edge_weights, valid_features, valid_target)\n",
    "\n",
    "            predictions.append(prediction.cpu().detach().numpy())\n",
    "            targets.append(target.cpu().detach().numpy())\n",
    "        \n",
    "        # concatenate all the ndarrays inside this list\n",
    "        targets = np.concatenate(targets)\n",
    "        # along axis:    axis == 1\n",
    "        predictions = np.concatenate(predictions).argmax(1)  # return the indices of maximum probability \n",
    "#         print('shape of the targets and predictions are: ', self.targets.shape, self.predictions.shape)\n",
    "        \n",
    "        f1 = f1_score(targets, predictions, average=\"micro\")\n",
    "        accuracy = accuracy_score(targets, predictions)\n",
    "#         print(\"\\nTest F-1 score: {:.4f}\".format(score))\n",
    "        return (f1, accuracy)\n",
    "\n",
    "# for cross-validation purpose: \n",
    "    def do_prediction(self, cluster):\n",
    "        \"\"\"\n",
    "        Scoring a cluster.\n",
    "        :param cluster: Cluster index.\n",
    "        :return prediction: Prediction matrix with probabilities.\n",
    "        :return target: Target vector.\n",
    "        \"\"\"\n",
    "        test_nodes = self.clustering_machine.sg_test_nodes_global[cluster].to(self.device)\n",
    "        prediction = self.model(self.edges, self.features, self.edge_weights)\n",
    "        \n",
    "        return prediction[test_nodes], self.label[test_nodes]\n",
    "    \n",
    "    def test(self):\n",
    "        \"\"\"\n",
    "        Scoring the test and printing the F-1 score.\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        self.predictions = []\n",
    "        self.targets = []\n",
    "        \n",
    "        self.edges = self.clustering_machine.edge_index_global_self_loops.to(self.device)\n",
    "        self.features = self.clustering_machine.features.to(self.device)\n",
    "        self.edge_weights = self.clustering_machine.edge_weight_global.to(self.device)\n",
    "        self.label = self.clustering_machine.label.to(self.device)\n",
    "        \n",
    "        for cluster in self.clustering_machine.test_clusters:\n",
    "            prediction, target = self.do_prediction(cluster)\n",
    "\n",
    "            self.predictions.append(prediction.cpu().detach().numpy())\n",
    "            self.targets.append(target.cpu().detach().numpy())\n",
    "        \n",
    "        # concatenate all the ndarrays inside this list\n",
    "        self.targets = np.concatenate(self.targets)\n",
    "        # along axis:    axis == 1\n",
    "        self.predictions = np.concatenate(self.predictions).argmax(1)  # return the indices of maximum probability \n",
    "#         print('shape of the targets and predictions are: ', self.targets.shape, self.predictions.shape)\n",
    "        \n",
    "        f1 = f1_score(self.targets, self.predictions, average=\"micro\")\n",
    "        accuracy = accuracy_score(self.targets, self.predictions)\n",
    "#         print(\"\\nTest F-1 score: {:.4f}\".format(score))\n",
    "        return (f1, accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UTILITY Check the mini clustering basic info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_clustering(clustering_machine, miniBatch = True):\n",
    "    whole_graph = clustering_machine.graph\n",
    "    validation_clusters_global = [ clustering_machine.sg_validation_nodes_global[cluster]\n",
    "                             for cluster in clustering_machine.train_clusters]\n",
    "\n",
    "    training_clusters_global = clustering_machine.sg_train_nodes_global\n",
    "\n",
    "    testing_clusters_global =  clustering_machine.sg_test_nodes_global\n",
    "\n",
    "    print('training nodes global ids are: \\n', training_clusters_global)\n",
    "    \n",
    "    print('testing global clusters are: ', testing_clusters_global)\n",
    "\n",
    "    print('validation global clusters are: ', validation_clusters_global)\n",
    "    \n",
    "    \n",
    "    isolate_clusters_global = [ clustering_machine.sg_nodes_global[cluster]\n",
    "                             for cluster in clustering_machine.train_clusters]\n",
    "    \n",
    "    modeling_clusters_global = [ clustering_machine.sg_model_nodes_global[cluster]\n",
    "                             for cluster in clustering_machine.train_clusters]\n",
    "    \n",
    "    print('node cluster memeber ship: ', clustering_machine.sg_nodes_global)\n",
    "    print('isolated clusters are: ', isolate_clusters_global)\n",
    "    print('modeling global clusters are: ', modeling_clusters_global)\n",
    "\n",
    "    subgraphs = [clustering_machine.graph.subgraph(isolate_clusters_global[cluster]) \\\n",
    "                                               for cluster in clustering_machine.train_clusters]\n",
    "    plt.subplot(331)\n",
    "    nx.draw(whole_graph, with_labels=True, font_weight='bold')\n",
    "    # 2) the two halves of the graph\n",
    "    plt.subplot(332)\n",
    "    nx.draw(subgraphs[0], with_labels=True, font_weight='bold')\n",
    "    plt.subplot(333)\n",
    "    nx.draw(subgraphs[1], with_labels=True, font_weight='bold')\n",
    "    \n",
    "    print('Info about the mini_batch only with training nodes: ')\n",
    "    sg_mini_train_edges_clusters_global = [  clustering_machine.sg_mini_train_edges_global[cluster] for cluster in clustering_machine.train_clusters]\n",
    "    sg_mini_train_nodes_clusters_global = clustering_machine.sg_mini_train_nodes_global\n",
    "    print('mini train edges of each cluster, global ids: ', sg_mini_train_edges_clusters_global)\n",
    "    print('mini train overlapping nodes global ids: ', sg_mini_train_nodes_clusters_global)\n",
    "\n",
    "    mini_train_subgraphs = [clustering_machine.graph.subgraph(clustering_machine.train_accum_neighbor[cluster]) \\\n",
    "                                           for cluster in clustering_machine.train_clusters]\n",
    "    plt.subplot(334)\n",
    "    nx.draw(mini_train_subgraphs[0], with_labels=True, font_weight='bold')\n",
    "    plt.subplot(335)\n",
    "    nx.draw(mini_train_subgraphs[1], with_labels=True, font_weight='bold')\n",
    "    \n",
    "    if miniBatch:\n",
    "        print('Info about the mini_batch only with validation nodes: ')\n",
    "        sg_mini_valid_edges_clusters_global = [  clustering_machine.sg_mini_valid_edges_global[cluster] for cluster in clustering_machine.train_clusters]\n",
    "        sg_mini_valid_nodes_clusters_global = clustering_machine.sg_mini_valid_nodes_global\n",
    "        print('mini train edges of each cluster, global ids: ', sg_mini_valid_edges_clusters_global)\n",
    "        print('mini train overlapping nodes global ids: ', sg_mini_valid_nodes_clusters_global)\n",
    "\n",
    "        mini_valid_subgraphs = [clustering_machine.graph.subgraph(clustering_machine.valid_accum_neighbor[cluster]) \\\n",
    "                                               for cluster in clustering_machine.train_clusters]\n",
    "        plt.subplot(337)\n",
    "        nx.draw(mini_valid_subgraphs[0], with_labels=True, font_weight='bold')\n",
    "        plt.subplot(338)\n",
    "        nx.draw(mini_valid_subgraphs[1], with_labels=True, font_weight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Trivial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 2.],\n",
      "        [0., 3.],\n",
      "        [0., 4.],\n",
      "        [0., 5.],\n",
      "        [0., 6.],\n",
      "        [0., 7.],\n",
      "        [0., 8.],\n",
      "        [0., 9.]]) torch.Size([10, 2])\n"
     ]
    }
   ],
   "source": [
    "'''Trivial data'''\n",
    "edge_index = torch.tensor([[0, 1, 1, 3, 1, 2, 4, 2, 4, 6, 6, 7, 7, 9, 2, 5, 9, 8], \n",
    "                           [1, 0, 3, 1, 2, 1, 2, 4, 6, 4, 7, 6, 9, 7, 5, 2, 8, 9]])\n",
    "# features = torch.rand(10, 3)\n",
    "features = torch.tensor([[0, 0], [0, 1], [0, 2], [0, 3], [0, 4],  \n",
    "                           [0, 5], [0, 6], [0, 7], [0, 8], [0, 9]], dtype = torch.float)\n",
    "# label = torch.tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "\n",
    "label = torch.tensor([0, 1, 1, 0, 1, 1, 1, 0, 0, 0])\n",
    "print(features, features.shape)\n",
    "\n",
    "check_clustering_machine = ClusteringMachine(edge_index, features, label)\n",
    "\n",
    "clustering_folder = './res_save_batch/clustering/'\n",
    "check_folder_exist(clustering_folder)\n",
    "\n",
    "clustering_file_name = clustering_folder + 'check_clustering_machine.txt'\n",
    "os.makedirs(os.path.dirname(clustering_file_name), exist_ok=True)\n",
    "with open(clustering_file_name, \"wb\") as fp:\n",
    "    pickle.dump(check_clustering_machine, fp)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### minibatch train nodes and batch validatioin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.75, 0.75)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mini_batch_folder = './res_save_batch/mini_batch_files/'\n",
    "check_folder_exist(mini_batch_folder)\n",
    "\n",
    "with open(clustering_file_name, \"rb\") as fp:\n",
    "    clustering_machine = pickle.load(fp)\n",
    "\n",
    "clustering_machine.split_whole_nodes_edges_then_cluster(0.4, 0.4)\n",
    "# generate the batches for train and validation\n",
    "clustering_machine.mini_batch_train_clustering(mini_batch_folder, 1, train_batch_num = 2) # include number of layers\n",
    "\n",
    "clustering_machine.mini_batch_validation_clustering(mini_batch_folder, 1, valid_batch_num = 2)\n",
    "\n",
    "# construct the batch trainer\n",
    "gcn_trainer_batch = ClusterGCNTrainer_mini_Train(mini_batch_folder, 2, 2, input_layers = [16], dropout=0.3)\n",
    "\n",
    "gcn_trainer_batch.train(1, 0.0001, 0.1, train_batch_num = 2)\n",
    "gcn_trainer_batch.batch_validate(valid_batch_num = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### mini-batch train nodes only in the isolated cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mini-batch of the isolate\n",
    "# clustering_machine = copy.deepcopy(check_clustering_machine)\n",
    "with open(clustering_file_name, \"rb\") as fp:\n",
    "    clustering_machine = pickle.load(fp)\n",
    "clustering_machine.split_cluster_nodes_edges(0.2, 0.4, partition_num = 2)\n",
    "clustering_machine.general_isolate_clustering(2) \n",
    "check_clustering(clustering_machine, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_clustering(clustering_machine, True)\n",
    "gcn_trainer_isolate = ClusterGCNTrainer_mini_Train(clustering_machine, 2, 2, input_layers = [16])\n",
    "gcn_trainer_isolate.train(1,  0.0001, 0.1)\n",
    "gcn_trainer_isolate.validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use library data to check the results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the train loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_train_loss_converge(mini_batch_folder, data_name, dataset, image_path,  comments, input_layer = [32, 16], epoch_num = 300, \\\n",
    "                              dropout = 0.3, lr = 0.0001, weight_decay = 0.01, mini_epoch_num = 5, \\\n",
    "                               valid_part_num = 2, train_part_num = 2, test_part_num = 1):\n",
    "    # mini-batch, but valid also in batches\n",
    "    a3, v3, time3, load3, Cluster_train_valid_batch_trainer = Cluster_train_valid_batch_run(mini_batch_folder, data_name, dataset, image_path, input_layer = input_layer, epochs=epoch_num, \\\n",
    "                                                                               dropout = dropout, lr = lr, weight_decay = weight_decay, mini_epoch_num = mini_epoch_num, \\\n",
    "                                                                               valid_part_num = valid_part_num, train_part_num = train_part_num, test_part_num = test_part_num)\n",
    "    \n",
    "    draw_Cluster_train_valid_batch = draw_trainer_info(data_name, Cluster_train_valid_batch_trainer, image_path, 'train_valid_batch_' + comments)\n",
    "    draw_Cluster_train_valid_batch.draw_ave_loss_per_node()\n",
    "    \n",
    "\n",
    "''' Draw the information about the GCN calculating batch size '''\n",
    "def draw_cluster_info(clustering_machine, data_name, img_path, comments = '_cluster_node_distr'):\n",
    "    \"\"\"\n",
    "        Won't call this for mini-batch with no clustering \n",
    "    \"\"\"\n",
    "    cluster_id = clustering_machine.train_clusters    # a list of cluster indices\n",
    "    cluster_datapoints = {'cluster_id': cluster_id,  \\\n",
    "                          'train_batch' : [clustering_machine.info_train_batch_size[idx] for idx in cluster_id], \\\n",
    "                          'cluster_size' : [clustering_machine.info_isolate_cluster_size[idx] for idx in cluster_id], \\\n",
    "                         }\n",
    "                         \n",
    "    df = pd.DataFrame(data=cluster_datapoints, dtype=np.int32)\n",
    "    # print(df)\n",
    "    df_reshape = df.melt('cluster_id', var_name = 'clusters', value_name = 'node_num')\n",
    "    \n",
    "    plt.clf()\n",
    "    plt.figure()\n",
    "    sns.set(style='whitegrid')\n",
    "    g = sns.catplot(x=\"cluster_id\", y=\"node_num\", hue='clusters', kind='bar', data=df_reshape)\n",
    "    g.despine(left=True)\n",
    "    g.fig.suptitle(data_name + comments)\n",
    "    g.set_xlabels(\"Cluster ID\")\n",
    "    g.set_ylabels(\"Number of nodes\")\n",
    "    \n",
    "    img_name = img_path + data_name + comments\n",
    "    os.makedirs(os.path.dirname(img_name), exist_ok=True)\n",
    "    g.savefig(img_name, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specific model run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cluster_train_valid_batch_run(mini_batch_folder, data_name, dataset, image_path, input_layer = [16, 16], epochs=300, \\\n",
    "                           dropout = 0.3, lr = 0.01, weight_decay = 0.01, mini_epoch_num = 5, \\\n",
    "                                 valid_part_num = 2, train_part_num = 2, test_part_num = 1):\n",
    "    \"\"\"\n",
    "    # Run the mini-batch model (train and validate both in batches)\n",
    "    Tuning parameters:  dropout, lr (learning rate), weight_decay: l2 regularization\n",
    "    return: validation accuracy value, validation F-1 value, time_training (ms), time_data_load (ms)\n",
    "    \"\"\"\n",
    "#     gcn_trainer_batch = ClusterGCNTrainer_mini_Train(mini_batch_folder, 2, 2, 2, 2, 2, input_layers = [16], dropout=0.3)\n",
    "    \n",
    "    gcn_trainer = ClusterGCNTrainer_mini_Train(mini_batch_folder, dataset.num_node_features, dataset.num_classes, input_layers = input_layer, dropout = dropout)\n",
    "    gcn_trainer.train(epoch_num=epochs, learning_rate=lr, weight_decay=weight_decay, mini_epoch_num = mini_epoch_num, train_batch_num = train_part_num)\n",
    "    \n",
    "    validation_F1, validation_accuracy = gcn_trainer.batch_validate(valid_batch_num = valid_part_num)\n",
    "    time_train_total = gcn_trainer.time_train_total\n",
    "    time_data_load = gcn_trainer.time_train_load_data\n",
    "    return validation_accuracy, validation_F1, time_train_total, time_data_load, gcn_trainer\n",
    "\n",
    "\n",
    "def Cluster_train_valid_batch_investigate(mini_batch_folder, data_name, dataset, image_path, input_layer = [16, 16], epochs=300, \\\n",
    "                           dropout = 0.3, lr = 0.01, weight_decay = 0.01, mini_epoch_num = 5, output_period = 10, \n",
    "                                         valid_part_num = 2, train_part_num = 2, test_part_num = 1):\n",
    "    \"\"\"\n",
    "        *** dynamically investigate the F1 score in the middle of the training after certain period ***\n",
    "        output: two dict containing F1-score and accuracy of a certain epoch index\n",
    "    \"\"\"\n",
    "    gcn_trainer = ClusterGCNTrainer_mini_Train(mini_batch_folder, dataset.num_node_features, dataset.num_classes, input_layers = input_layer, dropout = dropout)\n",
    "    Train_period_F1, Train_period_accuracy = gcn_trainer.train_investigate_F1(epoch_num=epochs, learning_rate=lr, weight_decay=weight_decay, mini_epoch_num = mini_epoch_num, \\\n",
    "                                                            output_period = output_period, train_batch_num = train_part_num, valid_batch_num = valid_part_num)\n",
    "    \n",
    "    return Train_period_F1, Train_period_accuracy\n",
    "\n",
    "\n",
    "def Isolate_clustering_run(local_clustering_machine, data_name, dataset, image_path, input_layer = [16, 16], epochs=300, neigh_layer = 1, frac = 1.0, \\\n",
    "                           dropout = 0.3, lr = 0.01, weight_decay = 0.01):\n",
    "    \"\"\"\n",
    "    # the partition num: will determine the training, testing and validation data\n",
    "    return: test F-1 value, validation F-1 value\n",
    "    \"\"\"\n",
    "    clustering_machine = copy.deepcopy(local_clustering_machine)\n",
    "    # defalt to contain 1 layer of neighbors of train nodes\n",
    "    clustering_machine.general_isolate_clustering(neigh_layer, fraction = frac)\n",
    "    gcn_trainer = ClusterGCNTrainer_mini_Train(clustering_machine, dataset.num_node_features, dataset.num_classes, input_layers = input_layer, dropout = dropout)\n",
    "    gcn_trainer.train(epoch_num=epochs, learning_rate=lr, weight_decay=weight_decay)\n",
    "    \n",
    "#     test_F1, test_accuracy = gcn_trainer.test()\n",
    "    validation_F1, validation_accuracy = gcn_trainer.validate()\n",
    "    time_train_total = gcn_trainer.time_train_total\n",
    "    time_data_load = gcn_trainer.time_train_load_data\n",
    "    return validation_accuracy, validation_F1, time_train_total, time_data_load, gcn_trainer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test and compare different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Execute the testing program '''\n",
    "def set_clustering_machine(data, intermediate_data_folder, test_ratio = 0.05, validation_ratio = 0.85, neigh_layer = 1, train_frac = 1.0, \\\n",
    "                           valid_part_num = 1, train_part_num = 2, test_part_num = 1):\n",
    "    \"\"\"\n",
    "        Set the clustering:\n",
    "            1) data: the target dataset data\n",
    "            2) intermediate_data_folder: path to store the intermediate generated data\n",
    "            3) test_ratio, validation_ratio: data split ratio\n",
    "            4) neigh_layer: number of hops (layers) for the neighbor nodes \n",
    "            5) train_frac: each time including fraction of the neigbor nodes in each layer\n",
    "            6) valid_part_num, train_part_num, test_part_num :  batch number for validation, train and test data correspondingly\n",
    "    \"\"\"\n",
    "    connect_edge_index, connect_features, connect_label = filter_out_isolate(data.edge_index, data.x, data.y)\n",
    "    clustering_machine = ClusteringMachine(connect_edge_index, connect_features, connect_label)\n",
    "#     clustering_machine.split_cluster_nodes_edges(test_ratio, validation_ratio, partition_num = train_part_num)\n",
    "    # mini-batch only: split to train test valid before clustering\n",
    "    clustering_machine.split_whole_nodes_edges_then_cluster(test_ratio, validation_ratio)\n",
    "    \n",
    "    # generate mini-batches\n",
    "    \n",
    "    mini_batch_folder = intermediate_data_folder + 'mini_batch_files/'\n",
    "    check_folder_exist(mini_batch_folder)  # if exist then delete\n",
    "    \n",
    "    clustering_machine.mini_batch_train_clustering(mini_batch_folder, neigh_layer, fraction = train_frac, train_batch_num = train_part_num)\n",
    "    # for validation , fraction has to be 1.0 so that to include the information form original graph\n",
    "    clustering_machine.mini_batch_validation_clustering(mini_batch_folder, neigh_layer, fraction = 1.0, valid_batch_num = valid_part_num)\n",
    "    \n",
    "    # stored the clustering machine with train-batch , validation-batch \n",
    "    clustering_file_folder = intermediate_data_folder + 'clustering/'\n",
    "    check_folder_exist(clustering_file_folder)  # if exist then delete\n",
    "    clustering_file_name = clustering_file_folder + 'clustering_machine.txt'\n",
    "    os.makedirs(os.path.dirname(clustering_file_name), exist_ok=True)\n",
    "    with open(clustering_file_name, \"wb\") as fp:\n",
    "        pickle.dump(clustering_machine, fp)\n",
    "        \n",
    "    # can off-line load the clustering model with train-batch generated\n",
    "#     with open(clustering_file_name, \"rb\") as fp:\n",
    "#         clustering_machine = pickle.load(fp)\n",
    "\n",
    "    return mini_batch_folder\n",
    "\n",
    "    \n",
    "def execute_one(mini_batch_folder, image_path, repeate_time = 5, input_layer = [32], epoch_num = 300, \\\n",
    "                dropout = 0.3, lr = 0.0001, weight_decay = 0.01, mini_epoch_num = 5, \\\n",
    "                valid_part_num = 2, train_part_num = 2, test_part_num = 1):\n",
    "    \"\"\"\n",
    "        return all test-F1 and validation-F1 for all four models\n",
    "    \"\"\"\n",
    "    validation_accuracy = {}\n",
    "    validation_f1 = {}\n",
    "    time_total_train = {}\n",
    "    time_data_load = {}\n",
    "    \n",
    "    # Each graph model corresponds to one function below\n",
    "#     graph_model = ['batch_valid', 'train_batch', 'whole_graph', 'isolate']\n",
    "    graph_model = ['batch_valid']\n",
    "    for i in range(repeate_time):\n",
    "        model_res = []\n",
    "        \n",
    "        model_res.append(Cluster_train_valid_batch_run(mini_batch_folder, data_name, dataset, image_path, input_layer = input_layer, epochs=epoch_num, \\\n",
    "                                                         dropout = dropout, lr = lr, weight_decay = weight_decay, mini_epoch_num = mini_epoch_num, \\\n",
    "                                                      valid_part_num = valid_part_num, train_part_num = train_part_num, test_part_num = test_part_num)[:4])\n",
    "        \n",
    "#         model_res.append(Isolate_clustering_run(clustering_machine, data_name, dataset, image_path, input_layer = input_layer, epochs=epoch_num, neigh_layer = layer_num, frac = frac, \\\n",
    "#                                                         dropout = dropout, lr = lr, weight_decay = weight_decay)[:4])\n",
    "        \n",
    "        validation_accuracy[i], validation_f1[i], time_total_train[i], time_data_load[i] = zip(*model_res)\n",
    "    return graph_model, validation_accuracy, validation_f1, time_total_train, time_data_load\n",
    "\n",
    "def store_data_multi_tests(f1_data, data_name, graph_model, img_path, comments):\n",
    "    run_id = sorted(f1_data.keys())\n",
    "    run_data = {'run_id': run_id}\n",
    "    \n",
    "    run_data.update({model_name : [f1_data[key][idx] for key in run_id] for idx, model_name in enumerate(graph_model)})\n",
    "    \n",
    "    pickle_filename = img_path + data_name + '_' + comments + '.pkl'\n",
    "    os.makedirs(os.path.dirname(pickle_filename), exist_ok=True)\n",
    "    df = pd.DataFrame(data=run_data, dtype=np.int32)\n",
    "    df.to_pickle(pickle_filename)\n",
    "    return pickle_filename\n",
    "\n",
    "def draw_data_multi_tests(pickle_filename, data_name, comments, xlabel, ylabel):\n",
    "    df = pd.read_pickle(pickle_filename)\n",
    "    df_reshape = df.melt('run_id', var_name = 'model', value_name = ylabel)\n",
    "\n",
    "    plt.clf()\n",
    "    plt.figure()\n",
    "    sns.set(style='whitegrid')\n",
    "    g = sns.catplot(x=\"model\", y=ylabel, kind='box', data=df_reshape)\n",
    "    g.despine(left=True)\n",
    "    g.fig.suptitle(data_name + ' ' + ylabel + ' ' + comments)\n",
    "    g.set_xlabels(xlabel)\n",
    "    g.set_ylabels(ylabel)\n",
    "\n",
    "    img_name = pickle_filename[:-4] + '_img'\n",
    "    os.makedirs(os.path.dirname(img_name), exist_ok=True)\n",
    "    plt.savefig(img_name, bbox_inches='tight')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate performance in the middle of the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_investigate(mini_batch_folder, image_path, repeate_time = 5, input_layer = [32], epoch_num = 300, \\\n",
    "                        dropout = 0.3, lr = 0.0001, weight_decay = 0.01, mini_epoch_num = 5, output_period = 10, \\\n",
    "                         valid_part_num = 2, train_part_num = 2, test_part_num = 1):\n",
    "    \"\"\"\n",
    "        return all test-F1 and validation-F1 for all four models\n",
    "    \"\"\"\n",
    "    \n",
    "    Train_peroid_f1 = {}\n",
    "    Train_peroid_accuracy = {}\n",
    "    \n",
    "    for i in range(repeate_time):\n",
    "        Train_peroid_f1[i], Train_peroid_accuracy[i] = Cluster_train_valid_batch_investigate(mini_batch_folder, data_name, dataset, image_path, input_layer = input_layer, epochs=epoch_num, \\\n",
    "                                            dropout = dropout, lr = lr, weight_decay = weight_decay, mini_epoch_num = mini_epoch_num, output_period = output_period, \\\n",
    "                                                                    valid_part_num = valid_part_num, train_part_num = train_part_num, test_part_num = test_part_num)\n",
    "        \n",
    "    return Train_peroid_f1, Train_peroid_accuracy\n",
    "\n",
    "def store_data_multi_investigate(investigate_res, data_name, res_name, img_path, comments):\n",
    "    \"\"\"\n",
    "        investigate_res: currently either F1-score or accuracy a dict {epoch num : value}\n",
    "    \"\"\"\n",
    "    run_id = sorted(investigate_res.keys())\n",
    "    run_data = {'run_id': run_id}\n",
    "    \n",
    "    epoch_num_range = sorted(investigate_res[0].keys())  # at least one entry exists inside the dictionary and the epoch range is fixed\n",
    "    run_data.update({epoch_num : [investigate_res[key][epoch_num] for key in run_id] for epoch_num in epoch_num_range})\n",
    "    \n",
    "    pickle_filename = img_path + data_name + '_' + res_name + '_' + comments + '.pkl'\n",
    "    os.makedirs(os.path.dirname(pickle_filename), exist_ok=True)\n",
    "    df = pd.DataFrame(data=run_data, dtype=np.int32)\n",
    "    df.to_pickle(pickle_filename)\n",
    "    return pickle_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"To test one single model for different parameter values\"\"\"\n",
    "def execute_tuning(tune_params, mini_batch_folder, image_path, repeate_time = 7, input_layer = [32], epoch_num = 400, \\\n",
    "                  dropout = 0.1, lr = 0.0001, weight_decay = 0.1, mini_epoch_num = 20, \\\n",
    "                  valid_part_num = 2, train_part_num = 2, test_part_num = 1):\n",
    "    \"\"\"\n",
    "        Tune all the hyperparameters\n",
    "        1) learning rate\n",
    "        2) dropout\n",
    "        3) layer unit number\n",
    "        4) weight decay\n",
    "    \"\"\"\n",
    "    validation_accuracy = {}\n",
    "    validation_f1 = {}\n",
    "    time_total_train = {}\n",
    "    time_data_load = {}\n",
    "    \n",
    "    res = [{tune_val : Cluster_train_valid_batch_run(mini_batch_folder, data_name, dataset, image_path, input_layer = input_layer, epochs=epoch_num, \\\n",
    "            dropout = dropout, lr = lr, weight_decay = weight_decay, mini_epoch_num = tune_val, \\\n",
    "            valid_part_num = valid_part_num, train_part_num = train_part_num, test_part_num = test_part_num)[:4] for tune_val in tune_params} for i in range(repeate_time)]\n",
    "    \n",
    "    for i, ref in enumerate(res):\n",
    "        validation_accuracy[i] = {tune_val : res_lst[0] for tune_val, res_lst in ref.items()}\n",
    "        validation_f1[i] = {tune_val : res_lst[1] for tune_val, res_lst in ref.items()}\n",
    "        time_total_train[i] = {tune_val : res_lst[2] for tune_val, res_lst in ref.items()}\n",
    "        time_data_load[i] = {tune_val : res_lst[3] for tune_val, res_lst in ref.items()}\n",
    "        \n",
    "    return validation_accuracy, validation_f1, time_total_train, time_data_load\n",
    "\n",
    "def store_data_multi_tuning(tune_params, target, data_name, img_path, comments):\n",
    "    \"\"\"\n",
    "        tune_params: is the tuning parameter list\n",
    "        target: is the result, here should be F1-score, accuraycy, load time, train time\n",
    "    \"\"\"\n",
    "    run_ids = sorted(target.keys())   # key is the run_id\n",
    "    run_data = {'run_id': run_ids}\n",
    "    # the key can be converted to string or not: i.e. str(tune_val)\n",
    "    # here we keep it as integer such that we want it to follow order\n",
    "    tmp = {tune_val : [target[run_id][tune_val] for run_id in run_ids] for tune_val in tune_params}  # the value is list\n",
    "    run_data.update(tmp)\n",
    "    \n",
    "    pickle_filename = img_path + data_name + '_' + comments + '.pkl'\n",
    "    os.makedirs(os.path.dirname(pickle_filename), exist_ok=True)\n",
    "    df = pd.DataFrame(data=run_data, dtype=np.int32)\n",
    "    df.to_pickle(pickle_filename)\n",
    "    return pickle_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-test execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_train_loss(data, data_name, dataset, image_data_path, intermediate_data_path, partition_nums, layers, \\\n",
    "                      dropout = 0.1, lr = 0.0001, weight_decay = 0.1, mini_epoch_num = 20, valid_part_num = 2):\n",
    "    for partn in partition_nums:\n",
    "        for GCN_layer in layers:\n",
    "            net_layer = len(GCN_layer) + 1\n",
    "            hop_layer = net_layer\n",
    "            print('Start checking train loss for partition num: ' + str(partn) + ' hop layer: ' + str(hop_layer))\n",
    "            img_path = image_data_path + 'cluster_num_' + str(partn) + '/' + 'net_layer_' + str(net_layer) + '_hop_layer_' + str(hop_layer) + '/'\n",
    "            intermediate_data_folder = intermediate_data_path + 'cluster_num_' + str(partn) + '/' + 'net_layer_' + str(net_layer) + '_hop_layer_' + str(hop_layer) + '/'\n",
    "            \n",
    "            # set the batch for validation and train\n",
    "            mini_batch_folder = set_clustering_machine(data, intermediate_data_folder, test_ratio = 0.05, validation_ratio = 0.85, neigh_layer = hop_layer, train_frac = 1.0, \\\n",
    "                           valid_part_num = valid_part_num, train_part_num = partn, test_part_num = 1)\n",
    "            \n",
    "            check_train_loss_converge(mini_batch_folder, data_name, dataset, img_path, 'part_num_' + str(partn), input_layer = GCN_layer, epoch_num = 400, \\\n",
    "                                     dropout = dropout, lr = lr, weight_decay = weight_decay, mini_epoch_num = mini_epoch_num, \n",
    "                                     valid_part_num = valid_part_num, train_part_num = partn, test_part_num = 1)\n",
    "            \n",
    "#             # for the large dataset and split first case, the cluster info cannot be generated\n",
    "#             clustering_machine.mini_batch_train_clustering(hop_layer)\n",
    "#             draw_cluster_info(clustering_machine, data_name, img_path, comments = '_cluster_node_distr_' + str(hop_layer) + '_hops')\n",
    "            \n",
    "def output_F1_score(data, data_name, dataset, image_data_path, intermediate_data_path, partition_nums, layers, \\\n",
    "                    dropout = 0.1, lr = 0.0001, weight_decay = 0.1, mini_epoch_num = 20, valid_part_num = 2):            \n",
    "    for partn in partition_nums:\n",
    "        for GCN_layer in layers:\n",
    "            net_layer = len(GCN_layer) + 1\n",
    "            hop_layer = net_layer\n",
    "            \n",
    "            # set the save path\n",
    "            print('Start running for partition num: ' + str(partn) + ' hop layer ' + str(hop_layer))\n",
    "            img_path = image_data_path + 'cluster_num_' + str(partn) + '/' + 'net_layer_' + str(net_layer) + '_hop_layer_' + str(hop_layer) + '/'\n",
    "            intermediate_data_folder = intermediate_data_path + 'cluster_num_' + str(partn) + '/' + 'net_layer_' + str(net_layer) + '_hop_layer_' + str(hop_layer) + '/'\n",
    "            \n",
    "            # set the batch for validation and train\n",
    "            mini_batch_folder = set_clustering_machine(data, intermediate_data_folder, test_ratio = 0.05, validation_ratio = 0.85, neigh_layer = hop_layer, train_frac = 1.0, \\\n",
    "                           valid_part_num = valid_part_num, train_part_num = partn, test_part_num = 1)\n",
    "            \n",
    "            # start to run the model, train and validation \n",
    "            graph_model, validation_accuracy, validation_f1, time_total_train, time_data_load = \\\n",
    "                execute_one(mini_batch_folder, img_path, repeate_time = 7, input_layer = GCN_layer, epoch_num = 400, \n",
    "                                            dropout = dropout, lr = lr, weight_decay = weight_decay, mini_epoch_num = mini_epoch_num, \\\n",
    "                                             valid_part_num = valid_part_num, train_part_num = partn, test_part_num = 1)\n",
    "            \n",
    "            \n",
    "            validation_accuracy = store_data_multi_tests(validation_accuracy, data_name, graph_model, img_path, 'test_cluster_num_' + str(partn) + '_hops_' + str(hop_layer))\n",
    "            draw_data_multi_tests(validation_accuracy, data_name, 'vali_cluster_num_' + str(partn) + '_hop_' + str(hop_layer), 'models', 'Accuracy')\n",
    "\n",
    "            validation_f1 = store_data_multi_tests(validation_f1, data_name, graph_model, img_path, 'validation_cluster_num_' + str(partn) + '_hops_' + str(hop_layer))\n",
    "            draw_data_multi_tests(validation_f1, data_name, 'vali_cluster_num_' + str(partn) + '_hop_' + str(hop_layer), 'models', 'F1 score')\n",
    "\n",
    "            time_train = store_data_multi_tests(time_total_train, data_name, graph_model, img_path, 'train_time_cluster_num_' + str(partn) + '_hops_' + str(hop_layer))\n",
    "            draw_data_multi_tests(time_train, data_name, 'train_time_cluster_num_' + str(partn) + '_hop_' + str(hop_layer), 'models', 'Train Time (ms)')\n",
    "\n",
    "            time_load = store_data_multi_tests(time_data_load, data_name, graph_model, img_path, 'load_time_cluster_num_' + str(partn) + '_hops_' + str(hop_layer))\n",
    "            draw_data_multi_tests(time_load, data_name, 'load_time_cluster_num_' + str(partn) + '_hop_' + str(hop_layer), 'models', 'Load Time (ms)')\n",
    "\n",
    "def output_train_investigate(data, data_name, dataset, image_data_path, intermediate_data_path, partition_nums, layers, \\\n",
    "                             dropout = 0.1, lr = 0.0001, weight_decay = 0.1, mini_epoch_num = 20, output_period = 40, valid_part_num = 2):            \n",
    "    for partn in partition_nums:\n",
    "        for GCN_layer in layers:\n",
    "            net_layer = len(GCN_layer) + 1\n",
    "            hop_layer = net_layer\n",
    "            # set the save path\n",
    "            print('Start running for partition num: ' + str(partn) + ' hop layer ' + str(hop_layer))\n",
    "            img_path = image_data_path + 'cluster_num_' + str(partn) + '/' + 'net_layer_' + str(net_layer) + '_hop_layer_' + str(hop_layer) + '/'\n",
    "            intermediate_data_folder = intermediate_data_path + 'cluster_num_' + str(partn) + '/' + 'net_layer_' + str(net_layer) + '_hop_layer_' + str(hop_layer) + '/'\n",
    "            \n",
    "            # set the batch for validation and train\n",
    "            mini_batch_folder = set_clustering_machine(data, intermediate_data_folder, test_ratio = 0.05, validation_ratio = 0.85, neigh_layer = hop_layer, train_frac = 1.0, \\\n",
    "                           valid_part_num = valid_part_num, train_part_num = partn, test_part_num = 1)\n",
    "\n",
    "            Train_peroid_f1, Train_peroid_accuracy = execute_investigate(mini_batch_folder, img_path, repeate_time = 7, input_layer = GCN_layer, epoch_num = 400, \\\n",
    "                                            dropout = dropout, lr = lr, weight_decay = weight_decay, mini_epoch_num = mini_epoch_num, output_period = output_period, \\\n",
    "                                            valid_part_num = valid_part_num, train_part_num = partn, test_part_num = 1)\n",
    "            \n",
    "            Train_peroid_f1 = store_data_multi_investigate(Train_peroid_f1, data_name, 'F1_score', img_path, 'invest_batch_num_' + str(partn) + '_hops_' + str(hop_layer))\n",
    "            draw_data_multi_tests(Train_peroid_f1, data_name, 'Train_process_batch_num_' + str(partn) + '_hop_' + str(hop_layer), 'epoch number', 'F1 score')\n",
    "\n",
    "            Train_peroid_accuracy = store_data_multi_investigate(Train_peroid_accuracy, data_name, 'Accuracy', img_path, 'invest_batch_num_' + str(partn) + '_hops_' + str(hop_layer))\n",
    "            draw_data_multi_tests(Train_peroid_accuracy, data_name, 'Train_process_batch_num_' + str(partn) + '_hop_' + str(hop_layer), 'epoch number', 'Accuracy')\n",
    "            \n",
    "            \n",
    "            \n",
    "def output_tune_param(data, data_name, dataset, image_data_path, intermediate_data_path, partition_nums, layers, dropout = 0.1, lr = 0.0001, weight_decay = 0.1, mini_epoch_num = 20, valid_part_num = 2):\n",
    "    for partn in partition_nums:\n",
    "        for GCN_layer in layers:\n",
    "            net_layer = len(GCN_layer) + 1\n",
    "            hop_layer = net_layer\n",
    "            # Set the tune parameters and name\n",
    "            tune_name = 'batch_epoch_num'\n",
    "            tune_params = [400, 200, 100, 50, 20, 10, 5, 1]\n",
    "#             tune_name = 'weight_decay'\n",
    "#             tune_params = [0.0001, 0.001, 0.01, 0.1]\n",
    "\n",
    "            img_path = image_data_path + 'cluster_num_' + str(partn) + '/' + 'net_layer_' + str(net_layer) + '_hop_layer_' + str(hop_layer) + '/' + 'tune_' + tune_name + '/'\n",
    "            intermediate_data_folder = intermediate_data_path + 'cluster_num_' + str(partn) + '/' + 'net_layer_' + str(net_layer) + '_hop_layer_' + str(hop_layer) + '/' + 'tune_' + tune_name + '/'\n",
    "            print('Start tuning for tuning param: ' + tune_name + ' partition num: ' + str(partn) + ' hop layer ' + str(hop_layer))\n",
    "            \n",
    "            # set the batch for validation and train\n",
    "            mini_batch_folder = set_clustering_machine(data, intermediate_data_folder, test_ratio = 0.05, validation_ratio = 0.85, neigh_layer = hop_layer, train_frac = 1.0, \\\n",
    "                           valid_part_num = valid_part_num, train_part_num = partn, test_part_num = 1)\n",
    "\n",
    "            validation_accuracy, validation_f1, time_total_train, time_data_load = execute_tuning(tune_params, mini_batch_folder, img_path, repeate_time = 7, \\\n",
    "                                                input_layer = GCN_layer, epoch_num = 400, dropout = dropout, lr = lr, weight_decay = weight_decay, mini_epoch_num = mini_epoch_num, \\\n",
    "                                                valid_part_num = valid_part_num, train_part_num = partn, test_part_num = 1)\n",
    "\n",
    "            validation_accuracy = store_data_multi_tuning(tune_params,validation_accuracy, data_name, img_path, 'accuracy_cluster_num_' + str(partn) + '_hops_' + str(hop_layer))\n",
    "            draw_data_multi_tests(validation_accuracy, data_name, 'vali_cluster_num_' + str(partn) + '_hop_' + str(hop_layer), 'epochs_per_batch', 'Accuracy')\n",
    "\n",
    "            validation_f1 = store_data_multi_tuning(tune_params, validation_f1, data_name, img_path, 'validation_cluster_num_' + str(partn) + '_hops_' + str(hop_layer))\n",
    "            draw_data_multi_tests(validation_f1, data_name, 'vali_cluster_num_' + str(partn) + '_hop_' + str(hop_layer), 'epochs_per_batch', 'F1 score')\n",
    "\n",
    "            time_train = store_data_multi_tuning(tune_params, time_total_train, data_name, img_path, 'train_time_cluster_num_' + str(partn) + '_hops_' + str(hop_layer))\n",
    "            draw_data_multi_tests(time_train, data_name, 'train_time_cluster_num_' + str(partn) + '_hop_' + str(hop_layer), 'epochs_per_batch', 'Train Time (ms)')\n",
    "\n",
    "            time_load = store_data_multi_tuning(tune_params, time_data_load, data_name, img_path, 'load_time_cluster_num_' + str(partn) + '_hops_' + str(hop_layer))\n",
    "            draw_data_multi_tests(time_load, data_name, 'load_time_cluster_num_' + str(partn) + '_hop_' + str(hop_layer), 'epochs_per_batch', 'Load Time (ms)')\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use data from pytorch geometric datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_data_root = '/media/xiangli/storage1/projects/tmpdata/'\n",
    "test_folder_name = 'Test_pickle_save_batch/train_10%_full_neigh_random_mini_epoch_400/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cora dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "data_name = 'Cora'\n",
    "dataset = Planetoid(root = local_data_root + 'Planetoid/Cora', name=data_name)\n",
    "data = dataset[0]\n",
    "image_data_path = './results/' + data_name + '/' + test_folder_name\n",
    "intermediate_data_folder = './intermediate_data/' + data_name + '/' + test_folder_name\n",
    "\n",
    "partition_nums = [2]\n",
    "layers = [[32]]\n",
    "tune_lr = 0.0001\n",
    "check_mini_epoch = 20\n",
    "# partition_nums = [2, 4, 8]\n",
    "# layers = [[], [32], [32, 32], [32, 32, 32]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle save Output_F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start running for partition num: 2 hop layer 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# set_clustering_machine(data, intermediate_data_folder, test_ratio = 0.05, validation_ratio = 0.85, neigh_layer = 3, train_frac = 1.0, \\\n",
    "#                            valid_part_num = 2, train_part_num = 4, test_part_num = 1)\n",
    "\n",
    "# check F1-score\n",
    "output_F1_score(data, data_name, dataset, image_data_path, intermediate_data_folder, partition_nums, layers, \\\n",
    "                dropout = 0.1, lr = tune_lr, weight_decay = 0.1, mini_epoch_num = check_mini_epoch, valid_part_num = 2)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start checking train loss for partition num: 2 hop layer: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check convergence\n",
    "output_train_loss(data, data_name, dataset, image_data_path, intermediate_data_folder, partition_nums, layers, \\\n",
    "                  dropout = 0.1, lr = tune_lr, weight_decay = 0.1, mini_epoch_num = check_mini_epoch, valid_part_num = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check in_train performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start running for partition num: 2 hop layer 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_train_investigate(data, data_name, dataset, image_data_path, intermediate_data_folder, partition_nums, layers, \\\n",
    "                         dropout = 0.1, lr = tune_lr, weight_decay = 0.1, mini_epoch_num = check_mini_epoch, output_period = 40, valid_part_num = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tuning epoch number for each train-batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start tuning for tuning param: batch_epoch_num partition num: 2 hop layer 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tuning the mini_epoch\n",
    "output_tune_param(data, data_name, dataset, image_data_path, intermediate_data_folder, partition_nums, layers, \\\n",
    "                  dropout = 0.1, lr = tune_lr, weight_decay = 0.1, valid_part_num = 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CoraFull dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of data:  1\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import CoraFull\n",
    "data_name = 'CoraFull'\n",
    "dataset = CoraFull(root = local_data_root + 'CoralFull')\n",
    "print('number of data: ', len(dataset))\n",
    "data = dataset[0]\n",
    "\n",
    "image_data_path = './results/' + data_name + '/' + test_folder_name\n",
    "intermediate_data_folder = './intermediate_data/' + data_name + '/' + test_folder_name\n",
    "\n",
    "partition_nums = [4]\n",
    "layers = [[128, 128]]\n",
    "# partition_nums = [2, 4, 8]\n",
    "# layers = [[], [32], [32, 32], [32, 32, 32]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start running for partition num: 4 hop layer 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tune the parameter\n",
    "\n",
    "output_tune_param(data, data_name, dataset, image_data_path, intermediate_data_folder, partition_nums, layers, \\\n",
    "                  dropout = 0.5, lr = 0.0001, weight_decay = 0.001, mini_epoch_num = 20, valid_part_num = 2)\n",
    "\n",
    "# in-train process\n",
    "# output_train_investigate(data, data_name, dataset, image_data_path, intermediate_data_folder, partition_nums, layers, \\\n",
    "#                          dropout = 0.5, lr = 0.0001, weight_decay = 0.001, mini_epoch_num = 20, output_period = 40, valid_part_num = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check F1-score\n",
    "# output_F1_score(data, data_name, dataset, image_data_path, intermediate_data_folder, partition_nums, layers, \\\n",
    "#                 dropout = 0.1, lr = 0.0001, weight_decay = 0.1, mini_epoch_num = 20, valid_part_num = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CiteSeer Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "data_name = 'CiteSeer'\n",
    "dataset = Planetoid(root = local_data_root + 'Planetoid/CiteSeer', name=data_name)\n",
    "data = dataset[0]\n",
    "image_data_path = './results/' + data_name + '/' + test_folder_name\n",
    "\n",
    "partition_nums = [2, 4, 8]\n",
    "layers = [[], [16], [16, 16]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning the epoch number per batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking train loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PubMed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "data_name = 'PubMed'\n",
    "dataset = Planetoid(root = local_data_root + 'Planetoid/PubMed', name=data_name)\n",
    "data = dataset[0]\n",
    "image_data_path = './results/' + data_name + '/' + test_folder_name\n",
    "\n",
    "partition_nums = [2, 4, 8]\n",
    "layers = [[], [64], [64, 64], [64, 64, 64]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune epoch number per batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the train error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# free GPU memory\n",
    "# !(nvidia-smi | grep 'python' | awk '{ print $3 }' | xargs -n1 kill -9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_geometric]",
   "language": "python",
   "name": "conda-env-pytorch_geometric-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
