{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dig into to GPU pytorch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "use_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(use_device)\n",
    "'''Trivial data'''\n",
    "edge_index = torch.tensor([[0, 1, 1, 3, 1, 2, 4, 2, 4, 6, 6, 7, 7, 9, 2, 5, 9, 8], \n",
    "                           [1, 0, 3, 1, 2, 1, 2, 4, 6, 4, 7, 6, 9, 7, 5, 2, 8, 9]])\n",
    "# features = torch.rand(10, 3)\n",
    "features = torch.tensor([[0, 0], [0, 1], [0, 2], [0, 3], [0, 4],  \n",
    "                           [0, 5], [0, 6], [0, 7], [0, 8], [0, 9]], dtype = torch.float)\n",
    "# label = torch.tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "\n",
    "label = torch.tensor([0, 1, 1, 0, 1, 1, 1, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.,  4.],\n",
      "        [ 2.,  5.],\n",
      "        [ 2.,  6.],\n",
      "        [ 2.,  7.],\n",
      "        [ 2.,  8.],\n",
      "        [ 2.,  9.],\n",
      "        [ 2., 10.],\n",
      "        [ 2., 11.],\n",
      "        [ 2., 12.],\n",
      "        [ 2., 13.]])\n"
     ]
    }
   ],
   "source": [
    "trial = features + torch.tensor([2, 4], dtype = torch.float)\n",
    "print(trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# select the first dimension number\n",
    "x = features.size(0)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 2.],\n",
      "        [0., 3.],\n",
      "        [0., 4.],\n",
      "        [0., 5.],\n",
      "        [0., 6.],\n",
      "        [0., 7.],\n",
      "        [0., 8.],\n",
      "        [0., 9.]], device='cuda:0') torch.Size([10, 2])\n",
      "tensor([[0., 1.],\n",
      "        [0., 3.],\n",
      "        [0., 5.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "gpu_features = features.to(use_device)\n",
    "print(gpu_features, gpu_features.shape)\n",
    "part_gpu_features = gpu_features[[1, 3, 5], :]\n",
    "print(part_gpu_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 2.],\n",
      "        [0., 3.],\n",
      "        [0., 4.],\n",
      "        [0., 5.],\n",
      "        [0., 6.],\n",
      "        [0., 7.],\n",
      "        [0., 8.],\n",
      "        [0., 9.]], device='cuda:0') torch.Size([10, 2])\n",
      "tensor([[ 0.,  0.],\n",
      "        [ 0., 11.],\n",
      "        [ 0.,  2.],\n",
      "        [ 0., 13.],\n",
      "        [ 0.,  4.],\n",
      "        [ 0., 15.],\n",
      "        [ 0.,  6.],\n",
      "        [ 0.,  7.],\n",
      "        [ 0.,  8.],\n",
      "        [ 0.,  9.]], device='cuda:0') torch.Size([10, 2])\n"
     ]
    }
   ],
   "source": [
    "### modify the tensor in-place by indexing, need to make the dtype and the device both consistent\n",
    "print(gpu_features, gpu_features.shape)\n",
    "gpu_features[[1, 3, 5], :] = torch.tensor([[0, 11.0], [0, 13], [0, 15]], dtype = torch.float).to(use_device)\n",
    "print(gpu_features, gpu_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 2.],\n",
      "        [0., 3.],\n",
      "        [0., 4.],\n",
      "        [0., 5.],\n",
      "        [0., 6.],\n",
      "        [0., 7.],\n",
      "        [0., 8.],\n",
      "        [0., 9.]], device='cuda:0') torch.Size([10, 2])\n",
      "tensor([[0., 0.],\n",
      "        [0., 2.],\n",
      "        [0., 2.],\n",
      "        [0., 4.],\n",
      "        [0., 4.],\n",
      "        [0., 6.],\n",
      "        [0., 6.],\n",
      "        [0., 7.],\n",
      "        [0., 8.],\n",
      "        [0., 9.],\n",
      "        [0., 8.],\n",
      "        [0., 9.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "gpu_features = features.to(use_device)\n",
    "print(gpu_features, gpu_features.shape)\n",
    "gpu_features[[1, 3, 5], :] = gpu_features[[2, 4, 6], :]\n",
    "gpu_features = torch.cat([gpu_features, gpu_features[-2:].to(use_device) ])\n",
    "print(gpu_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manimpulate local-global index mapping by using torch.tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Got the first remapping index tensor of all edges index (local) and copy it on to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remapped edges are: \n",
      "[[5, 0], [7, 3], [1, 6], [2, 4], [6, 8]]\n",
      "nodes on edges are: \n",
      "{101, 102, 104, 105, 106, 109, 111, 115, 119}\n",
      "show the mapper: \n",
      "{101: 0, 102: 1, 104: 2, 105: 3, 106: 4, 109: 5, 111: 6, 115: 7, 119: 8}\n"
     ]
    }
   ],
   "source": [
    "target_edges = [(109, 101), (115, 105), (102, 111), (104, 106), (111, 119)]\n",
    "target_nodes = {left for left, right in target_edges} | {right for left, right in target_edges}\n",
    "mapper = {node : i for i, node in enumerate(target_nodes)}\n",
    "local_target = [ [mapper[start], mapper[end]] for start, end in target_edges]\n",
    "print('remapped edges are: ')\n",
    "print(local_target)\n",
    "print('nodes on edges are: ')\n",
    "print(target_nodes)\n",
    "print('show the mapper: ')\n",
    "print(mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # second way through numpy array , not necessary\n",
    "# target_np = np.array(local_target)\n",
    "# print(target_np, type(target_np), target_np.shape)\n",
    "# target_tsr = torch.from_numpy(target_np).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5, 0],\n",
      "        [7, 3],\n",
      "        [1, 6],\n",
      "        [2, 4],\n",
      "        [6, 8]], device='cuda:0') <class 'torch.Tensor'> torch.Size([5, 2])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "target_tsr = torch.LongTensor(local_target).to('cuda')\n",
    "print(target_tsr, type(target_tsr), target_tsr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) On GPU, add the other direction and self-loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5, 7, 1, 2, 6]], device='cuda:0') <class 'torch.Tensor'> torch.Size([1, 5])\n",
      "tensor([[0, 3, 6, 4, 8]], device='cuda:0') <class 'torch.Tensor'> torch.Size([1, 5])\n"
     ]
    }
   ],
   "source": [
    "target_tsr = target_tsr.t()\n",
    "start, end = target_tsr\n",
    "start, end = start.unsqueeze(0), end.unsqueeze(0)\n",
    "print(start, type(start), start.shape)\n",
    "# print()\n",
    "print(end, type(end), end.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 3, 6, 4, 8],\n",
      "        [5, 7, 1, 2, 6]], device='cuda:0') <class 'torch.Tensor'> torch.Size([2, 5])\n"
     ]
    }
   ],
   "source": [
    "target_rever = torch.cat([end, start], dim=0)\n",
    "print(target_rever, type(target_rever), target_rever.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5, 7, 1, 2, 6, 0, 3, 6, 4, 8],\n",
      "        [0, 3, 6, 4, 8, 5, 7, 1, 2, 6]], device='cuda:0') <class 'torch.Tensor'> torch.Size([2, 10])\n"
     ]
    }
   ],
   "source": [
    "target_comb = torch.cat([target_tsr, target_rever], dim=1)\n",
    "print(target_comb, type(target_comb), target_comb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
      "        [0, 1, 2, 3, 4, 5, 6, 7, 8]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "loop_index = torch.arange(0, len(target_nodes), dtype=target_tsr.dtype, device=target_tsr.device)\n",
    "# loop_index = torch.LongTensor(list(mapper.values())).to('cuda')\n",
    "loop_index = loop_index.unsqueeze(0).repeat(2, 1)\n",
    "print(loop_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5, 7, 1, 2, 6, 0, 3, 6, 4, 8, 0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
      "        [0, 3, 6, 4, 8, 5, 7, 1, 2, 6, 0, 1, 2, 3, 4, 5, 6, 7, 8]],\n",
      "       device='cuda:0') <class 'torch.Tensor'> torch.Size([2, 19])\n"
     ]
    }
   ],
   "source": [
    "target_final = torch.cat([target_comb, loop_index], dim=1)\n",
    "print(target_final, type(target_final), target_final.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate the double direction weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=orange>\n",
    "In the two direction's of the same edge in the undirect-graph, the weights values are the same\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "from torch.nn import Parameter\n",
    "from torch_scatter import scatter_add\n",
    "# from torch_geometric.nn import MessagePassing\n",
    "import torch.nn.functional as F\n",
    "# from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import add_remaining_self_loops\n",
    "\n",
    "def get_edge_weight(edge_index, num_nodes, edge_weight=None, improved=False, dtype=None):\n",
    "        \n",
    "        if edge_weight is None:\n",
    "            edge_weight = torch.ones((edge_index.size(1), ), dtype=dtype, device=edge_index.device)\n",
    "        \n",
    "        fill_value = 1 if not improved else 2\n",
    "        # edge_index is already double direction if undirect, then add num_nodes self-loop edges added after the edge_index\n",
    "        edge_index, edge_weight = add_remaining_self_loops(edge_index, edge_weight, fill_value, num_nodes)\n",
    "        # after this edge_index is a 2 by (edge_num + node_num) tensor\n",
    "        row, col = edge_index   \n",
    "        # row includes the starting points of the edges  (first row of edge_index)\n",
    "        # col includes the ending points of the edges   (second row of edge_index)\n",
    "\n",
    "        deg = scatter_add(edge_weight, row, dim=0, dim_size=num_nodes)\n",
    "        # row records the source nodes, which is the index we are trying to add\n",
    "        # deg will record the out-degree of each node of x_i in all edges (x_i, x_j) including self_loops\n",
    "        \n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "        normalized_edge_weight = deg_inv_sqrt[row] * edge_weight * deg_inv_sqrt[col]\n",
    "        \n",
    "        edge_index_global_self_loops = edge_index\n",
    "        # transfer from tensor to the numpy to construct the dict for the edge_weights\n",
    "        edge_index = edge_index.t().numpy()\n",
    "        normalized_edge_weight = normalized_edge_weight.numpy()\n",
    "        num_edge, _ = edge_index.shape\n",
    "        # this info can also be stored as matrix considering the memory, depends whether the matrix is sparse or not\n",
    "        edge_weight_global_dict = {(edge_index[i][0], edge_index[i][1]) : normalized_edge_weight[i] for i in range(num_edge)}\n",
    "        \n",
    "#         print('after adding self-loops, edge_index is', edge_index)\n",
    "        edge_weight_global = [ edge_weight_global_dict[(edge[0], edge[1])] for edge in edge_index ]\n",
    "    \n",
    "        return edge_weight_global_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use trivial data\n",
    "\n",
    "edge_index = torch.tensor([[0, 1, 1, 3, 1, 2, 4, 2, 4, 6, 6, 7, 7, 9, 2, 5, 9, 8], \n",
    "                           [1, 0, 3, 1, 2, 1, 2, 4, 6, 4, 7, 6, 9, 7, 5, 2, 8, 9]])\n",
    "# features = torch.rand(10, 3)\n",
    "features = torch.tensor([[0, 0], [0, 1], [0, 2], [0, 3], [0, 4],  \n",
    "                           [0, 5], [0, 6], [0, 7], [0, 8], [0, 9]], dtype = torch.float)\n",
    "# label = torch.tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "\n",
    "label = torch.tensor([0, 1, 1, 0, 1, 1, 1, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 1): 0.35355338, (1, 0): 0.35355338, (1, 3): 0.35355338, (3, 1): 0.35355338, (1, 2): 0.25, (2, 1): 0.25, (4, 2): 0.28867513, (2, 4): 0.28867513, (4, 6): 0.3333333, (6, 4): 0.3333333, (6, 7): 0.3333333, (7, 6): 0.3333333, (7, 9): 0.3333333, (9, 7): 0.3333333, (2, 5): 0.35355338, (5, 2): 0.35355338, (9, 8): 0.40824828, (8, 9): 0.40824828, (0, 0): 0.49999997, (1, 1): 0.25, (2, 2): 0.25, (3, 3): 0.49999997, (4, 4): 0.3333333, (5, 5): 0.49999997, (6, 6): 0.3333333, (7, 7): 0.3333333, (8, 8): 0.49999997, (9, 9): 0.3333333}\n"
     ]
    }
   ],
   "source": [
    "edge_weight_global_dict = get_edge_weight(edge_index, features.shape[0])\n",
    "print(edge_weight_global_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create double_add_self_loop edge weights by a single direction edge weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 1), (1, 2), (1, 3), (6, 7), (4, 6), (8, 9), (2, 5), (2, 4), (7, 9)}\n"
     ]
    }
   ],
   "source": [
    "tmp = edge_index.t().numpy().tolist()\n",
    "graph = nx.from_edgelist(tmp)\n",
    "\n",
    "test_edges = {tuple(sorted(edge)) for edge in graph.edges()}\n",
    "test_nodes = sorted(node for node in graph.nodes())\n",
    "    \n",
    "print(test_edges)\n",
    "test_edge_weight_local = [ edge_weight_global_dict[(edge[0], edge[1])] for edge in test_edges ]       \n",
    "test_edge_weight_selfloop_local = [ edge_weight_global_dict[(i, i)] for i in test_nodes ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3536, 0.2500, 0.3536, 0.3333, 0.3333, 0.4082, 0.3536, 0.2887, 0.3333],\n",
      "       device='cuda:0')\n",
      "tensor([0.5000, 0.2500, 0.2500, 0.5000, 0.3333, 0.5000, 0.3333, 0.3333, 0.5000,\n",
      "        0.3333], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "test_edge_weight_local_tsr = torch.FloatTensor(test_edge_weight_local).to('cuda')\n",
    "test_edge_weight_selfloop_local_tsr = torch.FloatTensor(test_edge_weight_selfloop_local).to('cuda')\n",
    "print(test_edge_weight_local_tsr)\n",
    "print(test_edge_weight_selfloop_local_tsr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3536, 0.2500, 0.3536, 0.3333, 0.3333, 0.4082, 0.3536, 0.2887, 0.3333,\n",
      "        0.3536, 0.2500, 0.3536, 0.3333, 0.3333, 0.4082, 0.3536, 0.2887, 0.3333,\n",
      "        0.5000, 0.2500, 0.2500, 0.5000, 0.3333, 0.5000, 0.3333, 0.3333, 0.5000,\n",
      "        0.3333], device='cuda:0') torch.Size([28])\n"
     ]
    }
   ],
   "source": [
    "edge_weights = torch.cat([test_edge_weight_local_tsr, test_edge_weight_local_tsr, test_edge_weight_selfloop_local_tsr], dim=0)\n",
    "print(edge_weights, edge_weights.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement the overlap between different train-batches (nodes and edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 4\n",
      "4 5\n",
      "3 5\n",
      "set() <class 'set'> 0\n"
     ]
    }
   ],
   "source": [
    "a = [3, 4, 5]\n",
    "b = [6, 7, 8]\n",
    "for i in range(1, len(a)):\n",
    "    for left, right in zip(a, a[i:]):\n",
    "        print(left, right)\n",
    "        \n",
    "a = {3, 4, 5}; b = {7, 8, 6}\n",
    "c = a & b\n",
    "print(c, type(c), len(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_geometric]",
   "language": "python",
   "name": "conda-env-pytorch_geometric-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
